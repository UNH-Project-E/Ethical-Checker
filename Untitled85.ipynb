{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled85.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8cb4b8a8f9e64b94adcc5675ea556f48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_32e98649934640859d11df01e182829d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_63ab6051d75d4cd2898407bb32a93e34",
              "IPY_MODEL_833d8f986ccd485ebf4a0def86a099a6"
            ]
          }
        },
        "32e98649934640859d11df01e182829d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "63ab6051d75d4cd2898407bb32a93e34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b65ceceddf3647c798cface1e98fa620",
            "_dom_classes": [],
            "description": "Batches: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 37,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 37,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d7f75f7053d947b3bf1f236ac6cf7271"
          }
        },
        "833d8f986ccd485ebf4a0def86a099a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_684c9a81a0bd4ddb84d9732e6963a27b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 37/37 [01:10&lt;00:00,  1.92s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6d13346dca844ae38980e1d01fe89bd3"
          }
        },
        "b65ceceddf3647c798cface1e98fa620": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d7f75f7053d947b3bf1f236ac6cf7271": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "684c9a81a0bd4ddb84d9732e6963a27b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6d13346dca844ae38980e1d01fe89bd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b02592260d6f41a6a6fe80570f6dd0a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_dde96f294879489e97d19bc9b9c8ad33",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_277b6896d01e4bb3a39a32925c839829",
              "IPY_MODEL_6014ea82f50e4e479f1c2ca61717a042"
            ]
          }
        },
        "dde96f294879489e97d19bc9b9c8ad33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "277b6896d01e4bb3a39a32925c839829": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_be1d644ca4af49189fec51fc97669bf3",
            "_dom_classes": [],
            "description": "Batches: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 37,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 37,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cd2ac71758444f949c6cfbf86920cc1a"
          }
        },
        "6014ea82f50e4e479f1c2ca61717a042": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e9c6f2c567274fc39246e1efdeb3521e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 37/37 [11:03&lt;00:00, 17.94s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dddbf1a986b246539757c1c8211f23b4"
          }
        },
        "be1d644ca4af49189fec51fc97669bf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cd2ac71758444f949c6cfbf86920cc1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e9c6f2c567274fc39246e1efdeb3521e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dddbf1a986b246539757c1c8211f23b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "adefedfbd9a047a3a86e5886601f22c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_03a1e8a085864ced91f6cde49d828af1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6a1dded166e24c068e9b5d7c67fae60f",
              "IPY_MODEL_791984d4a8cb407e80e7786ddf87682b"
            ]
          }
        },
        "03a1e8a085864ced91f6cde49d828af1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6a1dded166e24c068e9b5d7c67fae60f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_251cbe84798c40e5b499823dfec896bb",
            "_dom_classes": [],
            "description": "Batches: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0843cb4fb27141a68dd1da31810107eb"
          }
        },
        "791984d4a8cb407e80e7786ddf87682b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0b38350afa0d4cb189cfaf40bb2cce45",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4/4 [00:23&lt;00:00,  5.98s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_31ac9f70e8a94452a3ba5a6bc998dac3"
          }
        },
        "251cbe84798c40e5b499823dfec896bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0843cb4fb27141a68dd1da31810107eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0b38350afa0d4cb189cfaf40bb2cce45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "31ac9f70e8a94452a3ba5a6bc998dac3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ceb8a8c1ea984245b22410874725f196": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8089f4a725ad47ec94b6c442f81a75b4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_744bc97853f34c31a89194373ddb03df",
              "IPY_MODEL_7edd8f4ae10a4b3a92530860973c4853"
            ]
          }
        },
        "8089f4a725ad47ec94b6c442f81a75b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "744bc97853f34c31a89194373ddb03df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ad716ad207b44735824db53338d6e0f0",
            "_dom_classes": [],
            "description": "Batches: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 37,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 37,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_521f287ac9f14efca3b1716cbc7e36a4"
          }
        },
        "7edd8f4ae10a4b3a92530860973c4853": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_47e5e0e3ae404b159f7f331e286a7648",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 37/37 [00:35&lt;00:00,  1.04it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4249a5b185a4498f97ddd25d4d3f6861"
          }
        },
        "ad716ad207b44735824db53338d6e0f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "521f287ac9f14efca3b1716cbc7e36a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "47e5e0e3ae404b159f7f331e286a7648": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4249a5b185a4498f97ddd25d4d3f6861": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQy7XKtQ3ZHv"
      },
      "source": [
        "# Installs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJYf4CYG2tCG",
        "outputId": "c9123155-d482-4e4b-86ed-d500b3a6a86d"
      },
      "source": [
        "pip install -U sentence-transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentence-transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/4d/9fb1028b0b4645c77401417151d06122d745c7a874fda6a4d5e6bb7bebc6/sentence-transformers-1.0.3.tar.gz (74kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 3.3MB/s \n",
            "\u001b[?25hCollecting transformers<5.0.0,>=3.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/d5/f4157a376b8a79489a76ce6cfe147f4f3be1e029b7144fa7b8432e8acb26/transformers-4.4.2-py3-none-any.whl (2.0MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0MB 5.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.8.0+cu101)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 21.0MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 28.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (20.9)\n",
            "Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.12)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2.23.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/23/2ddc317b2121117bf34dd00f5b0de194158f2a44ee2bf5e47c7166878a97/tokenizers-0.10.1-cp37-cp37m-manylinux2010_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 31.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (3.7.2)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=3.1.0->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.4.1)\n",
            "Building wheels for collected packages: sentence-transformers, sacremoses\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-1.0.3-cp37-none-any.whl size=114277 sha256=3da0df329bfc143f94ce2a90711075e1adc0bc67bcaadc3036c8e9d8a3453c00\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/0d/fa/4e28cf045da4781344e7972befb2fdf306051b225bfc290187\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=d286813353a6c4954e9d27865374530636eaec707d1de848811c6be8a6cc50db\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sentence-transformers sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers, sentencepiece, sentence-transformers\n",
            "Successfully installed sacremoses-0.0.43 sentence-transformers-1.0.3 sentencepiece-0.1.95 tokenizers-0.10.1 transformers-4.4.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cISG5vn-nNhA",
        "outputId": "dc30ced8-3d67-41a1-ab2d-e0e909283a52"
      },
      "source": [
        "pip install pdfminer.six"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pdfminer.six\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/f3/4fec7dabe8802ebec46141345bf714cd1fc7d93cb74ddde917e4b6d97d88/pdfminer.six-20201018-py3-none-any.whl (5.6MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6MB 4.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet; python_version > \"3.0\" in /usr/local/lib/python3.7/dist-packages (from pdfminer.six) (3.0.4)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from pdfminer.six) (2.3.0)\n",
            "Collecting cryptography\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/26/7af637e6a7e87258b963f1731c5982fb31cd507f0d90d91836e446955d02/cryptography-3.4.7-cp36-abi3-manylinux2014_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 48.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography->pdfminer.six) (1.14.5)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography->pdfminer.six) (2.20)\n",
            "Installing collected packages: cryptography, pdfminer.six\n",
            "Successfully installed cryptography-3.4.7 pdfminer.six-20201018\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ek7jbhX52RUT",
        "outputId": "f24409bf-79d4-4893-bbf7-8966e94fb394"
      },
      "source": [
        "pip install transformers torch"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.4.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.8.0+cu101)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.2)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzG92jY_2avD",
        "outputId": "224898af-ef25-4fb3-c8c9-b94a644e87dd"
      },
      "source": [
        "pip install bert-extractive-summarizer"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-extractive-summarizer\n",
            "  Downloading https://files.pythonhosted.org/packages/1a/07/fdb05f9e18b6f641499ef56737126fbd2fafe1cdc1a04ba069d5aa205901/bert_extractive_summarizer-0.7.1-py3-none-any.whl\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (from bert-extractive-summarizer) (4.4.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from bert-extractive-summarizer) (0.22.2.post1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (from bert-extractive-summarizer) (2.2.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers->bert-extractive-summarizer) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers->bert-extractive-summarizer) (1.19.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers->bert-extractive-summarizer) (0.0.43)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers->bert-extractive-summarizer) (4.41.1)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers->bert-extractive-summarizer) (0.10.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers->bert-extractive-summarizer) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers->bert-extractive-summarizer) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers->bert-extractive-summarizer) (20.9)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers->bert-extractive-summarizer) (3.7.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->bert-extractive-summarizer) (1.0.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->bert-extractive-summarizer) (1.4.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (7.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (1.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (0.8.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (1.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (3.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (0.4.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (1.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (54.1.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (2.0.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers->bert-extractive-summarizer) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers->bert-extractive-summarizer) (7.1.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers->bert-extractive-summarizer) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers->bert-extractive-summarizer) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers->bert-extractive-summarizer) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers->bert-extractive-summarizer) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers->bert-extractive-summarizer) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers->bert-extractive-summarizer) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers->bert-extractive-summarizer) (3.4.1)\n",
            "Installing collected packages: bert-extractive-summarizer\n",
            "Successfully installed bert-extractive-summarizer-0.7.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRN0DjXr2jwH",
        "outputId": "f54f0101-de85-4a07-c812-a021525a905f"
      },
      "source": [
        "pip install sumy"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sumy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/61/20/8abf92617ec80a2ebaec8dc1646a790fc9656a4a4377ddb9f0cc90bc9326/sumy-0.8.1-py2.py3-none-any.whl (83kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 3.8MB/s \n",
            "\u001b[?25hCollecting pycountry>=18.2.23\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/73/6f1a412f14f68c273feea29a6ea9b9f1e268177d32e0e69ad6790d306312/pycountry-20.7.3.tar.gz (10.1MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1MB 7.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from sumy) (2.23.0)\n",
            "Collecting breadability>=0.1.20\n",
            "  Downloading https://files.pythonhosted.org/packages/ad/2d/bb6c9b381e6b6a432aa2ffa8f4afdb2204f1ff97cfcc0766a5b7683fec43/breadability-0.1.20.tar.gz\n",
            "Requirement already satisfied: docopt<0.7,>=0.6.1 in /usr/local/lib/python3.7/dist-packages (from sumy) (0.6.2)\n",
            "Requirement already satisfied: nltk>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from sumy) (3.2.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.7.0->sumy) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.7.0->sumy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.7.0->sumy) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.7.0->sumy) (3.0.4)\n",
            "Requirement already satisfied: lxml>=2.0 in /usr/local/lib/python3.7/dist-packages (from breadability>=0.1.20->sumy) (4.2.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk>=3.0.2->sumy) (1.15.0)\n",
            "Building wheels for collected packages: pycountry, breadability\n",
            "  Building wheel for pycountry (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycountry: filename=pycountry-20.7.3-py2.py3-none-any.whl size=10746863 sha256=c303bdbe6091aa241f065f221c0e2d30933c5f67aab25e34f157969fc52e78e9\n",
            "  Stored in directory: /root/.cache/pip/wheels/33/4e/a6/be297e6b83567e537bed9df4a93f8590ec01c1acfbcd405348\n",
            "  Building wheel for breadability (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for breadability: filename=breadability-0.1.20-py2.py3-none-any.whl size=21680 sha256=8ddf8cb42ad855c67d39761a5d3bb02e06af0b70c5d10ad226883f53ec56f4e1\n",
            "  Stored in directory: /root/.cache/pip/wheels/5a/4d/a1/510b12c5e65e0b2b3ce539b2af66da0fc57571e528924f4a52\n",
            "Successfully built pycountry breadability\n",
            "Installing collected packages: pycountry, breadability, sumy\n",
            "Successfully installed breadability-0.1.20 pycountry-20.7.3 sumy-0.8.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FP75Gbtm7o-l",
        "outputId": "7f0a67f7-e9d4-40ae-b11e-fcd0c6e23330"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCmOh3JX97UI",
        "outputId": "4572548e-f940-46e5-81f4-e2eb5d1ce386"
      },
      "source": [
        "pip install requests"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2020.12.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ve6PuCVu9_Ab",
        "outputId": "77678967-320d-4ce9-a798-b5b704afe4f3"
      },
      "source": [
        "pip install bs4"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.7/dist-packages (0.0.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bs4) (4.6.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gy7QulmUgv5x",
        "outputId": "f069079c-d9bb-4b60-f742-3b5ddc5e4802"
      },
      "source": [
        "pip install PyPDF2"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting PyPDF2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b4/01/68fcc0d43daf4c6bdbc6b33cc3f77bda531c86b174cac56ef0ffdb96faab/PyPDF2-1.26.0.tar.gz (77kB)\n",
            "\r\u001b[K     |████▎                           | 10kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 20kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 30kB 9.0MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 40kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 51kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 61kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 71kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 3.3MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: PyPDF2\n",
            "  Building wheel for PyPDF2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyPDF2: filename=PyPDF2-1.26.0-cp37-none-any.whl size=61085 sha256=beeda78bd4472a1452c5dc4a3a2b1253e69707e449e10f23607d2ca86fb6dcc6\n",
            "  Stored in directory: /root/.cache/pip/wheels/53/84/19/35bc977c8bf5f0c23a8a011aa958acd4da4bbd7a229315c1b7\n",
            "Successfully built PyPDF2\n",
            "Installing collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-1.26.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMmcZCB414Sn",
        "outputId": "6d3cd907-a490-474e-e230-590715a514e8"
      },
      "source": [
        "pip install newspaper3k"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting newspaper3k\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/b9/51afecb35bb61b188a4b44868001de348a0e8134b4dfa00ffc191567c4b9/newspaper3k-0.2.8-py3-none-any.whl (211kB)\n",
            "\r\u001b[K     |█▌                              | 10kB 16.6MB/s eta 0:00:01\r\u001b[K     |███                             | 20kB 8.9MB/s eta 0:00:01\r\u001b[K     |████▋                           | 30kB 9.0MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 40kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 51kB 4.2MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 61kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 71kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 81kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 92kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 102kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 112kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 122kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 133kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 143kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 153kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 163kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 174kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 184kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 194kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 204kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 215kB 4.3MB/s \n",
            "\u001b[?25hCollecting tinysegmenter==0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/17/82/86982e4b6d16e4febc79c2a1d68ee3b707e8a020c5d2bc4af8052d0f136a/tinysegmenter-0.3.tar.gz\n",
            "Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (7.0.0)\n",
            "Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (3.13)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (2.23.0)\n",
            "Collecting tldextract>=2.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/62/b6acd3129c5615b9860e670df07fd55b76175b63e6b7f68282c7cad38e9e/tldextract-3.1.0-py2.py3-none-any.whl (87kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 8.3MB/s \n",
            "\u001b[?25hCollecting jieba3k>=0.35.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/cb/2c8332bcdc14d33b0bedd18ae0a4981a069c3513e445120da3c3f23a8aaa/jieba3k-0.35.1.zip (7.4MB)\n",
            "\u001b[K     |████████████████████████████████| 7.4MB 23.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (2.8.1)\n",
            "Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (4.2.6)\n",
            "Requirement already satisfied: nltk>=3.2.1 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (3.2.5)\n",
            "Collecting cssselect>=0.9.2\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/d4/3b5c17f00cce85b9a1e6f91096e1cc8e8ede2e1be8e96b87ce1ed09e92c5/cssselect-1.1.0-py2.py3-none-any.whl\n",
            "Collecting feedparser>=5.2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/21/faf1bac028662cc8adb2b5ef7a6f3999a765baa2835331df365289b0ca56/feedparser-6.0.2-py3-none-any.whl (80kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 7.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (4.6.3)\n",
            "Collecting feedfinder2>=0.0.4\n",
            "  Downloading https://files.pythonhosted.org/packages/35/82/1251fefec3bb4b03fd966c7e7f7a41c9fc2bb00d823a34c13f847fd61406/feedfinder2-0.0.4.tar.gz\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k) (3.0.4)\n",
            "Collecting requests-file>=1.4\n",
            "  Downloading https://files.pythonhosted.org/packages/77/86/cdb5e8eaed90796aa83a6d9f75cfbd37af553c47a291cd47bc410ef9bdb2/requests_file-1.5.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from tldextract>=2.0.1->newspaper3k) (3.0.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.5.3->newspaper3k) (1.15.0)\n",
            "Collecting sgmllib3k\n",
            "  Downloading https://files.pythonhosted.org/packages/9e/bd/3704a8c3e0942d711c1299ebf7b9091930adae6675d7c8f476a7ce48653c/sgmllib3k-1.0.0.tar.gz\n",
            "Building wheels for collected packages: tinysegmenter, jieba3k, feedfinder2, sgmllib3k\n",
            "  Building wheel for tinysegmenter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-cp37-none-any.whl size=13538 sha256=c0f6eccc08a9820dd378b137b2cd3a18f8647d317fa706c4b8ea118ae53eba5b\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/2b/43/a02ede72324dd40cdd7ca53aad718c7710628e91b8b0dc0f02\n",
            "  Building wheel for jieba3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jieba3k: filename=jieba3k-0.35.1-cp37-none-any.whl size=7398406 sha256=67b34833f29757b983b33191baff58f1d7003a6a648a2970b9a0c540c2c1d931\n",
            "  Stored in directory: /root/.cache/pip/wheels/83/15/9c/a3f1f67e7f7181170ad37d32e503c35da20627c013f438ed34\n",
            "  Building wheel for feedfinder2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-cp37-none-any.whl size=3358 sha256=f8304f7b6b1e34dc1477a0937d7bb57a1a4cee91442063b420ac24dcc05ff025\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/03/ca/778e3a7a627e3d98836cc890e7cb40c7575424cfd3340f40ed\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-cp37-none-any.whl size=6067 sha256=b59b9b8a82dd602a5eefbe095b4f182ce741c92a76f98ea79ecf1c76c27f532b\n",
            "  Stored in directory: /root/.cache/pip/wheels/f1/80/5a/444ba08a550cdd241bd9baf8bae44be750efe370adb944506a\n",
            "Successfully built tinysegmenter jieba3k feedfinder2 sgmllib3k\n",
            "Installing collected packages: tinysegmenter, requests-file, tldextract, jieba3k, cssselect, sgmllib3k, feedparser, feedfinder2, newspaper3k\n",
            "Successfully installed cssselect-1.1.0 feedfinder2-0.0.4 feedparser-6.0.2 jieba3k-0.35.1 newspaper3k-0.2.8 requests-file-1.5.1 sgmllib3k-1.0.0 tinysegmenter-0.3 tldextract-3.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPNzZFIe3inX"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9V-V8T-B3hG9"
      },
      "source": [
        "from nltk.cluster.util import cosine_distance\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tvs6BI6_CrYr"
      },
      "source": [
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "from sumy.nlp.tokenizers import Tokenizer"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmkwmkRU3u53"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "from sumy.nlp.tokenizers import Tokenizer"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2zokUYX5xT_"
      },
      "source": [
        "import requests\n",
        "#import RAKE\n",
        "import operator\n",
        "import timeit\n",
        "import time\n",
        "API_KEY = \"AIzaSyAvZlAZHcE3lXigI2ZJxWQvCoCpF6qFiyY\"\n",
        "SEARCH_ENGINE_ID = \"bf6585a79f0c6d8bb\""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7J0vWULO5ZVj"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TecHuT-o5mAN"
      },
      "source": [
        "def google_search(api_key, search_engine, query, page_number=1):\n",
        "  start = (page_number - 1) * 10 + 1\n",
        "  url = f\"https://www.googleapis.com/customsearch/v1?key={api_key}&cx={search_engine}&q={query}&start={start}\"\n",
        "  data = requests.get(url).json()\n",
        "  return data"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXHtpvgz5mFl"
      },
      "source": [
        "def results(data):\n",
        "  search_items = data.get(\"items\")\n",
        "  for i, search_item in enumerate(search_items, start=1):\n",
        "    title = search_item.get(\"title\")\n",
        "    snippet = search_item.get(\"snippet\")\n",
        "    link = search_item.get(\"link\")\n",
        "    print(\"Title:\", title)\n",
        "    print(\"Description:\", snippet)\n",
        "    print(\"URL:\", link, \"\\n\")\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVdNMBX06C2R"
      },
      "source": [
        "def only_link(data):\n",
        "  search_items = data.get(\"items\")\n",
        "  link=[]\n",
        "  for i, search_item in enumerate(search_items, start=1):\n",
        "    link.append(search_item.get(\"link\")) \n",
        "    #print(\"URL:\", link, \"\\n\")\n",
        "  return  link"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9mAN3WF6Kxf"
      },
      "source": [
        "def Sort (info):\n",
        "  info.sort(key = lambda x: x[1], reverse=True)\n",
        "  return info"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ld6WkGV36QTB"
      },
      "source": [
        "def read_file(files):\n",
        "  myfile = open(files, \"r\")\n",
        "  readfiles=myfile.readlines()\n",
        "  text =\"\"\n",
        "  for line in range(len(readfiles)):\n",
        "    text = text + \" \"+ readfiles[line]\n",
        "  return text "
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uheL9FSh6jXL"
      },
      "source": [
        "# Actual Using LSA Summarizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AMfae9H64Tn"
      },
      "source": [
        "textatten = read_file(\"Attention.txt\")\n",
        "sentencesAtten=sent_tokenize(textatten)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "0zHQX69F7-7h",
        "outputId": "6b0f2c3f-11b4-4c2b-e9a0-6629b658cda9"
      },
      "source": [
        "from sumy.summarizers.lsa import LsaSummarizer\n",
        "parser = PlaintextParser.from_string(textatten,Tokenizer(\"english\"))\n",
        "summarizer_lsa = LsaSummarizer()\n",
        "# Summarize using sumy LSA\n",
        "summary =summarizer_lsa(parser.document,2)\n",
        "lsa_summary=\"\"\n",
        "for sentence in summary:\n",
        "    lsa_summary+=str(sentence)  \n",
        "print(lsa_summary)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-e9cc46d08201>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msumy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummarizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlsa\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLsaSummarizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPlaintextParser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtextatten\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"english\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msummarizer_lsa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLsaSummarizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Summarize using sumy LSA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0msummarizer_lsa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'textatten' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhKV2-j78vN-",
        "outputId": "628af6e9-1597-410f-e88f-0a42066d1c98"
      },
      "source": [
        "myquery= input(\"Please enter the information to be searched \")\n",
        "data =google_search(API_KEY,SEARCH_ENGINE_ID,myquery)\n",
        "results(data)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please enter the information to be searched From this analysis, it emerges that the SepFormer is not only faster but also less memory demanding than DPTNet, DPRNN, and Wavesplit.[33] M. Pariente, S. Cornell, J. Cosentino, S. Sivasankaran, E. Tzinis, J. Heitkaemper, M. Olvera, F.-R. Stoter, M. Hu, J. M. ¨ Martın-Donas, D. Ditter, A. Frank, A. Deleforge, and E. Vin- ˜ cent, “Asteroid: the PyTorch-based audio source separation toolkit for researchers,” in Proc.\n",
            "Title: arXiv:2010.13154v2 [eess.AS] 8 Mar 2021\n",
            "Description: Mar 8, 2021 ... In this paper, we propose the SepFormer, a novel RNN-free ... faster and it is less \n",
            "memory-demanding than the latest speech separation systems with ... is not only \n",
            "faster but also less memory demanding than DPTNet, DPRNN, and ... [33] M. \n",
            "Pariente, S. Cornell, J. Cosentino, S. Sivasankaran, E. Tzi- nis, J.\n",
            "URL: https://arxiv.org/pdf/2010.13154 \n",
            "\n",
            "Title: Attention is All You Need in Speech Separation\n",
            "Description: Oct 25, 2020 ... It is thus significantly faster and it is less memory-demanding than the ... speech \n",
            "recognition, synthesis, enhancement, and separation, just to name a few. ... ^s2. \n",
            "m1. m2. Figure 1: The high-level description of our system: The ... From this \n",
            "analysis it emerges that the SepFormer is not only faster but also less ...\n",
            "URL: https://www.groundai.com/project/attention-is-all-you-need-in-speech-separation/1 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebG1Xh358jy3"
      },
      "source": [
        "# WebStripping "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNktL9k-lSQ4",
        "outputId": "f929eae6-a423-4f87-c2b2-2d7d17ba13e0"
      },
      "source": [
        "url = \"https://arxiv.org/pdf/2010.13154 \"\n",
        "\n",
        "# Requests URL and get response object \n",
        "response = requests.get(url) \n",
        "i=1\n",
        "pdf = open(\"pdf\"+str(i)+\".pdf\", 'wb') \n",
        "pdf.write(response.content) \n",
        "pdf.close() \n",
        "print(\"File \", i, \" downloaded\")"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File  1  downloaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Uvge6L8cyF6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7812c924-8b13-4f08-ce33-c08d740ea7ec"
      },
      "source": [
        "# importing required modules\n",
        "import PyPDF2\n",
        "from PyPDF2 import PdfFileReader\n",
        "  \n",
        "# creating a pdf file object\n",
        "pdfFileObj = open('pdf1.pdf', 'rb')\n",
        "  \n",
        "# creating a pdf reader object\n",
        "pdfReader = PyPDF2.PdfFileReader(pdfFileObj)\n",
        "with open(\"pdf1.pdf\", 'rb') as f:\n",
        "  pdf = PdfFileReader(f)\n",
        "  information = pdf.getDocumentInfo()\n",
        "  number_of_pages = pdf.getNumPages()\n",
        "\n",
        "txt = f\"\"\"\n",
        "Information about {\"pdf1.pdf\"}: \n",
        "Author: {information.author}\n",
        "Creator: {information.creator}\n",
        "Producer: {information.producer}\n",
        "Subject: {information.subject}\n",
        "Title: {information.title}\n",
        "Number of pages: {number_of_pages}\n",
        "    \"\"\"\n",
        "\n",
        "print(txt)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Information about pdf1.pdf: \n",
            "Author: \n",
            "Creator: LaTeX with hyperref\n",
            "Producer: pdfTeX-1.40.21\n",
            "Subject: \n",
            "Title: \n",
            "Number of pages: 5\n",
            "    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rWy12NqmCqK",
        "outputId": "10f5d0f1-f7fd-4ad7-e29c-79790224ad17"
      },
      "source": [
        "print(information)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'/Author': '', '/CreationDate': 'D:20210310012133Z', '/Creator': 'LaTeX with hyperref', '/Keywords': '', '/ModDate': 'D:20210310012133Z', '/PTEX.Fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', '/Producer': 'pdfTeX-1.40.21', '/Subject': '', '/Title': '', '/Trapped': '/False'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDXEEwE9nU8a",
        "outputId": "9772db06-c727-4c84-f29b-10b6c14cbaf2"
      },
      "source": [
        "from pdfminer.high_level import extract_text\n",
        " \n",
        "text = extract_text(\"pdf1.pdf\")\n",
        " \n",
        "print(text)\n"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ATTENTION IS ALL YOU NEED IN SPEECH SEPARATION\n",
            "\n",
            "Cem Subakan1, Mirco Ravanelli1, Samuele Cornell2, Mirko Bronzi1, Jianyuan Zhong3\n",
            "\n",
            "1Mila-Quebec AI Institute, Canada,\n",
            "2Universit`a Politecnica delle Marche, Italy\n",
            "3University of Rochester, USA\n",
            "\n",
            "1\n",
            "2\n",
            "0\n",
            "2\n",
            " \n",
            "r\n",
            "a\n",
            "\n",
            "M\n",
            " \n",
            "8\n",
            " \n",
            " \n",
            "]\n",
            "S\n",
            "A\n",
            ".\n",
            "s\n",
            "s\n",
            "e\n",
            "e\n",
            "[\n",
            " \n",
            " \n",
            "2\n",
            "v\n",
            "4\n",
            "5\n",
            "1\n",
            "3\n",
            "1\n",
            ".\n",
            "0\n",
            "1\n",
            "0\n",
            "2\n",
            ":\n",
            "v\n",
            "i\n",
            "X\n",
            "r\n",
            "a\n",
            "\n",
            "ABSTRACT\n",
            "\n",
            "Recurrent Neural Networks (RNNs) have long been the dominant\n",
            "architecture in sequence-to-sequence learning. RNNs, however, are\n",
            "inherently sequential models that do not allow parallelization of their\n",
            "computations. Transformers are emerging as a natural alternative to\n",
            "standard RNNs, replacing recurrent computations with a multi-head\n",
            "attention mechanism.\n",
            "\n",
            "In this paper, we propose the SepFormer, a novel RNN-free\n",
            "Transformer-based neural network for speech separation. The Sep-\n",
            "Former learns short and long-term dependencies with a multi-scale\n",
            "approach that employs transformers. The proposed model achieves\n",
            "state-of-the-art (SOTA) performance on the standard WSJ0-2/3mix\n",
            "datasets. It reaches an SI-SNRi of 22.3 dB on WSJ0-2mix and an\n",
            "SI-SNRi of 19.5 dB on WSJ0-3mix. The SepFormer inherits the\n",
            "parallelization advantages of Transformers and achieves a compet-\n",
            "itive performance even when downsampling the encoded represen-\n",
            "tation by a factor of 8. It is thus signiﬁcantly faster and it is less\n",
            "memory-demanding than the latest speech separation systems with\n",
            "comparable performance.\n",
            "\n",
            "Index Terms— speech separation, source separation,\n",
            "\n",
            "trans-\n",
            "\n",
            "former, attention, deep learning.\n",
            "\n",
            "1. INTRODUCTION\n",
            "\n",
            "RNNs are a crucial component of modern audio processing sys-\n",
            "tems and they are used in many different domains, including speech\n",
            "recognition, synthesis, enhancement, and separation, just to name a\n",
            "few. Especially when coupled with multiplicative gate mechanisms\n",
            "(like LSTM [1] and GRU [2, 3]), their recurrent connections are es-\n",
            "sential to learn long-term dependencies and properly manage speech\n",
            "contexts. Nevertheless, the inherently sequential nature of RNNs\n",
            "impairs an effective parallelization of the computations. This bot-\n",
            "tleneck is particularly evident when processing large datasets with\n",
            "long sequences. On the other hand, Transformers [4] completely\n",
            "avoid this bottleneck by eliminating recurrence and replacing it with\n",
            "a fully attention-based mechanism. By attending to the whole se-\n",
            "quence at once, a direct connection can be established between dis-\n",
            "tant elements allowing Transformers to learn long-term dependen-\n",
            "cies more easily [5]. For this reason, Transformers are gaining con-\n",
            "siderable popularity for speech processing and recently showed com-\n",
            "petitive performance in speech recognition [6], synthesis [7], en-\n",
            "hancement [8], diarization [9], as well as speaker recognition [10].\n",
            "\n",
            "Little research has been done so far on Transformer-based mod-\n",
            "els for monaural audio source separation. The ﬁeld has been revo-\n",
            "lutionized by the adoption of deep learning techniques [11–16], and\n",
            "with recent works [17–23] achieving impressive results by adopt-\n",
            "ing an end-to-end approach. Most of the current speech separation\n",
            "techniques [14, 15, 17–22] require effective modeling of long input\n",
            "\n",
            "x\n",
            "\n",
            "Encoder\n",
            "\n",
            "h Masking Net\n",
            "\n",
            "Decoder\n",
            "\n",
            "ˆs1\n",
            "\n",
            "ˆs2\n",
            "\n",
            "m1\n",
            "\n",
            "m2\n",
            "\n",
            "Fig. 1. The high-level description of our system: The encoder block\n",
            "estimates a learned-representation for the input signal, while the\n",
            "masking network estimates optimal masks to separate the sources\n",
            "present in the mixtures. The decoder ﬁnally reconstructs the esti-\n",
            "mated sources in the time domain using the masks provided by the\n",
            "masking network.\n",
            "\n",
            "sequences to perform well. Current systems rely, in large part, on the\n",
            "learned-domain masking strategy popularized by Conv-TasNet [15].\n",
            "In this framework, an overcomplete set of analysis and synthesis ﬁl-\n",
            "ters is learned directly from the data, and separation is performed\n",
            "by estimating a mask for each source in this learned-domain. Build-\n",
            "ing on this, Dual-Path RNN (DPRNN) [17] has demonstrated that\n",
            "better long-term modeling is crucial to improve the separation per-\n",
            "formance. This is achieved by splitting the input sequence into mul-\n",
            "tiple chunks that are processed locally and globally with different\n",
            "RNNs. Nevertheless, due to the use of RNNs, DPRNN still suffers\n",
            "from the aforementioned limitations of recurrent connections, espe-\n",
            "cially regarding the global processing step. An attempt to integrate\n",
            "transformers into the speech separation pipeline has been recently\n",
            "done in [22] where the proposed Dual-Path Transformer Network\n",
            "(DPTNet) is shown to outperform the standard DPRNN. Such an ar-\n",
            "chitecture, however, still embeds an RNN, effectively negating the\n",
            "parallelization capability of pure-attention models.\n",
            "\n",
            "In this paper, we propose a novel model called SepFormer (Sep-\n",
            "aration Transformer), which is mainly composed of multi-head at-\n",
            "tention and feed-forward layers. We adopt the dual-path frame-\n",
            "work introduced by DPRNN and we replace RNNs with a multi-\n",
            "scale pipeline composed of transformers that learn both short and\n",
            "long-term dependencies. The dual-path framework enables to miti-\n",
            "gate the quadratic complexity of transformers, as transformers in the\n",
            "dual-path framework process smaller chunks.\n",
            "\n",
            "To the best of our knowledge, this is the ﬁrst work showing\n",
            "that we can obtain state-of-the-art performance in separation with an\n",
            "RNN-free Transformer-based architecture. The SepFormer achieves\n",
            "an SI-SNRi of 22.3 dB on the standard WSJ0-2mix dataset. It also\n",
            "achieves the SOTA performance of 19.5 dB SI-SNRi on the WSJ0-\n",
            "3mix dataset. The SepFormer not only processes all the time steps in\n",
            "parallel but also achieves competitive performance when downsam-\n",
            "pling the encoded representation by a factor of 8. This makes the\n",
            "proposed architecture signiﬁcantly faster and less memory demand-\n",
            "\n",
            "\fing than the latest RNN-based separation models.\n",
            "\n",
            "2. THE MODEL\n",
            "\n",
            "The proposed model is based on the learned-domain masking ap-\n",
            "proach [14, 15, 17–22] and employs an encoder, a decoder, and a\n",
            "masking network, as shown in Figure 1. The encoder is fully con-\n",
            "volutional, while the masking network employs two Transformers\n",
            "embedded inside the dual-path processing block proposed in [17].\n",
            "The decoder ﬁnally reconstructs the separated signals in the time\n",
            "domain by using the masks predicted by the masking network. To\n",
            "foster reproducibility, the SepFormer will be made available within\n",
            "the SpeechBrain toolkit1.\n",
            "\n",
            "2.1. Encoder\n",
            "\n",
            "The encoder takes in the time-domain mixture-signal x ∈ RT as\n",
            "input, which contains audio from multiple speakers.\n",
            "It learns an\n",
            "STFT-like representation h ∈ RF ×T (cid:48)\n",
            "using a single convolutional\n",
            "layer:\n",
            "\n",
            "h = ReLU(conv1d(x)).\n",
            "\n",
            "(1)\n",
            "\n",
            "As we will describe in Sec. 4, the stride factor of this convolution\n",
            "impacts signiﬁcantly on the performance, speed, and memory of the\n",
            "model.\n",
            "\n",
            "2.2. Masking Network\n",
            "\n",
            "Figure 2 (top) shows the detailed architecture of the masking net-\n",
            "work (Masking Net). The masking network is fed by the encoded\n",
            "representations h ∈ RF ×T (cid:48)\n",
            "and estimates a mask {m1, . . . , mN s}\n",
            "for each of the N s speakers in the mixture.\n",
            "\n",
            "As in [15], the encoded input h is normalized with layer normal-\n",
            "ization [24] and processed by a linear layer (with dimensionality F ).\n",
            "We then create overlapping chunks of size C by chopping up h on\n",
            "the time axis with an overlap factor of 50%. We denote the output of\n",
            "the chunking operation with h(cid:48) ∈ RF ×C×N c, where C is the length\n",
            "of each chunk, and N c is the resulting number of chunks.\n",
            "\n",
            "The representation h(cid:48) feeds the SepFormer block, which is the\n",
            "main component of the masking network. This block, which will be\n",
            "described in detail in Sec. 2.3, employs a pipeline composed of two\n",
            "transformers able to learn short and long-term dependencies.\n",
            "\n",
            "The output of the SepFormer h(cid:48)(cid:48) ∈ RF ×C×N c is processed by\n",
            "PReLU activations followed by a linear layer. We denote the output\n",
            "of this module h(cid:48)(cid:48)(cid:48) ∈ R(F ×N s)×C×N c, where N s is the number of\n",
            "speakers. Afterwards we apply the overlap-add scheme described\n",
            "in [17] and obtain h(cid:48)(cid:48)(cid:48)(cid:48) ∈ RF ×N s×T (cid:48)\n",
            ". We pass this representation\n",
            "through two feed-forward layers and a ReLU activation at the end to\n",
            "ﬁnally obtain the mask mk for each of the speakers.\n",
            "\n",
            "2.3. SepFormer Block\n",
            "\n",
            "Figure 2 (Middle) shows the architecture of the SepFormer block.\n",
            "The SepFormer block is designed to model both short and long-\n",
            "term dependencies with the dual-scale approach of DPRNNs [17].\n",
            "In our model, the transformer block which models the short-term\n",
            "dependencies is named IntraTransformer (IntraT), and the block for\n",
            "longer-term dependencies is named InterTransformer (InterT). In-\n",
            "traT processes the second dimension of h(cid:48), and thus acts on each\n",
            "chunk independently, modeling the short-term dependencies within\n",
            "\n",
            "1speechbrain.github.io/\n",
            "\n",
            "each chunk. Next, we permute the last two dimensions (which we\n",
            "denote with P), and the InterT is applied to model the transitions\n",
            "across chunks. This scheme enables effective modelling of long-\n",
            "term dependencies across the chunks. The overall transformation of\n",
            "the SepFormer is therefore deﬁned as follows:\n",
            "h(cid:48)(cid:48) = finter(P(fintra(h(cid:48)))),\n",
            "\n",
            "(2)\n",
            "\n",
            "where we denote the IntraT and InterT with finter(.), and fintra(.),\n",
            "respectively. The overall SepFormer block is repeated N times.\n",
            "\n",
            "2.3.1. Intra and Inter Transformers\n",
            "\n",
            "Figure 2 (Bottom) shows the architecture of the Transformers used\n",
            "for both the IntraT and InterT blocks. It closely resembles the orig-\n",
            "inal one deﬁned in [4]. We use the variable z to denote the input\n",
            "to the Transformer. First of all, sinusoidal positional encoding e is\n",
            "added to the input z, such that,\n",
            "\n",
            "z(cid:48) = z + e.\n",
            "\n",
            "(3)\n",
            "\n",
            "Positional encoding injects information on the order of the various\n",
            "elements composing the sequence, thus improving the separation\n",
            "performance. We follow the positional encoding deﬁnition in [4].\n",
            "\n",
            "We then apply multiple Transformer layers. Inside each Trans-\n",
            "former layer g(.), we ﬁrst apply layer normalization, followed by\n",
            "multi-head attention (MHA):\n",
            "\n",
            "z(cid:48)(cid:48) = MultiHeadAttention(LayerNorm(z(cid:48))).\n",
            "\n",
            "(4)\n",
            "\n",
            "As proposed in [4], each attention head computes the scaled dot-\n",
            "product attention between all the elements of the sequence. The\n",
            "Transformer ﬁnally employs a feed-forward network (FFW), which\n",
            "is applied to each position independently:\n",
            "\n",
            "z(cid:48)(cid:48)(cid:48) = FeedForward(LayerNorm(z(cid:48)(cid:48) + z(cid:48))) + z(cid:48)(cid:48) + z(cid:48).\n",
            "\n",
            "(5)\n",
            "\n",
            "The overall transformer block is therefore deﬁned as follows:\n",
            "\n",
            "f (z) = gK (z + e) + z,\n",
            "\n",
            "(6)\n",
            "\n",
            "where gK (.) denotes K layers of transformer layer g(.). We use\n",
            "K = N intra layers for the IntraT, and K = N inter layers for the\n",
            "InterT. As shown in Figure 2 (Bottom) and Eq. (6), we add residual\n",
            "connections across the transformer layers, and across the transformer\n",
            "architecture to improve gradient backpropagation.\n",
            "\n",
            "2.4. Decoder\n",
            "\n",
            "The decoder simply uses a transposed convolution layer, with the\n",
            "same stride and kernel size of the encoder. The input to the de-\n",
            "coder is the element-wise multiplication between the mask mk of\n",
            "the source k and the output of the encoder h. The transformation of\n",
            "the decoder can therefore be expressed as follows:\n",
            "\n",
            "(cid:98)sk = conv1d-transpose(mk ∗ h),\n",
            "\n",
            "(7)\n",
            "\n",
            "where (cid:98)sk ∈ RT denotes the separated source k.\n",
            "3. EXPERIMENTAL SETUP\n",
            "\n",
            "3.1. Dataset\n",
            "\n",
            "We use the popular WSJ0-2mix and WSJ0-3mix datasets [11] for\n",
            "source separation, where mixtures of two speakers and three speak-\n",
            "ers are created by randomly mixing utterances in the WSJ0 corpus.\n",
            "The relative levels for the sources are sampled uniformly between 0\n",
            "dB to 5 dB. Respectively, 30, 10, 5 hours of speech is used for train-\n",
            "ing, validation, and test. The training and test sets are created with\n",
            "different sets of speakers. The waveforms are sampled at 8 kHz.\n",
            "\n",
            "\fh\n",
            "\n",
            "Norm+Linear\n",
            "\n",
            "Chunking\n",
            "\n",
            "SepFormer\n",
            "\n",
            "PReLU+Linear\n",
            "\n",
            "OverlapAdd\n",
            "\n",
            "FFW+ReLU\n",
            "\n",
            "h(cid:48)\n",
            "\n",
            "h(cid:48)(cid:48)\n",
            "\n",
            "h(cid:48)(cid:48)(cid:48)\n",
            "\n",
            "m1\n",
            "\n",
            "m2\n",
            "\n",
            "h(cid:48)(cid:48)(cid:48)(cid:48)\n",
            "\n",
            "h(cid:48)(cid:48)\n",
            "\n",
            "h(cid:48)\n",
            "\n",
            "IntraTransformer\n",
            "\n",
            "Permute\n",
            "\n",
            "InterTransformer\n",
            "\n",
            "e\n",
            "\n",
            "z(cid:48)\n",
            "\n",
            "z\n",
            "\n",
            "LayerNorm\n",
            "\n",
            "MHA\n",
            "\n",
            "LayerNorm\n",
            "\n",
            "FFW\n",
            "\n",
            "z(cid:48)(cid:48)(cid:48)\n",
            "\n",
            "f (z)\n",
            "\n",
            "z(cid:48)(cid:48)\n",
            "\n",
            "Repeat N times\n",
            "\n",
            "Repeat K times\n",
            "\n",
            "(Top) The overall architecture proposed for the masking network.\n",
            "\n",
            "Fig. 2.\n",
            "architecture f (.) that is used both in the IntraTransformer block and in the InterTransformer block.\n",
            "\n",
            "(Middle) The SepFormer Block.\n",
            "\n",
            "(Bottom) The transformer\n",
            "\n",
            "3.2. Architecture and Training Details\n",
            "\n",
            "The encoder is based on 256 convolutional ﬁlters with a kernel size\n",
            "of 16 samples and a stride factor of 8 samples. The decoder uses the\n",
            "same kernel size and the stride factors of the encoder.\n",
            "\n",
            "In our best models, the SepFormer masking network processes\n",
            "chunks of size C = 250 with a 50 % overlap between them and\n",
            "employs 8 layers of transformers in both IntraT and InterT. The\n",
            "IntraT-InterT dual-path processing pipeline is repeated N = 2 times.\n",
            "We used 8 parallel attention heads, and 1024-dimensional positional\n",
            "feed-forward networks within each Transformer layer. The model\n",
            "has a total of 26 million parameters.\n",
            "\n",
            "We explored the use of dynamic mixing (DM) data augmenta-\n",
            "tion [23] which consists in on-the-ﬂy creation of new mixtures from\n",
            "single speaker sources. In this work we expanded this powerful tech-\n",
            "nique by applying also speed perturbation on the sources before mix-\n",
            "ing them. The speed randomly changes between 95 % slow-down\n",
            "and 105 % speed-up.\n",
            "\n",
            "We used the Adam algorithm [25] as optimizer, with a learn-\n",
            "ing rate of 15e−5. After epoch 65 (after epoch 100 with DM), the\n",
            "learning rate is annealed by halving it if we do not observe any im-\n",
            "provement of the validation performance for 3 successive epochs\n",
            "(5 epoch for DM). Gradient clipping is employed to limit the L2\n",
            "norm of the gradients to 5. During training, we used a batch size of\n",
            "1, and used the scale-invariant signal-to-noise Ratio (SI-SNR) [26]\n",
            "via utterance-level permutation invariant loss [13], with clipping at\n",
            "30dB [23]. We used automatic mixed-precision to speed up training.\n",
            "The system is trained for a maximum of 200 epochs. Each epoch\n",
            "takes approximately 1.5 hours on a single NVIDIA V100 GPU with\n",
            "32 GB of memory.\n",
            "\n",
            "Table 1. Best results on the WSJ0-2mix dataset (test-set). DM\n",
            "stands for dynamic mixing.\n",
            "\n",
            "# Param Stride\n",
            "\n",
            "Model\n",
            "Tasnet [27]\n",
            "SignPredictionNet [28]\n",
            "ConvTasnet [15]\n",
            "Two-Step CTN [29]\n",
            "DeepCASA [18]\n",
            "FurcaNeXt [19]\n",
            "DualPathRNN [17]\n",
            "sudo rm -rf [21]\n",
            "VSUNOS [20]\n",
            "DPTNet* [22]\n",
            "Wavesplit** [23]\n",
            "Wavesplit** + DM [23]\n",
            "SepFormer\n",
            "SepFormer + DM\n",
            "\n",
            "SI-SNRi\n",
            "10.8\n",
            "15.3\n",
            "15.3\n",
            "16.1\n",
            "17.7\n",
            "n.a.\n",
            "18.8\n",
            "18.9\n",
            "20.1\n",
            "20.2\n",
            "21.0\n",
            "22.2\n",
            "20.4\n",
            "22.3\n",
            "\n",
            "SDRi\n",
            "11.1\n",
            "15.6\n",
            "15.6\n",
            "n.a.\n",
            "18.0\n",
            "18.4\n",
            "19.0\n",
            "n.a.\n",
            "20.4\n",
            "20.6\n",
            "21.2\n",
            "22.3\n",
            "20.5\n",
            "22.4\n",
            "\n",
            "n.a\n",
            "55.2M\n",
            "5.1M\n",
            "8.6M\n",
            "12.8M\n",
            "51.4M\n",
            "2.6M\n",
            "2.6M\n",
            "7.5M\n",
            "2.6M\n",
            "29M\n",
            "29M\n",
            "26M\n",
            "26M\n",
            "\n",
            "20\n",
            "8\n",
            "10\n",
            "10\n",
            "1\n",
            "n.a.\n",
            "1\n",
            "10\n",
            "2\n",
            "1\n",
            "1\n",
            "1\n",
            "8\n",
            "8\n",
            "\n",
            "*only SI-SNR and SDR (without improvement) are reported.\n",
            "**uses speaker-ids as additional info.\n",
            "\n",
            "Table 2. Ablation of the SepFormer on WSJ0-2Mix (validation set).\n",
            "\n",
            "SI-SNRi N N intra N inter\n",
            "\n",
            "22.3\n",
            "20.5\n",
            "20.4\n",
            "20.2\n",
            "19.9\n",
            "19.8\n",
            "19.4\n",
            "19.2\n",
            "19.1\n",
            "19.0\n",
            "\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "\n",
            "8\n",
            "8\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "3\n",
            "3\n",
            "\n",
            "# Heads DFF\n",
            "1024\n",
            "1024\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "2048\n",
            "\n",
            "8\n",
            "8\n",
            "16\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "\n",
            "PosEnc DM\n",
            "Yes\n",
            "No\n",
            "No\n",
            "No\n",
            "No\n",
            "No\n",
            "No\n",
            "No\n",
            "No\n",
            "No\n",
            "\n",
            "Yes\n",
            "Yes\n",
            "Yes\n",
            "Yes\n",
            "Yes\n",
            "Yes\n",
            "No\n",
            "Yes\n",
            "Yes\n",
            "No\n",
            "\n",
            "8\n",
            "8\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "1\n",
            "3\n",
            "3\n",
            "\n",
            "4. RESULTS\n",
            "\n",
            "4.1. Results on WSJ0-2mix\n",
            "\n",
            "4.2. Ablation Study\n",
            "\n",
            "Table 1 compares the performance achieved by the proposed Sep-\n",
            "Former with the best results reported in the literature on the WSJ0-\n",
            "2mix dataset. The SepFormer achieves an SI-SNR improvement (SI-\n",
            "SNRi) of 22.3 dB and a Signal-to-Distortion Ratio [30] (SDRi) im-\n",
            "provement of 22.4 dB on the test-set with dynamic mixing. When\n",
            "using dynamic mixing, the proposed architecture achieves state-of-\n",
            "the-art performance. The SepFormer outperforms previous systems\n",
            "without using dynamic mixing except Wavesplit, which uses speaker\n",
            "identity as additional information.\n",
            "\n",
            "Hereafter we study the effect of various hyperparameters and data\n",
            "augmentation on the performance of the SepFormer using WSJ0-\n",
            "2mix dataset. The results are summarized in Table 2. The reported\n",
            "performance in this table is calculated on the validation set.\n",
            "\n",
            "We observe that the number of InterT and IntraT blocks has an\n",
            "important impact on the performance. The best results are achieved\n",
            "with 8 layers for both blocks replicated two times. We also would\n",
            "like to point out that a respectable performance of 19.2 dB is ob-\n",
            "tained even when we use a single layer transformer for the Inter-\n",
            "\n",
            "\fFig. 3. (Left) The traning curves of SepFormer, DPRNN, and DPTNeT on the WSJ0-2mix dataset. (Middle & Right) The comparison of\n",
            "forward-pass speed and memory usage in the GPU on inputs ranging 1-5 seconds long sampled at 8kHz.\n",
            "\n",
            "Table 3. Best results on the WSJ0-3mix dataset.\n",
            "\n",
            "Model\n",
            "ConvTasnet [15]\n",
            "DualPathRNN [17]\n",
            "VSUNOS [20]\n",
            "Wavesplit [23]\n",
            "Wavesplit [23] + DM\n",
            "Sepformer\n",
            "Sepformer + DM\n",
            "\n",
            "SI-SNRi\n",
            "12.7\n",
            "14.7\n",
            "16.9\n",
            "17.3\n",
            "17.8\n",
            "17.6\n",
            "19.5\n",
            "\n",
            "SDRi\n",
            "13.1\n",
            "n.a\n",
            "n.a\n",
            "17.6\n",
            "18.1\n",
            "17.9\n",
            "19.7\n",
            "\n",
            "# Param\n",
            "5.1M\n",
            "2.6M\n",
            "7.5M\n",
            "29M\n",
            "29M\n",
            "26M\n",
            "26M\n",
            "\n",
            "Transformer. This suggests that the IntraTransformer, and thus lo-\n",
            "cal processing, has a greater inﬂuence on the performance. It also\n",
            "emerges that positional encoding is helpful (e.g. see lines 3 and 5 of\n",
            "Table 2). A similar outcome has been observed in [31] for speech\n",
            "enhancement. As for the number of attention heads, we observe a\n",
            "slight performance difference between 8 and 16 heads. Finally, it\n",
            "can be observed that dynamic mixing helps the performance signiﬁ-\n",
            "cantly.\n",
            "\n",
            "4.3. Results on WSJ0-3mix\n",
            "\n",
            "Table 3 showcases the best performing models on the WSJ0-3mix\n",
            "dataset. SepFormer obtains the state-of-the-art performance with an\n",
            "SI-SNRi of 19.5 dB and an SDRi of 19.7 dB. We used here the best\n",
            "architecture found for the WSJ0-2mix dataset. The only difference is\n",
            "that the decoder has now three outputs. It is worth noting that on this\n",
            "corpus the SepFormer outperforms all previously proposed systems.\n",
            "Our results on WSJ0-2mix and WSJ0-3mix show that it is pos-\n",
            "sible to achieve state-of-the-art performance in separation with an\n",
            "RNN-free Transformer-based model. The big advantage of Sep-\n",
            "Former over RNN-based systems like [17,20,22] is the possibility to\n",
            "parallelize the computations over different time steps. This leads to\n",
            "faster training and inference, as described in the following section.\n",
            "\n",
            "4.4. Speed and Memory Comparison\n",
            "\n",
            "We now compare the training and inference speed of our model with\n",
            "DPRNN [17] and DPTNet [22]. Figure 3 (left) shows the training\n",
            "curves of the aforementioned models on the WSJ0-2mix dataset.\n",
            "We plot the performance achieved on the validation set in the ﬁrst\n",
            "48 hours of training versus the wall-clock time. For a fair com-\n",
            "parison, we used the same machine with the same GPU (a single\n",
            "NVIDIA V100-32GB) for all the models. Moreover, all the systems\n",
            "are trained with a batch size of 1 and employ automatic mixed pre-\n",
            "cision. We observe that the SepFormer is faster than DPRNN and\n",
            "DPTNeT. Figure 3 (left), highlights that SepFormer reaches above\n",
            "17dB levels only after a full day of training, whereas the DPRNN\n",
            "\n",
            "model requires two days of training to achieve the same level of per-\n",
            "formance.\n",
            "\n",
            "Figure 3 (middle&right) compares the average computation time\n",
            "(in ms) and the total memory allocation (in GB) during inference\n",
            "when single precision is used. We analyze the speed of our best\n",
            "model for both WSJ0-2Mix and WSJ0-3Mix datasets. We compare\n",
            "our models against DP-RNN, DPTNeT, and Wavesplit. All the mod-\n",
            "els are stored in the same NVIDIA RTX8000-48GB GPU and we\n",
            "performed this analysis using the PyTorch proﬁler [32]. For Waves-\n",
            "plit we used the implementation in [33].\n",
            "\n",
            "From this analysis, it emerges that the SepFormer is not only\n",
            "faster but also less memory demanding than DPTNet, DPRNN, and\n",
            "Wavesplit. We observed the same behavior using the CPU for infer-\n",
            "ence also. Such a level of computational efﬁciency is achieved even\n",
            "though the proposed SepFormer employs more parameters than the\n",
            "other RNN-based methods (see Table 1). This is not only due to the\n",
            "superior parallelization capabilities of the proposed model, but also\n",
            "because the best performance is achieved with a stride factor of 8\n",
            "samples, against a stride of 1 for DPRNN and DPTNet. Increasing\n",
            "the stride of the encoder results in downsampling the input sequence,\n",
            "and therefore the model processes less data.\n",
            "In [17], the authors\n",
            "showed that the DPRNN performance degrades when increasing the\n",
            "stride factor. The SepFormer, instead, reaches competitive results\n",
            "even with a relatively large stride, leading to the aforementioned\n",
            "speed and memory advantages.\n",
            "\n",
            "5. CONCLUSIONS\n",
            "\n",
            "In this paper, we proposed a novel neural model for speech sepa-\n",
            "ration called SepFormer (Separation Transformer). The SepFormer\n",
            "is an RNN-free architecture that employs a masking network com-\n",
            "posed of transformers only. The masking network learns both short\n",
            "and long-term dependencies using a multi-scale approach. Our re-\n",
            "sults, reported on the WSJ0-2mix and WSJ0-3mix datasets, high-\n",
            "light that we can reach state-of-the-art performances in source sep-\n",
            "aration without using RNNs in the network design. This way, com-\n",
            "putations over different time-steps can be parallelized. Moreover,\n",
            "our model achieves a competitive performance even when subsam-\n",
            "pling the encoded representation by a factor of 8. These two prop-\n",
            "erties lead to a signiﬁcant speed-up at training/inference time and\n",
            "a drastic reduction of memory usage, especially when compared to\n",
            "recent models such as DPRNN, DPTNet, and Wavesplit. As future\n",
            "work, we would like to explore different transformer architectures\n",
            "that could potentially further improve performance, speed, and mem-\n",
            "ory usage.\n",
            "\n",
            "010203040Training time (hours)8101214161820SI-SNRi (dB)Training Speed on WSJ0-2MixSepFormerDP-RNNDPTNet1.02.03.04.05.0Input sequence length in seconds32.055.095.0166.0288.0501.0milisecondsAverage Forward-Pass TimeSepFormerDP-RNNDPTNetWavesplit1.02.03.04.05.0Input sequence length in seconds2.03.06.011.021.040.0GBytesMemory UsageSepFormerDP-RNNDPTNetWavesplit\f6. REFERENCES\n",
            "\n",
            "[1] S. Hochreiter and J. Schmidhuber, “Long short-term memory,”\n",
            "Neural Computation, vol. 9, no. 8, pp. 1735–1780, Nov. 1997.\n",
            "\n",
            "[2] K. Cho, B. van Merri¨enboer, D. Bahdanau, and Y. Bengio, “On\n",
            "the properties of neural machine translation: Encoder–decoder\n",
            "approaches,” in Proc. of SSST, 2014, pp. 103–111.\n",
            "\n",
            "[17] Y. Luo, Z. Chen, and T. Yoshioka,\n",
            "\n",
            "“Dual-path rnn: efﬁ-\n",
            "cient long sequence modeling for time-domain single-channel\n",
            "speech separation,” in Proc. of ICASSP, 2020, pp. 46–50.\n",
            "\n",
            "[18] Y. Liu and D. Wang,\n",
            "\n",
            "“Divide and conquer: A deep casa\n",
            "approach to talker-independent monaural speaker separation,”\n",
            "IEEE/ACM Transactions on audio, speech, and language pro-\n",
            "cessing, vol. 27, no. 12, 2019.\n",
            "\n",
            "[3] M. Ravanelli, P. Brakel, M. Omologo, and Y. Bengio, “Light\n",
            "gated recurrent units for speech recognition,” IEEE Transac-\n",
            "tions on Emerging Topics in Computational Intelligence, vol.\n",
            "2, no. 2, pp. 92–102, April 2018.\n",
            "\n",
            "[19] Z. Shi, H. Lin, L. Liu, R. Liu, J. Han, and A. Shi, “Furcanext:\n",
            "End-to-end monaural speech separation with dynamic gated di-\n",
            "lated temporal convolutional networks,” in MultiMedia Mod-\n",
            "eling, 2020, pp. 653–665.\n",
            "\n",
            "[4] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones,\n",
            "A. N. Gomez, L. Kaiser, and I. Polosukhin, “Attention is all\n",
            "you need,” CoRR, vol. abs/1706.03762, 2017.\n",
            "\n",
            "[20] E. Nachmani, Y. Adi, and L. Wolf, “Voice separation with\n",
            "an unknown number of multiple speakers,” ICML, pp. 7164–\n",
            "7175, 2020.\n",
            "\n",
            "[5] G. Kerg, B. Kanuparthi, A. Goyal, K. Goyette, Y. Bengio, and\n",
            "G. Lajoie, “Untangling tradeoffs between recurrence and self-\n",
            "attention in neural networks,” CoRR, vol. abs/2006.09471,\n",
            "2020.\n",
            "\n",
            "[6] S. Karita, N. Chen, T. Hayashi, T. Hori, H. Inaguma, Z. Jiang,\n",
            "M. Someki, N. E. Y. Soplin, R. Yamamoto, X. Wang, S. Watan-\n",
            "abe, T. Yoshimura, and W. Zhang, “A comparative study on\n",
            "transformer vs rnn in speech applications,” in Proc. of ASRU,\n",
            "2019, pp. 449–456.\n",
            "\n",
            "[7] N. Li, S. Liu, Y. Liu, S. Zhao, and M. Liu, “Neural speech\n",
            "synthesis with transformer network,” in Proc. of AAAI, 2019,\n",
            "pp. 6706–6713.\n",
            "\n",
            "[8] J. Kim, M. El-Khamy, and J. Lee, “T-gsa: Transformer with\n",
            "gaussian-weighted self-attention for speech enhancement,” in\n",
            "Proc. of ICASSP, 2020, pp. 6649–6653.\n",
            "\n",
            "[9] Q. Li, F. L. Kreyssig, C. Zhang, and P. C. Woodland, “Dis-\n",
            "criminative neural clustering for speaker diarisation,” CoRR,\n",
            "vol. abs/1910.09703, 2019.\n",
            "\n",
            "[10] X. Chang, W. Zhang, Y. Qian, J. Le Roux, and S. Watan-\n",
            "abe, “End-to-end multi-speaker speech recognition with trans-\n",
            "former,” in Proc. of ICASSP, 2020, pp. 6134–6138.\n",
            "\n",
            "[11] J. R. Hershey, Z. Chen, J. Le Roux, and S. Watanabe, “Deep\n",
            "clustering: Discriminative embeddings for segmentation and\n",
            "separation,” in Proc. of ICASSP, 2016, pp. 31–35.\n",
            "\n",
            "[12] D. Yu, M. Kolbæk, Z. Tan, and J. Jensen, “Permutation in-\n",
            "variant training of deep models for speaker-independent multi-\n",
            "talker speech separation,” in Proc. of ICASSP, 2017, pp. 241–\n",
            "245.\n",
            "\n",
            "[13] M. Kolbæk, D. Yu, Z.-H. Tan, and J. Jensen,\n",
            "\n",
            "“Multitalker\n",
            "speech separation with utterance-level permutation invariant\n",
            "training of deep recurrent neural networks,” IEEE/ACM Trans-\n",
            "actions on Audio, Speech, and Language Processing, vol. 25,\n",
            "no. 10, pp. 1901–1913, 2017.\n",
            "\n",
            "[21] E. Tzinis, Z. Wang, and P. Smaragdis, “Sudo rm -rf: Efﬁcient\n",
            "in MLSP,\n",
            "\n",
            "networks for universal audio source separation,”\n",
            "2020, pp. 1–6.\n",
            "\n",
            "[22] J. Chen, Q. Mao, and D. Liu,\n",
            "\n",
            "“Dual-Path Transformer\n",
            "Network: Direct Context-Aware Modeling for End-to-End\n",
            "Monaural Speech Separation,” in Proc. of Interspeech 2020,\n",
            "2020, pp. 2642–2646.\n",
            "\n",
            "[23] N. Zeghidour and D. Grangier,\n",
            "\n",
            "speech separation by speaker clustering,”\n",
            "arXiv:2002.08933, 2020.\n",
            "\n",
            "“Wavesplit: End-to-end\n",
            "arXiv preprint\n",
            "\n",
            "[24] L. J. Ba, J. R. Kiros, and G. E. Hinton, “Layer normalization,”\n",
            "\n",
            "CoRR, vol. abs/1607.06450, 2016.\n",
            "\n",
            "[25] D. P. Kingma and J. Ba, “Adam: A method for stochastic opti-\n",
            "\n",
            "mization,” arXiv preprint arXiv:1412.6980, 2014.\n",
            "\n",
            "[26] J. Le Roux, S. Wisdom, H. Erdogan, and J. R. Hershey, “Sdr–\n",
            "half-baked or well done?,” in Proc. of ICASSP. IEEE, 2019,\n",
            "pp. 626–630.\n",
            "\n",
            "[27] Y. Luo and N. Mesgarani, “TasNet: time-domain audio separa-\n",
            "tion network for real-time, single-channel speech separation,”\n",
            "CoRR, vol. abs/1711.00541, 2017.\n",
            "\n",
            "[28] Zhong-Qiu Wang, Ke Tan, and DeLiang Wang, “Deep learning\n",
            "based phase reconstruction for speaker separation: A trigono-\n",
            "metric perspective,” in Proc. of ICASSP, 2019, pp. 71–75.\n",
            "\n",
            "[29] E. Tzinis, S. Venkataramani, Z. Wang, C. Subakan, and\n",
            "P. Smaragdis, “Two-step sound source separation: Training on\n",
            "learned latent targets,” in Proc. of ICASSP, 2020, pp. 31–35.\n",
            "\n",
            "[30] E. Vincent, R. Gribonval, and C F´evotte, “Performance mea-\n",
            "surement in blind audio source separation,” IEEE transactions\n",
            "on audio, speech, and language processing, vol. 14, no. 4, pp.\n",
            "1462–1469, 2006.\n",
            "\n",
            "[31] J. Kim, M. El-Khamy, and J. Lee, “T-gsa: Transformer with\n",
            "gaussian-weighted self-attention for speech enhancement,” in\n",
            "Proc. of ICASSP, 2020, pp. 6649–6653.\n",
            "\n",
            "[14] Shrikant Venkataramani, Jonah Casebeer, and Paris Smaragdis,\n",
            "“End-to-end source separation with adaptive front-ends,” in\n",
            "Proc. of ACSSC, 2018, pp. 684–688.\n",
            "\n",
            "[32] Pytorch,\n",
            "\n",
            "“Proﬁler,”\n",
            "\n",
            "https://pytorch.org/\n",
            "\n",
            "tutorials/recipes/recipes/profiler.html,\n",
            "2020, Accessed: 2020-10-21.\n",
            "\n",
            "[15] Y. Luo and N. Mesgarani, “Conv-TasNet: Surpassing Ideal\n",
            "Time–Frequency Magnitude Masking for Speech Separation,”\n",
            "vol. 27, no. 8, pp. 1256–1266, Aug. 2019.\n",
            "\n",
            "[16] P. Huang, M. Kim, M. Hasegawa-Johnson, and P. Smaragdis,\n",
            "“Deep learning for monoaural source separation,” in Proc. of\n",
            "ICASSP, 2014, pp. 1562–1566.\n",
            "\n",
            "[33] M. Pariente, S. Cornell, J. Cosentino, S. Sivasankaran, E. Tzi-\n",
            "nis, J. Heitkaemper, M. Olvera, F.-R. St¨oter, M. Hu, J. M.\n",
            "Martın-Do˜nas, D. Ditter, A. Frank, A. Deleforge, and E. Vin-\n",
            "cent, “Asteroid: the PyTorch-based audio source separation\n",
            "in Proc. of Interspeech, 2020, pp.\n",
            "toolkit for researchers,”\n",
            "2637–2641.\n",
            "\n",
            "\f\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOiLy7YFv9kp"
      },
      "source": [
        "sentencesweb=sent_tokenize(text)\n",
        "sentencesAtten=sent_tokenize(textatten)"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xH5A2GD350vJ",
        "outputId": "0a0a27f5-681b-46c3-bbc3-6f5f19402b7b"
      },
      "source": [
        "print(sentencesweb)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ATTENTION IS ALL YOU NEED IN SPEECH SEPARATION\\n\\nCem Subakan1, Mirco Ravanelli1, Samuele Cornell2, Mirko Bronzi1, Jianyuan Zhong3\\n\\n1Mila-Quebec AI Institute, Canada,\\n2Universit`a Politecnica delle Marche, Italy\\n3University of Rochester, USA\\n\\n1\\n2\\n0\\n2\\n \\nr\\na\\n\\nM\\n \\n8\\n \\n \\n]\\nS\\nA\\n.', 's\\ns\\ne\\ne\\n[\\n \\n \\n2\\nv\\n4\\n5\\n1\\n3\\n1\\n.', '0\\n1\\n0\\n2\\n:\\nv\\ni\\nX\\nr\\na\\n\\nABSTRACT\\n\\nRecurrent Neural Networks (RNNs) have long been the dominant\\narchitecture in sequence-to-sequence learning.', 'RNNs, however, are\\ninherently sequential models that do not allow parallelization of their\\ncomputations.', 'Transformers are emerging as a natural alternative to\\nstandard RNNs, replacing recurrent computations with a multi-head\\nattention mechanism.', 'In this paper, we propose the SepFormer, a novel RNN-free\\nTransformer-based neural network for speech separation.', 'The Sep-\\nFormer learns short and long-term dependencies with a multi-scale\\napproach that employs transformers.', 'The proposed model achieves\\nstate-of-the-art (SOTA) performance on the standard WSJ0-2/3mix\\ndatasets.', 'It reaches an SI-SNRi of 22.3 dB on WSJ0-2mix and an\\nSI-SNRi of 19.5 dB on WSJ0-3mix.', 'The SepFormer inherits the\\nparallelization advantages of Transformers and achieves a compet-\\nitive performance even when downsampling the encoded represen-\\ntation by a factor of 8.', 'It is thus signiﬁcantly faster and it is less\\nmemory-demanding than the latest speech separation systems with\\ncomparable performance.', 'Index Terms— speech separation, source separation,\\n\\ntrans-\\n\\nformer, attention, deep learning.', '1.', 'INTRODUCTION\\n\\nRNNs are a crucial component of modern audio processing sys-\\ntems and they are used in many different domains, including speech\\nrecognition, synthesis, enhancement, and separation, just to name a\\nfew.', 'Especially when coupled with multiplicative gate mechanisms\\n(like LSTM [1] and GRU [2, 3]), their recurrent connections are es-\\nsential to learn long-term dependencies and properly manage speech\\ncontexts.', 'Nevertheless, the inherently sequential nature of RNNs\\nimpairs an effective parallelization of the computations.', 'This bot-\\ntleneck is particularly evident when processing large datasets with\\nlong sequences.', 'On the other hand, Transformers [4] completely\\navoid this bottleneck by eliminating recurrence and replacing it with\\na fully attention-based mechanism.', 'By attending to the whole se-\\nquence at once, a direct connection can be established between dis-\\ntant elements allowing Transformers to learn long-term dependen-\\ncies more easily [5].', 'For this reason, Transformers are gaining con-\\nsiderable popularity for speech processing and recently showed com-\\npetitive performance in speech recognition [6], synthesis [7], en-\\nhancement [8], diarization [9], as well as speaker recognition [10].', 'Little research has been done so far on Transformer-based mod-\\nels for monaural audio source separation.', 'The ﬁeld has been revo-\\nlutionized by the adoption of deep learning techniques [11–16], and\\nwith recent works [17–23] achieving impressive results by adopt-\\ning an end-to-end approach.', 'Most of the current speech separation\\ntechniques [14, 15, 17–22] require effective modeling of long input\\n\\nx\\n\\nEncoder\\n\\nh Masking Net\\n\\nDecoder\\n\\nˆs1\\n\\nˆs2\\n\\nm1\\n\\nm2\\n\\nFig.', '1.', 'The high-level description of our system: The encoder block\\nestimates a learned-representation for the input signal, while the\\nmasking network estimates optimal masks to separate the sources\\npresent in the mixtures.', 'The decoder ﬁnally reconstructs the esti-\\nmated sources in the time domain using the masks provided by the\\nmasking network.', 'sequences to perform well.', 'Current systems rely, in large part, on the\\nlearned-domain masking strategy popularized by Conv-TasNet [15].', 'In this framework, an overcomplete set of analysis and synthesis ﬁl-\\nters is learned directly from the data, and separation is performed\\nby estimating a mask for each source in this learned-domain.', 'Build-\\ning on this, Dual-Path RNN (DPRNN) [17] has demonstrated that\\nbetter long-term modeling is crucial to improve the separation per-\\nformance.', 'This is achieved by splitting the input sequence into mul-\\ntiple chunks that are processed locally and globally with different\\nRNNs.', 'Nevertheless, due to the use of RNNs, DPRNN still suffers\\nfrom the aforementioned limitations of recurrent connections, espe-\\ncially regarding the global processing step.', 'An attempt to integrate\\ntransformers into the speech separation pipeline has been recently\\ndone in [22] where the proposed Dual-Path Transformer Network\\n(DPTNet) is shown to outperform the standard DPRNN.', 'Such an ar-\\nchitecture, however, still embeds an RNN, effectively negating the\\nparallelization capability of pure-attention models.', 'In this paper, we propose a novel model called SepFormer (Sep-\\naration Transformer), which is mainly composed of multi-head at-\\ntention and feed-forward layers.', 'We adopt the dual-path frame-\\nwork introduced by DPRNN and we replace RNNs with a multi-\\nscale pipeline composed of transformers that learn both short and\\nlong-term dependencies.', 'The dual-path framework enables to miti-\\ngate the quadratic complexity of transformers, as transformers in the\\ndual-path framework process smaller chunks.', 'To the best of our knowledge, this is the ﬁrst work showing\\nthat we can obtain state-of-the-art performance in separation with an\\nRNN-free Transformer-based architecture.', 'The SepFormer achieves\\nan SI-SNRi of 22.3 dB on the standard WSJ0-2mix dataset.', 'It also\\nachieves the SOTA performance of 19.5 dB SI-SNRi on the WSJ0-\\n3mix dataset.', 'The SepFormer not only processes all the time steps in\\nparallel but also achieves competitive performance when downsam-\\npling the encoded representation by a factor of 8.', 'This makes the\\nproposed architecture signiﬁcantly faster and less memory demand-\\n\\n\\x0cing than the latest RNN-based separation models.', '2.', 'THE MODEL\\n\\nThe proposed model is based on the learned-domain masking ap-\\nproach [14, 15, 17–22] and employs an encoder, a decoder, and a\\nmasking network, as shown in Figure 1.', 'The encoder is fully con-\\nvolutional, while the masking network employs two Transformers\\nembedded inside the dual-path processing block proposed in [17].', 'The decoder ﬁnally reconstructs the separated signals in the time\\ndomain by using the masks predicted by the masking network.', 'To\\nfoster reproducibility, the SepFormer will be made available within\\nthe SpeechBrain toolkit1.', '2.1.', 'Encoder\\n\\nThe encoder takes in the time-domain mixture-signal x ∈ RT as\\ninput, which contains audio from multiple speakers.', 'It learns an\\nSTFT-like representation h ∈ RF ×T (cid:48)\\nusing a single convolutional\\nlayer:\\n\\nh = ReLU(conv1d(x)).', '(1)\\n\\nAs we will describe in Sec.', '4, the stride factor of this convolution\\nimpacts signiﬁcantly on the performance, speed, and memory of the\\nmodel.', '2.2.', 'Masking Network\\n\\nFigure 2 (top) shows the detailed architecture of the masking net-\\nwork (Masking Net).', 'The masking network is fed by the encoded\\nrepresentations h ∈ RF ×T (cid:48)\\nand estimates a mask {m1, .', '.', '.', ', mN s}\\nfor each of the N s speakers in the mixture.', 'As in [15], the encoded input h is normalized with layer normal-\\nization [24] and processed by a linear layer (with dimensionality F ).', 'We then create overlapping chunks of size C by chopping up h on\\nthe time axis with an overlap factor of 50%.', 'We denote the output of\\nthe chunking operation with h(cid:48) ∈ RF ×C×N c, where C is the length\\nof each chunk, and N c is the resulting number of chunks.', 'The representation h(cid:48) feeds the SepFormer block, which is the\\nmain component of the masking network.', 'This block, which will be\\ndescribed in detail in Sec.', '2.3, employs a pipeline composed of two\\ntransformers able to learn short and long-term dependencies.', 'The output of the SepFormer h(cid:48)(cid:48) ∈ RF ×C×N c is processed by\\nPReLU activations followed by a linear layer.', 'We denote the output\\nof this module h(cid:48)(cid:48)(cid:48) ∈ R(F ×N s)×C×N c, where N s is the number of\\nspeakers.', 'Afterwards we apply the overlap-add scheme described\\nin [17] and obtain h(cid:48)(cid:48)(cid:48)(cid:48) ∈ RF ×N s×T (cid:48)\\n.', 'We pass this representation\\nthrough two feed-forward layers and a ReLU activation at the end to\\nﬁnally obtain the mask mk for each of the speakers.', '2.3.', 'SepFormer Block\\n\\nFigure 2 (Middle) shows the architecture of the SepFormer block.', 'The SepFormer block is designed to model both short and long-\\nterm dependencies with the dual-scale approach of DPRNNs [17].', 'In our model, the transformer block which models the short-term\\ndependencies is named IntraTransformer (IntraT), and the block for\\nlonger-term dependencies is named InterTransformer (InterT).', 'In-\\ntraT processes the second dimension of h(cid:48), and thus acts on each\\nchunk independently, modeling the short-term dependencies within\\n\\n1speechbrain.github.io/\\n\\neach chunk.', 'Next, we permute the last two dimensions (which we\\ndenote with P), and the InterT is applied to model the transitions\\nacross chunks.', 'This scheme enables effective modelling of long-\\nterm dependencies across the chunks.', 'The overall transformation of\\nthe SepFormer is therefore deﬁned as follows:\\nh(cid:48)(cid:48) = finter(P(fintra(h(cid:48)))),\\n\\n(2)\\n\\nwhere we denote the IntraT and InterT with finter(.', '), and fintra(.', '),\\nrespectively.', 'The overall SepFormer block is repeated N times.', '2.3.1.', 'Intra and Inter Transformers\\n\\nFigure 2 (Bottom) shows the architecture of the Transformers used\\nfor both the IntraT and InterT blocks.', 'It closely resembles the orig-\\ninal one deﬁned in [4].', 'We use the variable z to denote the input\\nto the Transformer.', 'First of all, sinusoidal positional encoding e is\\nadded to the input z, such that,\\n\\nz(cid:48) = z + e.\\n\\n(3)\\n\\nPositional encoding injects information on the order of the various\\nelements composing the sequence, thus improving the separation\\nperformance.', 'We follow the positional encoding deﬁnition in [4].', 'We then apply multiple Transformer layers.', 'Inside each Trans-\\nformer layer g(.', '), we ﬁrst apply layer normalization, followed by\\nmulti-head attention (MHA):\\n\\nz(cid:48)(cid:48) = MultiHeadAttention(LayerNorm(z(cid:48))).', '(4)\\n\\nAs proposed in [4], each attention head computes the scaled dot-\\nproduct attention between all the elements of the sequence.', 'The\\nTransformer ﬁnally employs a feed-forward network (FFW), which\\nis applied to each position independently:\\n\\nz(cid:48)(cid:48)(cid:48) = FeedForward(LayerNorm(z(cid:48)(cid:48) + z(cid:48))) + z(cid:48)(cid:48) + z(cid:48).', '(5)\\n\\nThe overall transformer block is therefore deﬁned as follows:\\n\\nf (z) = gK (z + e) + z,\\n\\n(6)\\n\\nwhere gK (.)', 'denotes K layers of transformer layer g(.).', 'We use\\nK = N intra layers for the IntraT, and K = N inter layers for the\\nInterT.', 'As shown in Figure 2 (Bottom) and Eq.', '(6), we add residual\\nconnections across the transformer layers, and across the transformer\\narchitecture to improve gradient backpropagation.', '2.4.', 'Decoder\\n\\nThe decoder simply uses a transposed convolution layer, with the\\nsame stride and kernel size of the encoder.', 'The input to the de-\\ncoder is the element-wise multiplication between the mask mk of\\nthe source k and the output of the encoder h. The transformation of\\nthe decoder can therefore be expressed as follows:\\n\\n(cid:98)sk = conv1d-transpose(mk ∗ h),\\n\\n(7)\\n\\nwhere (cid:98)sk ∈ RT denotes the separated source k.\\n3.', 'EXPERIMENTAL SETUP\\n\\n3.1.', 'Dataset\\n\\nWe use the popular WSJ0-2mix and WSJ0-3mix datasets [11] for\\nsource separation, where mixtures of two speakers and three speak-\\ners are created by randomly mixing utterances in the WSJ0 corpus.', 'The relative levels for the sources are sampled uniformly between 0\\ndB to 5 dB.', 'Respectively, 30, 10, 5 hours of speech is used for train-\\ning, validation, and test.', 'The training and test sets are created with\\ndifferent sets of speakers.', 'The waveforms are sampled at 8 kHz.', 'h\\n\\nNorm+Linear\\n\\nChunking\\n\\nSepFormer\\n\\nPReLU+Linear\\n\\nOverlapAdd\\n\\nFFW+ReLU\\n\\nh(cid:48)\\n\\nh(cid:48)(cid:48)\\n\\nh(cid:48)(cid:48)(cid:48)\\n\\nm1\\n\\nm2\\n\\nh(cid:48)(cid:48)(cid:48)(cid:48)\\n\\nh(cid:48)(cid:48)\\n\\nh(cid:48)\\n\\nIntraTransformer\\n\\nPermute\\n\\nInterTransformer\\n\\ne\\n\\nz(cid:48)\\n\\nz\\n\\nLayerNorm\\n\\nMHA\\n\\nLayerNorm\\n\\nFFW\\n\\nz(cid:48)(cid:48)(cid:48)\\n\\nf (z)\\n\\nz(cid:48)(cid:48)\\n\\nRepeat N times\\n\\nRepeat K times\\n\\n(Top) The overall architecture proposed for the masking network.', 'Fig.', '2.\\narchitecture f (.)', 'that is used both in the IntraTransformer block and in the InterTransformer block.', '(Middle) The SepFormer Block.', '(Bottom) The transformer\\n\\n3.2.', 'Architecture and Training Details\\n\\nThe encoder is based on 256 convolutional ﬁlters with a kernel size\\nof 16 samples and a stride factor of 8 samples.', 'The decoder uses the\\nsame kernel size and the stride factors of the encoder.', 'In our best models, the SepFormer masking network processes\\nchunks of size C = 250 with a 50 % overlap between them and\\nemploys 8 layers of transformers in both IntraT and InterT.', 'The\\nIntraT-InterT dual-path processing pipeline is repeated N = 2 times.', 'We used 8 parallel attention heads, and 1024-dimensional positional\\nfeed-forward networks within each Transformer layer.', 'The model\\nhas a total of 26 million parameters.', 'We explored the use of dynamic mixing (DM) data augmenta-\\ntion [23] which consists in on-the-ﬂy creation of new mixtures from\\nsingle speaker sources.', 'In this work we expanded this powerful tech-\\nnique by applying also speed perturbation on the sources before mix-\\ning them.', 'The speed randomly changes between 95 % slow-down\\nand 105 % speed-up.', 'We used the Adam algorithm [25] as optimizer, with a learn-\\ning rate of 15e−5.', 'After epoch 65 (after epoch 100 with DM), the\\nlearning rate is annealed by halving it if we do not observe any im-\\nprovement of the validation performance for 3 successive epochs\\n(5 epoch for DM).', 'Gradient clipping is employed to limit the L2\\nnorm of the gradients to 5.', 'During training, we used a batch size of\\n1, and used the scale-invariant signal-to-noise Ratio (SI-SNR) [26]\\nvia utterance-level permutation invariant loss [13], with clipping at\\n30dB [23].', 'We used automatic mixed-precision to speed up training.', 'The system is trained for a maximum of 200 epochs.', 'Each epoch\\ntakes approximately 1.5 hours on a single NVIDIA V100 GPU with\\n32 GB of memory.', 'Table 1.', 'Best results on the WSJ0-2mix dataset (test-set).', 'DM\\nstands for dynamic mixing.', '# Param Stride\\n\\nModel\\nTasnet [27]\\nSignPredictionNet [28]\\nConvTasnet [15]\\nTwo-Step CTN [29]\\nDeepCASA [18]\\nFurcaNeXt [19]\\nDualPathRNN [17]\\nsudo rm -rf [21]\\nVSUNOS [20]\\nDPTNet* [22]\\nWavesplit** [23]\\nWavesplit** + DM [23]\\nSepFormer\\nSepFormer + DM\\n\\nSI-SNRi\\n10.8\\n15.3\\n15.3\\n16.1\\n17.7\\nn.a.', '18.8\\n18.9\\n20.1\\n20.2\\n21.0\\n22.2\\n20.4\\n22.3\\n\\nSDRi\\n11.1\\n15.6\\n15.6\\nn.a.', '18.0\\n18.4\\n19.0\\nn.a.', '20.4\\n20.6\\n21.2\\n22.3\\n20.5\\n22.4\\n\\nn.a\\n55.2M\\n5.1M\\n8.6M\\n12.8M\\n51.4M\\n2.6M\\n2.6M\\n7.5M\\n2.6M\\n29M\\n29M\\n26M\\n26M\\n\\n20\\n8\\n10\\n10\\n1\\nn.a.', '1\\n10\\n2\\n1\\n1\\n1\\n8\\n8\\n\\n*only SI-SNR and SDR (without improvement) are reported.', '**uses speaker-ids as additional info.', 'Table 2.', 'Ablation of the SepFormer on WSJ0-2Mix (validation set).', 'SI-SNRi N N intra N inter\\n\\n22.3\\n20.5\\n20.4\\n20.2\\n19.9\\n19.8\\n19.4\\n19.2\\n19.1\\n19.0\\n\\n2\\n2\\n2\\n2\\n2\\n3\\n2\\n2\\n2\\n2\\n\\n8\\n8\\n4\\n4\\n4\\n4\\n4\\n4\\n3\\n3\\n\\n# Heads DFF\\n1024\\n1024\\n2048\\n2048\\n2048\\n2048\\n2048\\n2048\\n2048\\n2048\\n\\n8\\n8\\n16\\n8\\n8\\n8\\n8\\n8\\n8\\n8\\n\\nPosEnc DM\\nYes\\nNo\\nNo\\nNo\\nNo\\nNo\\nNo\\nNo\\nNo\\nNo\\n\\nYes\\nYes\\nYes\\nYes\\nYes\\nYes\\nNo\\nYes\\nYes\\nNo\\n\\n8\\n8\\n4\\n4\\n4\\n4\\n4\\n1\\n3\\n3\\n\\n4.', 'RESULTS\\n\\n4.1.', 'Results on WSJ0-2mix\\n\\n4.2.', 'Ablation Study\\n\\nTable 1 compares the performance achieved by the proposed Sep-\\nFormer with the best results reported in the literature on the WSJ0-\\n2mix dataset.', 'The SepFormer achieves an SI-SNR improvement (SI-\\nSNRi) of 22.3 dB and a Signal-to-Distortion Ratio [30] (SDRi) im-\\nprovement of 22.4 dB on the test-set with dynamic mixing.', 'When\\nusing dynamic mixing, the proposed architecture achieves state-of-\\nthe-art performance.', 'The SepFormer outperforms previous systems\\nwithout using dynamic mixing except Wavesplit, which uses speaker\\nidentity as additional information.', 'Hereafter we study the effect of various hyperparameters and data\\naugmentation on the performance of the SepFormer using WSJ0-\\n2mix dataset.', 'The results are summarized in Table 2.', 'The reported\\nperformance in this table is calculated on the validation set.', 'We observe that the number of InterT and IntraT blocks has an\\nimportant impact on the performance.', 'The best results are achieved\\nwith 8 layers for both blocks replicated two times.', 'We also would\\nlike to point out that a respectable performance of 19.2 dB is ob-\\ntained even when we use a single layer transformer for the Inter-\\n\\n\\x0cFig.', '3.', '(Left) The traning curves of SepFormer, DPRNN, and DPTNeT on the WSJ0-2mix dataset.', '(Middle & Right) The comparison of\\nforward-pass speed and memory usage in the GPU on inputs ranging 1-5 seconds long sampled at 8kHz.', 'Table 3.', 'Best results on the WSJ0-3mix dataset.', 'Model\\nConvTasnet [15]\\nDualPathRNN [17]\\nVSUNOS [20]\\nWavesplit [23]\\nWavesplit [23] + DM\\nSepformer\\nSepformer + DM\\n\\nSI-SNRi\\n12.7\\n14.7\\n16.9\\n17.3\\n17.8\\n17.6\\n19.5\\n\\nSDRi\\n13.1\\nn.a\\nn.a\\n17.6\\n18.1\\n17.9\\n19.7\\n\\n# Param\\n5.1M\\n2.6M\\n7.5M\\n29M\\n29M\\n26M\\n26M\\n\\nTransformer.', 'This suggests that the IntraTransformer, and thus lo-\\ncal processing, has a greater inﬂuence on the performance.', 'It also\\nemerges that positional encoding is helpful (e.g. see lines 3 and 5 of\\nTable 2).', 'A similar outcome has been observed in [31] for speech\\nenhancement.', 'As for the number of attention heads, we observe a\\nslight performance difference between 8 and 16 heads.', 'Finally, it\\ncan be observed that dynamic mixing helps the performance signiﬁ-\\ncantly.', '4.3.', 'Results on WSJ0-3mix\\n\\nTable 3 showcases the best performing models on the WSJ0-3mix\\ndataset.', 'SepFormer obtains the state-of-the-art performance with an\\nSI-SNRi of 19.5 dB and an SDRi of 19.7 dB.', 'We used here the best\\narchitecture found for the WSJ0-2mix dataset.', 'The only difference is\\nthat the decoder has now three outputs.', 'It is worth noting that on this\\ncorpus the SepFormer outperforms all previously proposed systems.', 'Our results on WSJ0-2mix and WSJ0-3mix show that it is pos-\\nsible to achieve state-of-the-art performance in separation with an\\nRNN-free Transformer-based model.', 'The big advantage of Sep-\\nFormer over RNN-based systems like [17,20,22] is the possibility to\\nparallelize the computations over different time steps.', 'This leads to\\nfaster training and inference, as described in the following section.', '4.4.', 'Speed and Memory Comparison\\n\\nWe now compare the training and inference speed of our model with\\nDPRNN [17] and DPTNet [22].', 'Figure 3 (left) shows the training\\ncurves of the aforementioned models on the WSJ0-2mix dataset.', 'We plot the performance achieved on the validation set in the ﬁrst\\n48 hours of training versus the wall-clock time.', 'For a fair com-\\nparison, we used the same machine with the same GPU (a single\\nNVIDIA V100-32GB) for all the models.', 'Moreover, all the systems\\nare trained with a batch size of 1 and employ automatic mixed pre-\\ncision.', 'We observe that the SepFormer is faster than DPRNN and\\nDPTNeT.', 'Figure 3 (left), highlights that SepFormer reaches above\\n17dB levels only after a full day of training, whereas the DPRNN\\n\\nmodel requires two days of training to achieve the same level of per-\\nformance.', 'Figure 3 (middle&right) compares the average computation time\\n(in ms) and the total memory allocation (in GB) during inference\\nwhen single precision is used.', 'We analyze the speed of our best\\nmodel for both WSJ0-2Mix and WSJ0-3Mix datasets.', 'We compare\\nour models against DP-RNN, DPTNeT, and Wavesplit.', 'All the mod-\\nels are stored in the same NVIDIA RTX8000-48GB GPU and we\\nperformed this analysis using the PyTorch proﬁler [32].', 'For Waves-\\nplit we used the implementation in [33].', 'From this analysis, it emerges that the SepFormer is not only\\nfaster but also less memory demanding than DPTNet, DPRNN, and\\nWavesplit.', 'We observed the same behavior using the CPU for infer-\\nence also.', 'Such a level of computational efﬁciency is achieved even\\nthough the proposed SepFormer employs more parameters than the\\nother RNN-based methods (see Table 1).', 'This is not only due to the\\nsuperior parallelization capabilities of the proposed model, but also\\nbecause the best performance is achieved with a stride factor of 8\\nsamples, against a stride of 1 for DPRNN and DPTNet.', 'Increasing\\nthe stride of the encoder results in downsampling the input sequence,\\nand therefore the model processes less data.', 'In [17], the authors\\nshowed that the DPRNN performance degrades when increasing the\\nstride factor.', 'The SepFormer, instead, reaches competitive results\\neven with a relatively large stride, leading to the aforementioned\\nspeed and memory advantages.', '5.', 'CONCLUSIONS\\n\\nIn this paper, we proposed a novel neural model for speech sepa-\\nration called SepFormer (Separation Transformer).', 'The SepFormer\\nis an RNN-free architecture that employs a masking network com-\\nposed of transformers only.', 'The masking network learns both short\\nand long-term dependencies using a multi-scale approach.', 'Our re-\\nsults, reported on the WSJ0-2mix and WSJ0-3mix datasets, high-\\nlight that we can reach state-of-the-art performances in source sep-\\naration without using RNNs in the network design.', 'This way, com-\\nputations over different time-steps can be parallelized.', 'Moreover,\\nour model achieves a competitive performance even when subsam-\\npling the encoded representation by a factor of 8.', 'These two prop-\\nerties lead to a signiﬁcant speed-up at training/inference time and\\na drastic reduction of memory usage, especially when compared to\\nrecent models such as DPRNN, DPTNet, and Wavesplit.', 'As future\\nwork, we would like to explore different transformer architectures\\nthat could potentially further improve performance, speed, and mem-\\nory usage.', '010203040Training time (hours)8101214161820SI-SNRi (dB)Training Speed on WSJ0-2MixSepFormerDP-RNNDPTNet1.02.03.04.05.0Input sequence length in seconds32.055.095.0166.0288.0501.0milisecondsAverage Forward-Pass TimeSepFormerDP-RNNDPTNetWavesplit1.02.03.04.05.0Input sequence length in seconds2.03.06.011.021.040.0GBytesMemory UsageSepFormerDP-RNNDPTNetWavesplit\\x0c6.', 'REFERENCES\\n\\n[1] S. Hochreiter and J. Schmidhuber, “Long short-term memory,”\\nNeural Computation, vol.', '9, no.', '8, pp.', '1735–1780, Nov. 1997.', '[2] K. Cho, B. van Merri¨enboer, D. Bahdanau, and Y. Bengio, “On\\nthe properties of neural machine translation: Encoder–decoder\\napproaches,” in Proc.', 'of SSST, 2014, pp.', '103–111.', '[17] Y. Luo, Z. Chen, and T. Yoshioka,\\n\\n“Dual-path rnn: efﬁ-\\ncient long sequence modeling for time-domain single-channel\\nspeech separation,” in Proc.', 'of ICASSP, 2020, pp.', '46–50.', '[18] Y. Liu and D. Wang,\\n\\n“Divide and conquer: A deep casa\\napproach to talker-independent monaural speaker separation,”\\nIEEE/ACM Transactions on audio, speech, and language pro-\\ncessing, vol.', '27, no.', '12, 2019.', '[3] M. Ravanelli, P. Brakel, M. Omologo, and Y. Bengio, “Light\\ngated recurrent units for speech recognition,” IEEE Transac-\\ntions on Emerging Topics in Computational Intelligence, vol.', '2, no.', '2, pp.', '92–102, April 2018.', '[19] Z. Shi, H. Lin, L. Liu, R. Liu, J. Han, and A. Shi, “Furcanext:\\nEnd-to-end monaural speech separation with dynamic gated di-\\nlated temporal convolutional networks,” in MultiMedia Mod-\\neling, 2020, pp.', '653–665.', '[4] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones,\\nA. N. Gomez, L. Kaiser, and I. Polosukhin, “Attention is all\\nyou need,” CoRR, vol.', 'abs/1706.03762, 2017.', '[20] E. Nachmani, Y. Adi, and L. Wolf, “Voice separation with\\nan unknown number of multiple speakers,” ICML, pp.', '7164–\\n7175, 2020.', '[5] G. Kerg, B. Kanuparthi, A. Goyal, K. Goyette, Y. Bengio, and\\nG. Lajoie, “Untangling tradeoffs between recurrence and self-\\nattention in neural networks,” CoRR, vol.', 'abs/2006.09471,\\n2020.', '[6] S. Karita, N. Chen, T. Hayashi, T. Hori, H. Inaguma, Z. Jiang,\\nM. Someki, N. E. Y. Soplin, R. Yamamoto, X. Wang, S. Watan-\\nabe, T. Yoshimura, and W. Zhang, “A comparative study on\\ntransformer vs rnn in speech applications,” in Proc.', 'of ASRU,\\n2019, pp.', '449–456.', '[7] N. Li, S. Liu, Y. Liu, S. Zhao, and M. Liu, “Neural speech\\nsynthesis with transformer network,” in Proc.', 'of AAAI, 2019,\\npp.', '6706–6713.', '[8] J. Kim, M. El-Khamy, and J. Lee, “T-gsa: Transformer with\\ngaussian-weighted self-attention for speech enhancement,” in\\nProc.', 'of ICASSP, 2020, pp.', '6649–6653.', '[9] Q. Li, F. L. Kreyssig, C. Zhang, and P. C. Woodland, “Dis-\\ncriminative neural clustering for speaker diarisation,” CoRR,\\nvol.', 'abs/1910.09703, 2019.', '[10] X. Chang, W. Zhang, Y. Qian, J.', 'Le Roux, and S. Watan-\\nabe, “End-to-end multi-speaker speech recognition with trans-\\nformer,” in Proc.', 'of ICASSP, 2020, pp.', '6134–6138.', '[11] J. R. Hershey, Z. Chen, J.', 'Le Roux, and S. Watanabe, “Deep\\nclustering: Discriminative embeddings for segmentation and\\nseparation,” in Proc.', 'of ICASSP, 2016, pp.', '31–35.', '[12] D. Yu, M. Kolbæk, Z. Tan, and J. Jensen, “Permutation in-\\nvariant training of deep models for speaker-independent multi-\\ntalker speech separation,” in Proc.', 'of ICASSP, 2017, pp.', '241–\\n245.', '[13] M. Kolbæk, D. Yu, Z.-H. Tan, and J. Jensen,\\n\\n“Multitalker\\nspeech separation with utterance-level permutation invariant\\ntraining of deep recurrent neural networks,” IEEE/ACM Trans-\\nactions on Audio, Speech, and Language Processing, vol.', '25,\\nno.', '10, pp.', '1901–1913, 2017.', '[21] E. Tzinis, Z. Wang, and P. Smaragdis, “Sudo rm -rf: Efﬁcient\\nin MLSP,\\n\\nnetworks for universal audio source separation,”\\n2020, pp.', '1–6.', '[22] J. Chen, Q. Mao, and D. Liu,\\n\\n“Dual-Path Transformer\\nNetwork: Direct Context-Aware Modeling for End-to-End\\nMonaural Speech Separation,” in Proc.', 'of Interspeech 2020,\\n2020, pp.', '2642–2646.', '[23] N. Zeghidour and D. Grangier,\\n\\nspeech separation by speaker clustering,”\\narXiv:2002.08933, 2020.', '“Wavesplit: End-to-end\\narXiv preprint\\n\\n[24] L. J. Ba, J. R. Kiros, and G. E. Hinton, “Layer normalization,”\\n\\nCoRR, vol.', 'abs/1607.06450, 2016.', '[25] D. P. Kingma and J. Ba, “Adam: A method for stochastic opti-\\n\\nmization,” arXiv preprint arXiv:1412.6980, 2014.', '[26] J.', 'Le Roux, S. Wisdom, H. Erdogan, and J. R. Hershey, “Sdr–\\nhalf-baked or well done?,” in Proc.', 'of ICASSP.', 'IEEE, 2019,\\npp.', '626–630.', '[27] Y. Luo and N. Mesgarani, “TasNet: time-domain audio separa-\\ntion network for real-time, single-channel speech separation,”\\nCoRR, vol.', 'abs/1711.00541, 2017.', '[28] Zhong-Qiu Wang, Ke Tan, and DeLiang Wang, “Deep learning\\nbased phase reconstruction for speaker separation: A trigono-\\nmetric perspective,” in Proc.', 'of ICASSP, 2019, pp.', '71–75.', '[29] E. Tzinis, S. Venkataramani, Z. Wang, C. Subakan, and\\nP. Smaragdis, “Two-step sound source separation: Training on\\nlearned latent targets,” in Proc.', 'of ICASSP, 2020, pp.', '31–35.', '[30] E. Vincent, R. Gribonval, and C F´evotte, “Performance mea-\\nsurement in blind audio source separation,” IEEE transactions\\non audio, speech, and language processing, vol.', '14, no.', '4, pp.', '1462–1469, 2006.', '[31] J. Kim, M. El-Khamy, and J. Lee, “T-gsa: Transformer with\\ngaussian-weighted self-attention for speech enhancement,” in\\nProc.', 'of ICASSP, 2020, pp.', '6649–6653.', '[14] Shrikant Venkataramani, Jonah Casebeer, and Paris Smaragdis,\\n“End-to-end source separation with adaptive front-ends,” in\\nProc.', 'of ACSSC, 2018, pp.', '684–688.', '[32] Pytorch,\\n\\n“Proﬁler,”\\n\\nhttps://pytorch.org/\\n\\ntutorials/recipes/recipes/profiler.html,\\n2020, Accessed: 2020-10-21.', '[15] Y. Luo and N. Mesgarani, “Conv-TasNet: Surpassing Ideal\\nTime–Frequency Magnitude Masking for Speech Separation,”\\nvol.', '27, no.', '8, pp.', '1256–1266, Aug. 2019.', '[16] P. Huang, M. Kim, M. Hasegawa-Johnson, and P. Smaragdis,\\n“Deep learning for monoaural source separation,” in Proc.', 'of\\nICASSP, 2014, pp.', '1562–1566.', '[33] M. Pariente, S. Cornell, J. Cosentino, S. Sivasankaran, E. Tzi-\\nnis, J. Heitkaemper, M. Olvera, F.-R. St¨oter, M. Hu, J. M.\\nMartın-Do˜nas, D. Ditter, A. Frank, A. Deleforge, and E. Vin-\\ncent, “Asteroid: the PyTorch-based audio source separation\\nin Proc.', 'of Interspeech, 2020, pp.', 'toolkit for researchers,”\\n2637–2641.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iR5KqpF2uzUn"
      },
      "source": [
        "documents_df=pd.DataFrame(sentencesweb,columns=['documents'])"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "Ls65aqLoDf5U",
        "outputId": "d8ae6c54-00e7-4d93-9408-05a769a720ae"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "sbert_model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
        "\n",
        "document_embeddings = sbert_model.encode(sentencesweb)\n",
        "#print(document_embeddings)\n",
        "pairwise_similarities=cosine_similarity(document_embeddings)\n",
        "#print(pairwise_similarities)\n",
        "similar_ix=np.argsort(pairwise_similarities[::-1]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-24-364f7c2ea814>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    similar_ix=np.argsort(pairwise_similarities[::-1]\u001b[0m\n\u001b[0m                                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131,
          "referenced_widgets": [
            "8cb4b8a8f9e64b94adcc5675ea556f48",
            "32e98649934640859d11df01e182829d",
            "63ab6051d75d4cd2898407bb32a93e34",
            "833d8f986ccd485ebf4a0def86a099a6",
            "b65ceceddf3647c798cface1e98fa620",
            "d7f75f7053d947b3bf1f236ac6cf7271",
            "684c9a81a0bd4ddb84d9732e6963a27b",
            "6d13346dca844ae38980e1d01fe89bd3",
            "b02592260d6f41a6a6fe80570f6dd0a3",
            "dde96f294879489e97d19bc9b9c8ad33",
            "277b6896d01e4bb3a39a32925c839829",
            "6014ea82f50e4e479f1c2ca61717a042",
            "be1d644ca4af49189fec51fc97669bf3",
            "cd2ac71758444f949c6cfbf86920cc1a",
            "e9c6f2c567274fc39246e1efdeb3521e",
            "dddbf1a986b246539757c1c8211f23b4"
          ]
        },
        "id": "L08DHMe9pQ88",
        "outputId": "b1c64f63-aee9-48ac-b453-6bad7d203cd1"
      },
      "source": [
        "model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
        "text_embeddings = model.encode(sentencesweb, batch_size = 8, show_progress_bar = True)\n",
        "text_embeddings2 = model.encode(sentencesAtten, batch_size = 8, show_progress_bar = True)\n",
        "np.shape(text_embeddings)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8cb4b8a8f9e64b94adcc5675ea556f48",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Batches', max=37.0, style=ProgressStyle(description_width…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b02592260d6f41a6a6fe80570f6dd0a3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Batches', max=37.0, style=ProgressStyle(description_width…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(294, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kPixbiot6aE"
      },
      "source": [
        "similarities = cosine_similarity(text_embeddings,text_embeddings2)"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V58UfPBmwXsR"
      },
      "source": [
        "similarities_sorted = similarities.argsort()"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdVL8K1Rwdmx"
      },
      "source": [
        "# Get list of similarity indices i.e. doc at index 0 simialr with doc at index 1169 below.\n",
        "id_1 = []\n",
        "id_2 = []\n",
        "score = []\n",
        "for index,array in enumerate(similarities_sorted):\n",
        "    id_1.append(index)\n",
        "    id_2.append(array[-2])\n",
        "    score.append(similarities[index][array[-2]])"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utcpl9Whwkfi"
      },
      "source": [
        "index_df = pd.DataFrame({'id_1' : id_1,\n",
        "                          'id_2' : id_2,\n",
        "                          'score' : score})"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "cjHF4uiswpwW",
        "outputId": "4c5a00e6-eeb5-4ca5-b483-6ed15f8e2bb8"
      },
      "source": [
        "index_df"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id_1</th>\n",
              "      <th>id_2</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>210</td>\n",
              "      <td>0.649880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>136</td>\n",
              "      <td>0.746824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>19</td>\n",
              "      <td>0.705024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>0.882654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>33</td>\n",
              "      <td>0.785237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>289</th>\n",
              "      <td>289</td>\n",
              "      <td>204</td>\n",
              "      <td>0.976245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>290</th>\n",
              "      <td>290</td>\n",
              "      <td>198</td>\n",
              "      <td>0.811714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>291</th>\n",
              "      <td>291</td>\n",
              "      <td>282</td>\n",
              "      <td>0.635487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>292</th>\n",
              "      <td>292</td>\n",
              "      <td>263</td>\n",
              "      <td>0.983444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>293</th>\n",
              "      <td>293</td>\n",
              "      <td>247</td>\n",
              "      <td>0.685769</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>294 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     id_1  id_2     score\n",
              "0       0   210  0.649880\n",
              "1       1   136  0.746824\n",
              "2       2    19  0.705024\n",
              "3       3    13  0.882654\n",
              "4       4    33  0.785237\n",
              "..    ...   ...       ...\n",
              "289   289   204  0.976245\n",
              "290   290   198  0.811714\n",
              "291   291   282  0.635487\n",
              "292   292   263  0.983444\n",
              "293   293   247  0.685769\n",
              "\n",
              "[294 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29n9fYG0xMHr",
        "outputId": "fb9cde8b-bdd4-44eb-e967-24ea705d1779"
      },
      "source": [
        "index_df[\"score\"]"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      0.649880\n",
              "1      0.746824\n",
              "2      0.705024\n",
              "3      0.882654\n",
              "4      0.785237\n",
              "         ...   \n",
              "289    0.976245\n",
              "290    0.811714\n",
              "291    0.635487\n",
              "292    0.983444\n",
              "293    0.685769\n",
              "Name: score, Length: 294, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRSHkcC8w9Y7",
        "outputId": "f9936d3e-7591-48d4-d271-91c4a12d8088"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "sum_of_sims =(np.sum(index_df[\"score\"]))\n",
        "print(sum_of_sims)\n"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "239.74783873558044\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jg6zttr_x_K0",
        "outputId": "9ee1afa9-33fb-47ce-86e5-d9c9b9ee1ab5"
      },
      "source": [
        "len(sentencesweb)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "294"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JT3UdPcex1GQ",
        "outputId": "a034cc75-0f21-4cf9-87dc-0f2a1d5c5105"
      },
      "source": [
        "percentage_of_similarity = round(float((sum_of_sims / len(sentencesweb)) * 100))\n",
        "print(f'Average similarity float: {float(sum_of_sims / len(sentencesweb))}')\n",
        "print(f'Average similarity percentage: {float(sum_of_sims / len(sentencesweb)) * 100}')\n",
        "print(f'Average similarity rounded percentage: {percentage_of_similarity}')"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average similarity float: 0.8154688392366681\n",
            "Average similarity percentage: 81.54688392366681\n",
            "Average similarity rounded percentage: 82\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlBb3jcz6oxn"
      },
      "source": [
        "URL_link =only_link(data)"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iks3cPlW2MO0",
        "outputId": "caebb630-1884-4576-aaa8-5ec507aec618"
      },
      "source": [
        "import newspaper \n",
        "all_scraped_documents =[]  \n",
        "i= 0\n",
        "# Parse through each url and display its content \n",
        "for url in URL_link: \n",
        "    print(\"First Run\")\n",
        "    url_i = newspaper.Article(url=\"%s\" % (url), language='en') \n",
        "    url_i.download() \n",
        "    url_i.parse() \n",
        "    all_scraped_documents.append(url_i.text)\n",
        "    i = i+1\n",
        "    print(url_i.text)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First Run\n",
            "\n",
            "First Run\n",
            "In this paper, we propose the SepFormer, a novel RNN-free Transformer-based neural network for speech separation. The SepFormer learns short and long-term dependencies with a multi-scale approach that employs transformers. The proposed model matches or overtakes the state-of-the-art (SOTA) performance on the standard WSJ0-2/3mix datasets. It indeed achieves an SI-SNRi of 20.2 dB on WSJ0-2mix matching the SOTA, and an SI-SNRi of 17.6 dB on WSJ0-3mix, a SOTA result. The SepFormer inherits the parallelization advantages of Transformers and achieves a competitive performance even when downsampling the encoded representation by a factor of 8. It is thus significantly faster and it is less memory-demanding than the latest RNN-based systems.\n",
            "\n",
            "\n",
            "\n",
            "ame\n",
            "\n",
            "RNNs are a crucial component of modern audio processing systems and they are used in many different domains, including speech recognition, synthesis, enhancement, and separation, just to name a few. Especially when coupled with multiplicative gate mechanisms (like LSTM [6] and GRU [4, 24] ), their recurrent connections are essential to learn long-term dependencies and properly manage speech contexts. Nevertheless, the inherently sequential nature of RNNs impairs an effective parallelization of the computations. This bottleneck is particularly evident when processing large datasets with long sequences. On the other hand, Transformers [30] completely avoid this bottleneck by eliminating recurrence and replacing it with a fully attention-based mechanism. By attending to the whole sequence at once, a direct connection can be established between distant elements allowing Transformers to learn long-term dependencies more easily [9] . For this reason, Transformers are gaining considerable popularity for speech processing and recently showed competitive performance in speech recognition [8] , synthesis [15] , enhancement [11] , diarization [16] , as well as speaker recognition [2] .\n",
            "\n",
            "Little research has been done so far on Transformer-based models for monaural audio source separation. The field has been revolutionized by the adoption of deep learning techniques [5, 34, 13, 31, 20, 7] , and with recent works [18, 17, 27, 21, 29, 3, 35] achieving impressive results by adopting an end-to-end approach. Most of the current speech separation techniques [31, 20, 17, 18, 27, 21, 29, 3] require effective modeling of long input sequences to perform well. Current systems rely, in large part, on the learned-domain masking strategy popularized by Conv-TasNet [20] . In this framework, an overcomplete set of analysis and synthesis filters is learned directly from the data, and separation is performed by estimating a mask for each source in this learned-domain. Building on this, Dual-Path RNN (DPRNN) [18] has demonstrated that better long-term modeling is crucial to improve the separation performance. This is achieved by splitting the input sequence into multiple chunks that are processed locally and globally with different RNNs. Nevertheless, due to the use of RNNs, DPRNN still suffers from the aforementioned limitations of recurrent connections, especially regarding the global processing step. An attempt to integrate transformers into the speech separation pipeline has been recently done in [3] where the proposed Dual-Path Transformer Network (DPTNet) is shown to outperform the standard DPRNN. Such an architecture, however, still embeds an RNN, effectively negating the parallelization capability of pure-attention models.\n",
            "\n",
            "x Encoder h Masking Net Decoder ^s1 ^s2 m1 m2 Figure 1: The high-level description of our system: The encoder block estimates a learned-representation for the input signal, while the masking network estimates optimal masks to separate the sources present in the mixtures. The decoder finally reconstructs the estimated sources in the time domain using the masks provided by the masking network.\n",
            "\n",
            "In this paper, we propose a novel model called SepFormer (Separation Transformer), which is mainly composed of multi-head attention and feed-forward layers. We adopt the dual-path framework introduced by DPRNN and we replace RNNs with a multi-scale pipeline composed of transformers that learn both short and long-term dependencies. To the best of our knowledge, this is the first work showing that we can obtain state-of-the-art performance in separation with an RNN-free Transformer-based architecture. The SepFormer achieves an SI-SNRi of 20.2 dB on the standard WSJ0-2mix dataset, thus outperforming the DPRNN and matching the state-of-the-art performance of DPTNeT. It also achieves the SOTA performance of 17.6 dB SI-SNRi on the WSJ0-3mix dataset.\n",
            "\n",
            "The SepFormer not only processes all the time steps in parallel but also achieves competitive performance when downsampling the encoded representation by a factor of 8. This makes the proposed architecture significantly faster and less memory demanding than the latest RNN-based separation models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ctz0O316yvs"
      },
      "source": [
        "textextract2=all_scraped_documents[1]"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131,
          "referenced_widgets": [
            "adefedfbd9a047a3a86e5886601f22c7",
            "03a1e8a085864ced91f6cde49d828af1",
            "6a1dded166e24c068e9b5d7c67fae60f",
            "791984d4a8cb407e80e7786ddf87682b",
            "251cbe84798c40e5b499823dfec896bb",
            "0843cb4fb27141a68dd1da31810107eb",
            "0b38350afa0d4cb189cfaf40bb2cce45",
            "31ac9f70e8a94452a3ba5a6bc998dac3",
            "ceb8a8c1ea984245b22410874725f196",
            "8089f4a725ad47ec94b6c442f81a75b4",
            "744bc97853f34c31a89194373ddb03df",
            "7edd8f4ae10a4b3a92530860973c4853",
            "ad716ad207b44735824db53338d6e0f0",
            "521f287ac9f14efca3b1716cbc7e36a4",
            "47e5e0e3ae404b159f7f331e286a7648",
            "4249a5b185a4498f97ddd25d4d3f6861"
          ]
        },
        "id": "zmrYZ15c-b9Y",
        "outputId": "26e313ad-9a03-4261-908d-5a623c7ee856"
      },
      "source": [
        "sentencesweb=sent_tokenize(textextract2)\n",
        "text_embeddings = model.encode(sentencesweb, batch_size = 8, show_progress_bar = True)\n",
        "text_embeddings2 = model.encode(sentencesAtten, batch_size = 8, show_progress_bar = True)\n",
        "np.shape(text_embeddings)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "adefedfbd9a047a3a86e5886601f22c7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Batches', max=4.0, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ceb8a8c1ea984245b22410874725f196",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Batches', max=37.0, style=ProgressStyle(description_width…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVD8yWnp-8Gs"
      },
      "source": [
        "similarities = cosine_similarity(text_embeddings,text_embeddings2)\n",
        "similarities_sorted = similarities.argsort()\n",
        "# Get list of similarity indices i.e. doc at index 0 simialr with doc at index 1169 below.\n",
        "id_1 = []\n",
        "id_2 = []\n",
        "score = []\n",
        "for index,array in enumerate(similarities_sorted):\n",
        "    id_1.append(index)\n",
        "    id_2.append(array[-2])\n",
        "    score.append(similarities[index][array[-2]])"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKW9vp_9_TNj"
      },
      "source": [
        "index_df = pd.DataFrame({'id_1' : id_1,\n",
        "                          'id_2' : id_2,\n",
        "                          'score' : score})"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rXvCwWA_edM",
        "outputId": "4e3e6fcf-c8ba-4993-fd8f-89107a4c064d"
      },
      "source": [
        "index_df[\"score\"]"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     0.833049\n",
              "1     0.917383\n",
              "2     0.822351\n",
              "3     0.824403\n",
              "4     0.893228\n",
              "5     0.925941\n",
              "6     0.717517\n",
              "7     0.806087\n",
              "8     0.882654\n",
              "9     0.720121\n",
              "10    0.657550\n",
              "11    0.734949\n",
              "12    0.754830\n",
              "13    0.608916\n",
              "14    0.716941\n",
              "15    0.746506\n",
              "16    0.705208\n",
              "17    0.809264\n",
              "18    0.777090\n",
              "19    0.727775\n",
              "20    0.765856\n",
              "21    0.704917\n",
              "22    0.742932\n",
              "23    0.803181\n",
              "24    0.968818\n",
              "25    0.830427\n",
              "26    0.851589\n",
              "27    0.744633\n",
              "28    0.706705\n",
              "29    0.757208\n",
              "30    0.849228\n",
              "31    0.932374\n",
              "Name: score, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6qYzgEA_syJ",
        "outputId": "af6a95c0-b713-4d24-b777-0acf537f7e5b"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "sum_of_sims =(np.sum(index_df[\"score\"]))\n",
        "print(sum_of_sims)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25.23962926864624\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIZfLP4T_8pt",
        "outputId": "49d7f39a-925d-42ad-ff64-5595ec77343f"
      },
      "source": [
        "percentage_of_similarity = round(float((sum_of_sims / len(sentencesweb)) * 100))\n",
        "print(f'Average similarity float: {float(sum_of_sims / len(sentencesweb))}')\n",
        "print(f'Average similarity percentage: {float(sum_of_sims / len(sentencesweb)) * 100}')\n",
        "print(f'Average similarity rounded percentage: {percentage_of_similarity}')"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average similarity float: 0.788738414645195\n",
            "Average similarity percentage: 78.8738414645195\n",
            "Average similarity rounded percentage: 79\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwHVB_9e9HSd"
      },
      "source": [
        "# Trial 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwVeVAuk88Vm"
      },
      "source": [
        "#Tokenizing the received\n",
        "textevol = read_file(\"Evolution.txt\")\n",
        "sentencesevol=sent_tokenize(textevol)\n",
        "textStruct = read_file(\"Structural_bio.txt\")\n",
        "sentencesStruct=sent_tokenize(textStruct)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzKAAHQi_7DA",
        "outputId": "6a62e563-d199-46d1-ca7f-354eb69bba88"
      },
      "source": [
        "parser = PlaintextParser.from_string(textStruct,Tokenizer(\"english\"))\n",
        "summarizer_lsa = LsaSummarizer()\n",
        "# Summarize using sumy LSA\n",
        "summary =summarizer_lsa(parser.document,2)\n",
        "lsa_summary=\"\"\n",
        "for sentence in summary:\n",
        "    lsa_summary+=str(sentencesStruct)  \n",
        "print(lsa_summary)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[' Structural bioinformatics\\n CLoNe: automated clustering based on local density\\n neighborhoods for application to biomolecular structural\\n ensembles\\n Sylvain Tra¨ ger1,2, Giorgio Tamo` 1,2, Deniz Aydin1,2, Giulia Fonti1,2,\\n Martina Audagnotto1,2 and Matteo Dal Peraro1,2,*\\n 1\\n Institute of Bioengineering, School of Life Sciences, Ecole Polytechnique Fe´ de´ rale de Lausanne, Lausanne 1025, Switzerland and 2\\n Swiss Institute of Bioinformatics, Lausanne 1015, Switzerland\\n *To whom correspondence should be addressed.', 'Associate Editor: Lenore Cowen\\n Received on January 8, 2020; revised on July 14, 2020; editorial decision on August 12, 2020; accepted on August 18, 2020\\n Abstract\\n Motivation: Proteins are intrinsically dynamic entities.', 'Flexibility sampling methods, such as molecular dynamics or\\n those arising from integrative modeling strategies, are now commonplace and enable the study of molecular conformational landscapes in many contexts.', 'Resulting structural ensembles increase in size as technological and algorithmic advancements take place, making their analysis increasingly demanding.', 'In this regard, cluster analysis\\n remains a go-to approach for their classification.', 'However, many state-of-the-art algorithms are restricted to specific\\n cluster properties.', 'Combined with tedious parameter fine-tuning, cluster analysis of protein structural ensembles\\n suffers from the lack of a generally applicable and easy to use clustering scheme.', 'Results: We present CLoNe, an original Python-based clustering scheme that builds on the Density Peaks algorithm\\n of Rodriguez and Laio.', 'CLoNe relies on a probabilistic analysis of local density distributions derived from nearest\\n neighbors to find relevant clusters regardless of cluster shape, size, distribution and amount.', 'We show its capabilities on many toy datasets with properties otherwise dividing state-of-the-art approaches and improves on the original algorithm in key aspects.', 'Applied to structural ensembles, CLoNe was able to extract meaningful conformations from membrane binding events and ligand-binding pocket opening as well as identify dominant dimerization\\n motifs or inter-domain organization.', 'CLoNe additionally saves clusters as individual trajectories for further analysis\\n and provides scripts for automated use with molecular visualization software.', 'Availability and implementation: www.epfl.ch/labs/lbm/resources, github.com/LBM-EPFL/CLoNe.', 'Contact: matteo.dalperaro@epfl.ch\\n Supplementary information: Supplementary data are available at Bioinformatics online.', '1 Introduction\\n The perception of molecular structures, especially proteins, is gradually shifting from the concept of one single and rigid structure to\\n the idea that biomolecules natively exhibit a continuum of states\\n (Frank, 2018).', 'Protein folding, post-translational modifications\\n (Audagnotto and Dal Peraro, 2017), binding to other molecules or\\n their involvement in catalytic events result in vast and complex conformational landscapes.', 'Molecular dynamics (MD), thanks to progress in both its technological and algorithmic aspects, allows for\\n the simulation of key biomolecular events.', 'Their observability, however, tends to be limited by currently accessible timescales.', 'Researchers consistently come up with innovative protocols to push\\n this limit further (Barducci et al., 2011; Bussi, 2014; Chavent et al.,\\n 2016; Doerr et al., 2016; Hamelberg et al., 2004; Noe´ et al., 2019;\\n Shirts and Pande, 2000; Sultan et al., 2018; Wassenaar et al., 2015)\\n granting us with the ability to capture protein folding as well as protein–protein, protein–membrane and protein–ligand interactions\\n (Audagnotto et al., 2016; De Vivo et al., 2016; McKiernan et al.,\\n 2017; Oleinikovas et al., 2016).', 'State-of-the-art protocols for smallmolecule docking (Amaro et al., 2018; Kokh et al., 2011; Vahl\\n Quevedo et al., 2014), protein–protein docking and integrative\\n modeling strategies, in general, have shifted toward the integration\\n of dynamics in some form as well (Abriata and Dal Peraro, 2020;\\n Malhotra et al., 2019; Tamo` et al., 2015).', 'All of the aforementioned\\n aspects advocate dynamics as a cornerstone of modern structural\\n biology and push the need for efficient tools to extract functional insight from structural ensembles in general.', 'VC The Author(s) 2020.', 'Published by Oxford University Press.', '1\\n This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (http://creativecommons.org/licenses/by-nc/4.0/),\\n which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited.', 'For commercial re-use, please contact\\n journals.permissions@oup.com\\n Bioinformatics, 2020, 1–8\\n doi: 10.1093/bioinformatics/btaa742\\n Advance Access Publication Date: 21 August 2020\\n Original Paper\\n Downloaded from https://academic.oup.com/bioinformatics/advance-article/doi/10.1093/bioinformatics/btaa742/5895303 by guest on 19 March 2021\\n However, these advances come at a price.', 'The sheer size, the intrinsic complexity and redundancy of structural ensembles makes\\n their successful analysis and computational integration non-trivial.', 'Coarse-graining tools such as cluster analysis effectively reduce simulations of thousands of conformations to few key biological states\\n and hence constitute a go-to approach with countless applications to\\n date [(Cheng et al., 2008; De Paris et al., 2015; de Souza et al.,\\n 2017), reviewed in (Peng et al., 2018; Shao et al., 2007)].', 'Such states\\n may serve as basis of Markov state models (Husic and Pande, 2018;\\n Wang et al., 2018).', 'To our knowledge, however, an algorithm able\\n to cluster data efficiently irrespective of their properties is still missing.', 'Indeed, different cluster shapes, sizes and densities usually dictate which clustering approach is best suited for a given task.', 'The\\n most known and widely used scheme is probably that of k-means\\n and its many variations (Jain, 2010).', 'This center-based clustering\\n scheme, however, suffers from unequal results due to random initializations, the a priori setting of the number of clusters and its limitation to spherical clusters.', 'Alternatively, hierarchical schemes such as\\n the Ward-linkage agglomerative algorithm (Ward, 1963) do not require pre-setting the number of clusters and are popular for building\\n Markov state models (Beauchamp et al., 2012; Husic and Pande,\\n 2017; Paris et al., 2015).', 'They are however sensitive to noise and\\n outliers and may suffer from non-spherical clusters (Peng et al.,\\n 2018).', 'Conversely, DBSCAN (Ester et al., 1996) is able to manage\\n clusters regardless of shape by utilizing density differences between\\n clusters and noise.', 'However, setting its parameter is not trivial and\\n its optimal value may not be unique throughout the dataset when\\n clusters of largely different densities are present.', 'This limitation is at\\n the core of OPTICS, which can be seen as an extension of DBSCAN\\n (Ankerst et al., 1999), although not strictly advertised as a clustering\\n algorithm.', 'Defining metastable states of proteins is non-trivial due to the\\n large and often redundant number of internal degrees of freedom,\\n yielding sampled conformational spaces with local minima often devoid of biological significance.', 'We can make the assumption that,\\n given enough sampling and a choice of relevant features, metastable\\n states would lie in regions or clusters of high density, which would\\n be separated by valleys of different density levels that would correspond to transitional states.', 'Furthermore, no assumption can be\\n made on the shape or relative densities of clusters, which would depend on both conformational sampling and target system.', 'Rodriguez and Laio (2014) designed the Density Peaks (DP) algorithm aimed at clustering regardless of shape and dimensionality.', 'Their algorithm generated significant interest thanks to their clever\\n definition of cluster centers, which states that a cluster center should\\n display a higher density (q) than its neighbors and a high distance to\\n another point of higher density (d).', 'DP takes a single input parameter, which relates to a cutoff distance for the computation of q.', 'However, it requires the user to specify thresholds for both q and d\\n mid-computation in order to select the cluster centers, which prevents a fully automated clustering process.', 'DP has since been\\n improved by the inclusion of k nearest neighbors (kNN) (Du et al.,\\n 2016; Xie et al., 2016; Zhang and Li, 2015) or heat diffusion\\n (Mehmood et al., 2016) for a more robust estimation of q, which\\n allows for a better handling of cases where clusters have significantly different densities.', 'These improvements still require user intervention for selecting cluster centers.', 'Conversely, Wang and Xu (2017)\\n built on DP to automatically select cluster centers based on maximizing an average silhouette index, although other input parameters\\n are required instead.', 'Liang and Cheng coupled principles from\\n DBSCAN with a divide-and-conquer approach to recursively and\\n automatically select cluster centers (Liang and Chen, 2016).', 'Recently, d’Errico et al.', 'coupled DP with a non-parametric density\\n estimator (Rodriguez et al., 2018), yielding Density Peaks Advanced\\n (DPA; d’Errico et al., 2018).', 'While exhibiting impressive robustness\\n to a variety of cluster shapes, densities and to outliers, DPA still suffers from a few issues.', 'We found that it performed worse than the\\n original on some typical benchmark datasets, and requires a sensitive albeit unique input parameter.', 'Moreover, both DP and DPA exhibit an inconsistent outlier removal procedure.', 'These drawbacks\\n may prove crucial when targeting structural biological data, where\\n regions at lower effective density may have equal or even increased\\n significance than others at higher densities.', 'The complexity of biological structures leads to numerous unique yet equally relevant\\n choices of features, each with their own topology.', 'The analysis of\\n such datasets is greatly hindered by sensitivity to input parameters,\\n which implies that tedious fine-tuning steps have to be undertaken.', 'Here, we introduce an approach to remedy these drawbacks,\\n enabling a facilitated analysis of complex real-world datasets from\\n structural biology.', 'Our approach builds on the original DP algorithm by introducing a fragmenting of the data into specific density\\n distributions.', 'In essence, the local densities of each point are computed using nearest neighbors and a Gaussian kernel and points\\n associated with local density maxima are identified as putative cluster centers.', 'To increase robustness to non-spherical cluster shapes,\\n clusters are merged using the Bhattacaryaa coefficient\\n (Bhattacharyya, 1943) by comparing density distributions derived\\n from putative cluster cores and boundaries.', 'Finally, outliers from\\n impromptu noise fluctuations are removed by means of a Bayes classifier.', 'This, to the best of our knowledge, constitute an original contribution to the density peaks algorithm.', 'Termed Clustering based\\n on Local density Neighborhoods (CLoNe), our approach relies on a\\n single input parameter that is both robust and intuitive to set.', 'We\\n test it on many typical benchmark datasets and against state-of-theart clustering schemes.', 'The local focus of CLoNe allows for the detection of biological states of smaller frequency while its ease of use\\n allows the researcher to focus on choosing relevant biological features for pre-processing or analyzing their structural ensemble without being hindered by algorithmic limitations.', 'Furthermore, CLoNe\\n outputs useful molecular visualization scripts for the validation of\\n cluster relevance in the target biological context (Supplementary Fig.', 'S1).', 'We apply CLoNe on a range of structural datasets from MD\\n simulations or integrative modeling studies, each time detailing the\\n feature selection process and which information can be extracted\\n from the results.', 'Our examples cover previously published studies\\n on protein–membrane interactions, internal structural rearrangements of disordered proteins, cryptic allosteric pocket formation and\\n transmembrane dimerization motifs, and highlight the broad advantages of CLoNe for the analysis of molecular structural ensembles.', '2 Materials and methods\\n An overview and basic usage of CLoNe is available in\\n Supplementary Figure S1, on GitHub and the webpage of our laboratory (see Abstract section).', 'We created a synthetic dataset containing clusters of significantly different densities and various shapes\\n in order to showcase the procedure behind our approach.', 'CLoNe\\n starts by finding the k nearest neighbors of each point in a dataset X\\n of N points using k-nearest neighbors (kNN) (Pedregosa et al.,\\n 2011), yielding a neighbor matrix M where each row i contains all\\n the neighbors j of point i in increasing order of Euclidean distance.', 'To account for significant density differences between clusters, we\\n initially assume that all points are cluster centers.', 'In a first step, we\\n estimate the local density q of each point i using a Gaussian kernel:\\n qi ¼ X\\n jkNNi\\n e\\n  Mi;j\\n dc\\n  2\\n ¼ X\\n jkNNi\\n qij (1)\\n where kNNi is the set of nearest neighbors of i in increasing order of\\n distance and dc is a cutoff distance defined as to be superior to a\\n user-defined percentage pdc (the single input parameter of CLoNe)\\n of all distances within M, similar to the original DP algorithm\\n (Rodriguez and Laio, 2014).', 'We define the core of putative cluster i\\n as the set of neighbors that contribute to qi at least as much of the\\n j1 previous neighbors on average:\\n corei ¼ j  kNNijqij\\n 1\\n pdcN\\n Xj1\\n k¼0 qik \\x04 \\x05 (2)\\n We show in Figure 1a the cardinality (number of elements) of\\n the core of each point in our synthetic dataset.', 'As expected, this\\n 2 S.Tra¨ ger et al.', 'Downloaded from https://academic.oup.com/bioinformatics/advance-article/doi/10.1093/bioinformatics/btaa742/5895303 by guest on 19 March 2021\\n number is higher for points closer to real cluster centers and lower\\n for points laying on the outskirt of clusters.', 'The visualization of core\\n cardinalities is an efficient way to observe the underlying topology\\n of the dataset.', 'In order to identify if i is a genuine candidate for cluster center, we identify its first neighbor j of higher density.', 'If neighbor j belongs to corei, then neighbor j is a better candidate for\\n cluster center in this region than i. Conversely, i is a genuine candidate for cluster center if j is not in the core of i.', 'Cluster assignation\\n is done in a single step by assigning a point to the same cluster as its\\n nearest point of higher density, in order of decreasing local density,\\n similar to the original DP approach.', 'The results at this stage of\\n CLoNe are shown in Figure 1a.', 'One of the drawbacks of the DP algorithm is its limited ability to\\n deal with clusters with more than one peak or those with an elongated region of similar density, such as the noisy circles benchmark\\n dataset (Supplementary Fig.', 'S2).', 'This is true at this stage of CLoNe\\n as well, as the Gaussian kernel in (1) is biased toward determining\\n cores with spherical shapes (Fig.', '1b).', 'We can make the assumptions\\n that if two existing clusters A and B should be merged, then the\\n density from one core to the other should be relatively constant.', 'This can be estimated by looking at the core cardinality distribution\\n of the points belonging to the core of both clusters as well as that of\\n the points from the boundary between them (Fig.', '1b, left), which\\n can be defined as:\\n boundaryAB ¼ i 2 A; j 2 Bjd ið Þ ; j < dcg \\x06 (3)\\n Then, we define the following probability density function for\\n the ensemble of points belonging to either cluster cores or the\\n boundary from (3):\\n Ps ¼ KDE corei ð Þ f g ; i 2 S (4)\\n where S denotes one of the aforementioned ensembles and #corei the\\n core cardinality of point i and KDE refers to the probability density\\n function estimated by unimodal Gaussian kernel density estimation.', 'Similarity between probability distributions can be measured using\\n the Bhattacharyya coefficient (BC) (Bhattacharyya, 1943), which is\\n bound between 0 and 1.', 'Thus, the formula to compute the BC between the core of cluster A with the boundary from (3) becomes:\\n BCA ¼ ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\\n PboundPcoreA\\n p (5)\\n We take the decision of merging Clusters A and B if the mean of\\n their respective BC with their boundary is above a threshold sBC:\\n B Að Þ ; B ¼ 1\\n 2 ð Þ BCA þ BCB > sBC (6)\\n where PcoreB is obtained as for cluster A in (5) and sBC was chosen to\\n be the 65th percentile to limit uncertainty and based on benchmarks\\n (Fig.', '1 and Supplementary Fig.', 'S2).', 'Taking the mean of both coefficients prevents the merging of a cluster whose probability density is\\n similar to that of its boundary with a cluster of significantly higher\\n density.', 'This enabled us to identify clusters that can hardly be\\n defined with a single density peak, such as uniform density over\\n non-spherical shapes (Figs 1b and 2a).', 'The point with highest q is\\n chosen as the new cluster center.', 'If pdc is chosen too small, clusters\\n may be split into sub-clusters.', 'Within our approach, these subclusters are likely to be merged into clusters matching the original\\n topology, expanding the range of acceptable values for pdc and making it an input parameter less sensitive than the one of DPA\\n (Supplementary Fig.', 'S3).', 'The second drawback of using the Gaussian kernel in (1) is that\\n it may falsely identify impromptu local noise fluctuations as cluster\\n centers (Fig.', '1b).', 'To remedy this, we define two probability density\\n functions.', 'Mcores is the probability density of the local density of all\\n points belonging to any cluster core as per (2):\\n Mcores ¼ KDEð qx f g ; x 2 corei 8i 2 C Þ (7)\\n where C is the set of cluster centers remaining after the previous\\n merging step.', 'Moutliers is the equivalent function for all points identified as outliers:\\n Moutliers ¼ KDEð qx; x 2 X if qx < f \\x04 qcenterx\\n \\x06 \\x08Þ (8)\\n where qcenterx is the local density of the center of the cluster x\\n belongs to and f an arbitrary fraction chosen to be 0.1 by default\\n and used throughout this article.', 'To determine if an identified cluster is more probable to be derived from noise than to be a genuine\\n cluster, we use a Bayesian classifier.', 'For each cluster core ci, we derive the following posterior probabilities using Bayes’ theorem:\\n p Yð Þ¼ jci\\n p Yð Þ pðcijYÞ\\n pðciÞ ; Y 2 f g outliers; cores (9)\\n where the prior probabilities are defined as follows:\\n Fig.', '1.', 'Clustering based on local density neighborhoods.', 'We created a synthetic\\n dataset that contains four croissant-shaped clusters of 500 elements each with different scaling as well as a cluster in the shape of a cross with 4000 elements and added\\n Gaussian noise.', '(a) On the left, the cardinality of the core of each point in the dataset.', 'On the right, the clusters obtained after the first stage of clustering.', '(b) The average Bhattacaryya coefficient B(A,B) between two Clusters A and B is shown.', 'The\\n upper left plots show an example of two clusters being merged corresponding to the\\n upper square in panel (a).', 'The lower left plots show an example of two clusters that\\n will not be merged corresponding to the lower square in panel (a).', 'Points belonging\\n to the core of each cluster are shown in black, regular points in shades of gray and\\n points belonging to the boundary in red.', 'The plot on the right shows the clustering\\n after merging clusters.', '(c) CLoNe uses a Bayesian classifier to decide if a cluster is\\n genuine or arises from noise fluctuations.', 'On the left, the corresponding probability\\n density functions of points belonging to any cluster cores (black), noise (blue), or to\\n individual cluster cores (light blue).', 'The range of local density of clusters classified\\n as noise fluctuations are shown on the secondary y-axis (dark blue).', 'The final clustering result is shown on the right, with identified outliers shown as black crosses\\n CLoNe: automated clustering of biomolecular structural ensembles 3\\n Downloaded from https://academic.oup.com/bioinformatics/advance-article/doi/10.1093/bioinformatics/btaa742/5895303 by guest on 19 March 2021\\n p Yð Þ ¼ jYj\\n N ; Y 2 f g outliers; cores (10)\\n where jYj denotes the cardinality of the corresponding class.', 'The\\n likelihoods pðcijYÞ can be computed by evaluating the previously\\n defined probability distributions (7) and (8) at ci.', 'Disregarding the\\n evidence pðciÞ common for both outliers and cores classes, we thus\\n obtain the following Bayesian classifier:\\n y^i ¼ argmax Y2f g outliers; cores\\n p Yð ÞY\\n x2ci\\n MYðqxÞ (11)\\n This classifier enabled us to remove all cluster centers arising\\n from noise fluctuations.', 'Combined with the previous merging step,\\n the clustering is now complete (Fig.', '1c).', 'The software has been written using Python3.7.', 'When used on\\n structural biological data, CLoNe outputs cluster centers as separate\\n PDB files, individual clusters as XTC trajectories and Tcl scripts for\\n automated loading within the visualization software VMD (Visual\\n Molecular Dynamics, (Humphrey et al., 1996)).', 'The loading of MD\\n trajectories as well as the saving of cluster centers and cluster subtrajectories is done through the MDTraj package (McGibbon et al.,\\n 2015).', 'We use the scipy (Jones et al., 2001), scikit-learn (Pedregosa\\n et al., 2011) and Statsmodels (Seabold and Perktold, 2010) packages\\n for many operations described in the previous subsection and to\\n compare CLoNe to other clustering algorithms.', '3 Results\\n 3.1 Automatic cluster center determination from local\\n density neighborhood analysis\\n We applied CLoNe to a large set of common benchmark datasets\\n from various sources (Chang and Yeung, 2008; d’Errico et al., 2018;\\n Fra¨nti and Sieranoja, 2018; Fu and Medico, 2007; Gionis et al.,\\n 2007; Pedregosa et al., 2011), covering different key properties of\\n clusters, such as non-spherical shapes, anisotropy, as well as significant size and density differences, all of which can be expected from\\n real-world datasets from structural biology.', 'In the previous section,\\n we detailed how CLoNe automatically detects cluster centers, accurately merges clusters and removes outliers, succeeding in cases where\\n previous iterations of DP did not (Fig.', '2a and Supplementary Fig.', 'S2).', 'Similarly to the original DP algorithm (Rodriguez and Laio,\\n 2014), CLoNe requires a single input parameter pdc, which relates\\n to a cutoff distance used in the estimation of local densities (see\\n Section 2).', 'In general, pdc takes a value in a small range and is\\n intuitive to set.', 'For instance, with pdc values of 1 or 2 local densities\\n will be estimated considering neighborhoods small enough to identify individual spiral branches as clusters (Fig.', '2b).', 'For higher values\\n of pdc, the scale of the Gaussian kernel in Equation (1) will increase\\n and merge individual branches into whole spirals, allowing the study\\n of multiple hierarchies intuitively (Fig.', '2c).', 'Other than clusters with\\n non-spherical shapes, CLoNe identifies successfully the numerous\\n Gaussian clusters of the A3 dataset (Fig.', '2d).', 'Some degree of overlapping in real-world datasets is to be expected.', 'The S4 dataset contains 15 highly overlapping Gaussian clusters of varying densities\\n and shapes but equal size.', 'As with the A3 dataset, CLoNe does not\\n perform unnecessary merging with nearby clusters (Fig.', '2e) and is\\n robust to large amounts of outliers on top of clusters with significantly different densities (Fig.', '2f).', 'This general applicability of\\n CLoNe coupled with a single, robust and easy to set input parameter\\n (Supplementary Fig.', 'S3) is unique among the commonly used clustering algorithms found in the Scikit-learn package (Pedregosa et al.,\\n 2011).', 'In fact, CLoNe is among the fastest algorithms from that\\n package in addition to both DP and DPA and the most accurate on\\n the available benchmark cases (Supplementary Fig.', 'S2).', 'The only\\n other algorithm succeeding on all benchmark cases is OPTICS\\n (Ankerst et al., 1999), which runs slightly slower than CLoNe on\\n these datasets and tends to classify too many points as outliers.', 'Similar to the original implementation of DP, CLoNe is applicable\\n to high dimensionality datasets as well (Supplementary Table S1\\n and Supplementary Fig.', 'S4).', 'One of the principal aims of this work is to offer a clustering algorithm able to classify unlabeled biological structural ensembles\\n into relevant states associated with their function and mechanism of\\n action.', 'We have applied CLoNe to real-world structural biology\\n data reporting on the dynamic conformational space of a protein\\n that associates with its specific biological membrane, cryptic allosteric pocket opening and dimerization of transmembrane proteins.', '3.2 Determining relevant states within protein\\n conformational ensembles\\n COQ9 is a lipid-binding protein associated with the biosynthesis of\\n coenzyme Q (CoQ), a redox-active lipid that is essential for cellular\\n respiration (Lohman et al., 2014).', 'Recently, coarse-grained molecular dynamics (CG-MD) simulations and liposome co-flotation assays\\n were used together to reveal that COQ9 accesses membranes in a\\n multi-step fashion through a distinct, C-terminal amphipathic helix\\n (a10) (Lohman et al., 2019).', 'In these simulations, COQ9 first diffused in the aqueous environment, then underwent various\\n Fig.', '2.', 'Local neighborhood density analysis for automated center and cluster determination.', 'For each panel, the cardinality of the core of each point as detailed in the Section 2\\n is shown on the left.', 'The resulting clusters are shown on the right, with clusters in different colors and identified outliers as black crosses.', '(a) Noisy circles dataset.', '(b and c)\\n Four instances of spiral dataset with different values of the input parameter yielding different yet valid clusters.', '(d) The a3 dataset containing 50 Gaussian clusters.', '(e) The s4\\n dataset with highly overlapping Gaussian clusters, some with anisotropic distributions.', '(f) A synthetic dataset with clusters of significantly different sizes and densities taken\\n from Density Peaks Advanced\\n 4 S.Tra¨ ger et al.', 'Downloaded from https://academic.oup.com/bioinformatics/advance-article/doi/10.1093/bioinformatics/btaa742/5895303 by guest on 19 March 2021\\n conformational changes upon membrane binding (Lohman et al.,\\n 2019).', 'We applied CLoNe to the CG-MD trajectory used in the latter study and sought to identify the main binding events pertaining\\n to the protein itself.', 'To this end, we extracted features characterizing both its movements in the aqueous environment through monitoring its distance to the membrane as well as key conformational\\n changes based on the angle between the unique a10 helix of COQ9\\n and its globular domain (Fig.', '3a, left).', 'Using these two features,\\n CLoNe outputs three clusters, each of which seem to follow\\n Gaussian distributions (Fig.', '3b).', 'One cluster regroups all conformations that correspond to diffusion movements in the aqueous environment, while the other two highlight the membrane association of\\n a10 first followed by the globular domain as a converging step\\n (Fig.', '3a), thus its higher density (Fig.', '3b).', 'Similar results can be\\n obtained hypothesis-free by using raw atomic spatial coordinates\\n (Supplementary Fig.', 'S4).', 'The Gaussian distribution of structural\\n clusters has also been observed in a recent study from our group\\n involving the KAP1 protein, where CLoNe was also successfully\\n applied (Supplementary Fig.', 'S5) (Fonti et al., 2019).', '3.2 Isolating sub-ensembles of relevant conformations\\n for ligand–target interactions\\n In recent years, small-molecule docking software is no stranger to\\n dynamics, taking into account ensembles of ligand conformations\\n (Amaro et al., 2018) or receptor flexibility (Kokh et al., 2011;\\n Salmaso and Moro, 2018; Vahl Quevedo et al., 2014).', 'A recent\\n study highlighted a novel replica exchange-based MD protocol combined with benzene probes, where each replica harbors a different\\n scaling of water–protein interactions (Oleinikovas et al., 2016).', 'Using this method, the authors could observe the opening of cryptic\\n allosteric pockets in several systems, including that of the TEM1 blactamase, which plays a critical role in antibiotic resistance (Horn\\n and Shoichet, 2004).', 'The simulations were started from the apo\\n crystal structure with a closed allosteric pocket (Fig.', '4a).', 'Out of the\\n eight replicas of the simulation, we chose three with neutral (first),\\n medium (fourth) and highest (last) scaling factors as a tradeoff between maximizing the sampled conformational space and limiting\\n redundancy of the over-represented closed conformations\\n (Oleinikovas et al., 2016) (Fig.', '4b).', 'Along with key residue R244 on\\n the opposite wall of the pocket, the opening of a-helices H11 and\\n H12 and key residues L220 and N276 dictate pocket opening and\\n allow two inhibitors to be accommodated (Horn and Shoichet,\\n 2004), while the three mentioned residues form a triad when the\\n pocket is closed.', 'In addition to the opening of the two helices, visual\\n inspection of the simulations indicated a deepening of the pocket.', 'As\\n a result, we chose features tracking the distance between the Ca of\\n residues L220 and N276 as well as that of their sidechains to monitor pocket opening as well as the distance between the Ca of I263\\n and I279 as a measure of pocket depth (Fig.', '4a).', 'The original study\\n used fpocket (Le Guilloux et al., 2009) to monitor pocket exposure\\n in each replica (Fig.', '4b, top).', 'The same was done on the clusters\\n obtained by CLoNe (Fig.', '4b, bottom), showing different levels of\\n pocket openness.', 'Corresponding cluster centers highlight key structural differences between each state (Fig.', '4c), which are representative of the feature distribution per cluster (Fig.', '4d, top).', 'Cluster\\n assignation follows the observation of the original publication,\\n where open states were more prevalent in the replica of medium\\n scaling (Fig.', '4d, bottom).', '3.3 Identifying dominant conformational motifs in\\n protein oligomerization\\n Another challenge in structural biology is the understanding of how\\n biomolecules oligomerize to distinctive functional states.', 'One of\\n these cases, the transmembrane a-helix of the Amyloid Precursor\\n Protein (termed APP hereafter), has recently been studied by our lab\\n through the high-throughput MD protocol DAFT (Docking Assay\\n For Transmembrane components, (Wassenaar et al., 2015)) in order\\n to identify which of two dimerization motifs is promoted depending\\n on the lipid composition of the synaptic plasma membrane\\n (Audagnotto et al., 2016).', 'The G700G704G708 motif is thought to\\n direct the binding of APP to regulators promoting cholesterol biosynthesis, while the G709A713 motif would bind to cholesterol molecules (Fig.', '5a).', 'Extracting features from molecular datasets is not\\n always straightforward.', 'Macromolecular movements possess an inherent redundancy due to the sheer number of internal degrees of\\n freedom or prior knowledge may be lacking in order to select meaningful features, such as those highlighted in Figures 3 and 4.', 'The use\\n of dimensionality reduction methods, such as principal component\\n analysis (PCA) has been seen for clustering of MD simulations\\n (Wolf and Kirschner, 2013) and can help identifying coordinates of\\n significance while discarding less useful dimensions.', 'The DAFT simulations of APP from (Audagnotto et al., 2016) are over 2 ms in total\\n and contain countless states, many corresponding to unbound\\n monomers.', 'The first principal component based on the Cartesian\\n coordinates of the coarse grain backbone covers 77% of the variability in the simulation, highlighting two clusters (Fig.', '5b).', 'The\\n blue cluster of lower amplitude corresponds to all states exhibiting\\n unbound monomers (Fig.', '5e, left), while the second cluster regroups\\n all the dimerized states regardless of motif.', 'Focusing on that cluster,\\n we calculated the pair-wise distances between the backbone atoms\\n of each motifs in both helices (Fig.', '5a) and reduced these features to\\n a two-dimensional principal space covering 94% of the variability\\n before clustering (Fig.', '5c).', 'We want to highlight CLoNe’s ability to\\n analyze the neighborhood of low-density clusters without influence\\n from high-density regions (Fig.', '5c and Supplementary Table S2).', 'Clusters in blue in Figure 5d all depict states close to the\\n G700G704G708 motifs and those in green the G709A713 motif.', 'In the\\n middle are two clusters, shown in brown, that we interpret as hybrid.', 'In all cases, the darker-shaded clusters of each group correspond to the closest to the optimal motif arrangement, while the\\n others can be considered as closely related metastable states\\n (Supplementary Fig.', 'S6).', 'Similar to the original study (Audagnotto\\n Fig.', '3.', 'Utilizing Gaussian cluster properties to extract centers as key biological states of the COQ9 membrane protein.', '(a) COQ9 and its associated features, which include an\\n internal angle h and its distance to the membrane d (left).', 'Cluster centers are shown on the right side of the panel.', '(b) Every frame is plotted in the mentioned feature space and\\n color coded according to their core cardinality (left) and cluster assignation (right), which follows the same color code as in (a).', 'Outliers are shown as black crosses and centers\\n as black stars\\n CLoNe: automated clustering of biomolecular structural ensembles 5\\n Downloaded from https://academic.oup.com/bioinformatics/advance-article/doi/10.1093/bioinformatics/btaa742/5895303 by guest on 19 March 2021\\n et al., 2016), CLoNe finds the preferred dimerization motif to be\\n G700G704G708 as evidenced by the corresponding centers’ local densities, cluster population and core cardinality (Fig.', '5c and\\n Supplementary Table S2).', 'A comparison between CLoNe and other\\n state-of-the-art algorithms on all the structural data shown in this\\n section demonstrates the advantages of CLoNe for analysis of molecular structural ensembles (Supplementary Fig.', 'S7).', '4 Discussion\\n Many clustering methods rely on parameters that are often nontrivial to optimize or on random initial conditions that may drastically change the outcome.', 'Commonly used algorithms are generally\\n restricted to specific cluster properties, forcing the researcher\\n through a process of trial and error.', 'Moreover, choosing relevant\\n features from structural datasets is challenging and different features\\n may generate different cluster topologies, sometimes irrelevant.', 'CLoNe was designed with these issues in mind and aims to provide\\n a stream-lined analytic process to yield results rapidly along with\\n helpful visualization scripts to analyze and confirm the relevance of\\n the clusters in the target biological context (Supplementary Fig.', 'S1).', 'CLoNe’s only parameter regulates the size of the local neighborhood\\n considered around each data point, which can be regarded as cluster\\n sizing parameter.', 'Its value need only be decreased if clusters seem\\n too inclusive and vice-versa, making CLoNe an intuitive algorithm\\n to use in addition to its general applicability.', 'For structural datasets,\\n CLoNe is able to extract clusters as separate trajectories and provides scripts for their automatic loading in the visualization software\\n VMD (Humphrey et al., 1996).', 'For larger macromolecules, the concept of a conformational state is blurry, hard to determine and often\\n depends on context.', 'It is not always clear which features to use to\\n obtain an accurate partition of the structural ensemble.', 'The results\\n obtained on COQ9 can be obtained hypothesis-free on raw spatial\\n coordinates or using PCA to extract relevant features\\n (Supplementary Fig.', 'S4).', 'This was done in the case of APP as well as\\n to reduce an otherwise redundant feature space to one of lower\\n dimensionality.', 'If one wishes to disentangle internal from overall\\n motion, dihedral PCA was used with success to study peptide folding (Altis et al., 2007; Mu et al., 2004).', 'However, when other\\n features than the chosen ones can be expected to exhibit motions of\\n larger amplitudes, PCA will favor the latter over the former.', 'This is\\n true for the TEM1 b-lactamase, where internal structural motions\\n will be more prevalent than the fluctuations of the selected key\\n pocket residues.', 'In such cases, a feature-based approach is to be preferred.', 'Alternatively, some will advocate the use of time-lagged independent component analysis (TICA) (Naritomi and Fuchigami,\\n 2011) instead.', 'TICA was found to be the better alternative for building Markov state models (Husic and Pande, 2018; Pe´rez-Herna´ndez\\n et al., 2013).', 'However, in cases where large amplitude fluctuations\\n are the target or when there is redundancy in features, we believe\\n that PCA remains a safe approach.', 'As the conformational ensembles presented in this study tend to\\n exhibit Gaussian distributions, CLoNe may thus be used to extract\\n cluster centers as higher probability states.', 'Such states offer an overview of the ensemble and may serve as starting models for building\\n Markov state models in general.', 'Moreover, the precision of the classification achieved by CLoNe enables the identification of dominant\\n biological states from large datasets.', 'Beyond the case of APP,\\n CLoNe identified different key pocket conformations in the case of\\n TEM1 b-lactamase.', 'Further clustering efforts on this system should\\n target the different positions of R244, which was not tracked in this\\n study but was previously shown to play a dual role between TEM1’s\\n active site and allosteric pocket (Horn and Shoichet, 2004).', 'CLoNe\\n may then be used as a pre-processing tool prior to small-molecule\\n docking studies, where accounting for receptor flexibility is an active\\n development area (Kokh et al., 2011; Vahl Quevedo et al., 2014).', 'Integrative modeling aims at incorporating data from multiple\\n sources to determine the structure of macromolecular complexes.', 'Such hybrid strategies typically combine low resolution data of\\n whole complexes with high resolution structures of their components so as to predict the quaternary structure of the former\\n (Cassidy et al., 2018).', 'This process is however severely hindered by\\n structural dynamics differing between a complex and its isolated\\n components.', 'For this reason, many hybrid modeling strategies now\\n incorporate some form of dynamics to bridge this gap (Malhotra\\n et al., 2019; Tamo` et al., 2015).', 'While we previously utilized classical MD for the prediction of heptameric aerolysin pores (Degiacomi\\n et al., 2013; Degiacomi and Dal Peraro, 2013), such an approach\\n would not be feasible for heteromultimeric assemblies where\\n Fig.', '4.', 'Identification of different opening states of the allosteric cryptic pocket in TEM1 b-lactamase.', '(a) apo and Holo structures (left and right, respectively).', 'Allosteric inhibitors are shown in gray and white.', 'Features following helical opening include the distance between Ca atoms of N276 and L220 (medium blue) and the Cc of their sidechain\\n (light blue).', 'Pocket depth is monitored by the distance between Ca-carbons of I263 and 279 (dark blue).', '(b) The pocket exposure calculated using the fpocket software for the\\n original replicas (top) and for each clusters (bottom).', 'The dotted line in both is the reference value of the holo crystal structure used in the original paper.', '(c) The center of each\\n cluster in cartoon representation on top of a surface representation of the allosteric pocket, highlighting the different states of helical openness and pocket depth.', 'The triad\\n N276-L220-R244 governing pocket opening and closing are shown as gray sticks.', '(c) The distribution of each feature for each cluster (top) and the cluster assignation along\\n the three chosen replicas (bottom)\\n 6 S.Tra¨ ger et al.', 'Downloaded from https://academic.oup.com/bioinformatics/advance-article/doi/10.1093/bioinformatics/btaa742/5895303 by guest on 19 March 2021\\n multiple conformational ensembles are required simultaneously.', 'Reducing them to their crucial components may enable the structural characterization of large macromolecular complexes, which\\n may otherwise be intractable.', 'Applied to the fields of smallmolecule docking, integrative modeling and structural dynamics\\n studies, CLoNe presents itself as a versatile and powerful tool for\\n modern computational structural biology.', 'Acknowledgements\\n We thank Vladimiras Oleinikovas and Francesco L. Gervasio for providing\\n the simulations of the TEM1 b-lactamase as well as offering general advice;\\n Lucien F. Krapp and Romain Groux for helpful discussions.', 'Funding\\n M.D.P.', 'lab was supported by the Swiss National Science Foundation (grants\\n number 200021_157217 and 31003A_170154).', 'Conflict of Interest: none declared.', 'References\\n Abriata,L.A.', 'and Dal Peraro,M.', '(2020) Will cryo-electron microscopy shift\\n the current paradigm in protein structure prediction?', 'J. Chem.', 'Inf.', 'Model.,\\n 60, 2443–2447.', 'Altis,A.', 'et al.', '(2007) Dihedral angle principal component analysis of molecular\\n dynamics simulations.', 'J. Chem.', 'Phys., 126, 244111.', 'Amaro,R.E.', 'et al.', '(2018) Ensemble docking in drug discovery.', 'Biophys.', 'J.,\\n 114, 2271–2278.', 'Ankerst,M.', 'et al.', '(1999) OPTICS: Ordering Points to Identify the Clustering\\n Structure.', 'In: Proceedings of the 1999 ACM SIGMOD International\\n Conference on Management of Data, SIGMOD ’99, pp.', '49–60.', 'ACM, New\\n York, NY, USA.', 'Audagnotto,M.', 'and Dal Peraro,M.', '(2017) Protein post-translational modifications: in silico prediction tools and molecular modeling.', 'Comput.', 'Struct.', 'Biotechnol.', 'J., 15, 307–319.', 'Audagnotto,M.', 'et al.', '(2016) Effect of the synaptic plasma membrane on the\\n stability of the amyloid precursor protein homodimer.', 'J. Phys.', 'Chem.', 'Lett.,\\n 7, 3572–3578.', 'Barducci,A.', 'et al.', '(2011) Metadynamics.', 'Wiley Interdiscip.', 'Rev.', 'Comput.', 'Mol.', 'Sci., 1, 826–843.', 'Beauchamp,K.A.', 'et al.', '(2012) Simple few-state models reveal hidden complexity in protein folding.', 'Proc.', 'Natl.', 'Acad.', 'Sci.', 'USA, 109, 17807–17813.', 'Bhattacharyya,A.', '(1943) On a measure of divergence between two statistical\\n populations defined by their probability distributions.', 'Bull.', 'Calcutta Math.', 'Soc., 35, 99–109.', 'Bussi,G.', '(2014) Hamiltonian replica exchange in GROMACS: a flexible implementation.', 'Mol.', 'Phys., 112, 379–384.', 'Cassidy,C.K.', 'et al.', '(2018) CryoEM-based hybrid modeling approaches for\\n structure determination.', 'Curr.', 'Opin.', 'Microbiol., 43, 14–23.', 'Chang,H.', 'and Yeung,D.-Y.', '(2008) Robust path-based spectral clustering.', 'Pattern Recogn., 41, 191–203.', 'Chavent,M.', 'et al.', '(2016) Molecular dynamics simulations of membrane proteins and their interactions: from nanoscale to mesoscale.', 'Curr.', 'Opin.', 'Struct.', 'Biol., 40, 8–16.', 'Cheng,L.S.', 'et al.', '(2008) Ensemble-based virtual screening reveals potential\\n novel antiviral compounds for avian influenza neuraminidase.', 'J. Med.', 'Chem., 51, 3878–3894.', 'd’Errico,M.', 'et al.', '(2018) Automatic topography of high-dimensional data sets\\n by non-parametric density peak clustering.', 'arXiv:1802.10549v1 [stat.ML]\\n De Paris,R.', 'et al.', '(2015) Clustering molecular dynamics trajectories for optimizing docking experiments.', 'Comput.', 'Intell.', 'Neurosci., 2015, 1–9.', 'de Souza,V.C.', 'et al.', '(2017) Clustering algorithms applied on analysis of protein molecular dynamics.', 'In: 2017 IEEE Latin American Conference on\\n Computational Intelligence (LA-CCI).', 'Arequipa, 2017, pp.', '1–6.', 'https://doi.', 'org/10.1109/LA-CCI.2017.8285695\\n De Vivo,M.', 'et al.', '(2016) Role of molecular dynamics and related methods in\\n drug discovery.', 'J. Med.', 'Chem., 59, 4035–4061.', 'Degiacomi,M.T.', 'and Dal Peraro,M.', '(2013) Macromolecular symmetric assembly prediction using swarm intelligence dynamic modeling.', 'Structure,\\n 21, 1097–1106.', 'Degiacomi,M.T.', 'et al.', '(2013) Molecular assembly of the aerolysin pore reveals\\n a swirling membrane-insertion mechanism.', 'Nat.', 'Chem.', 'Biol., 9, 623–629.', 'Doerr,S.', 'et al.', '(2016) HTMD: high-throughput molecular dynamics for molecular discovery.', 'J. Chem.', 'Theory Comput., 12, 1845–1852.', 'Du,M.', 'et al.', '(2016) Study on density peaks clustering based on k-nearest neighbors and principal component analysis.', 'Knowl.', 'Based Syst., 99, 135–145.', 'Ester,M.', 'et al.', '(1996) A density-based algorithm for discovering clusters a\\n density-based algorithm for discovering clusters in large spatial databases\\n with noise.', 'In: Proceedings of the Second International Conference on\\n Knowledge Discovery and Data Mining, KDD’96, pp.', '226–231.', 'AAAI\\n Press, Portland, OR, USA.', 'Fonti,G.', 'et al.', '(2019) KAP1 is an antiparallel dimer with a natively functional\\n asymmetry.', 'Life Science Alliance, 2(4), e201900349.', 'Frank,J.', '(2018) New opportunities created by single-particle cryo-EM: the\\n mapping of conformational space.', 'Biochemistry, 57, 888–888.', 'Fra¨nti,P., and Sieranoja,S.', '(2018) K-means properties on six clustering benchmark datasets.', 'Applied Intelligence, 48, 4743–4759.', '10.1007/s10489-\\n 018-1238-7\\n Fig.', '5.', 'Classification and frequency estimation of APP dimerization motifs in the\\n plasma membrane.', '(a) The two known dimerization motifs of the transmembrane\\n helix of APP.', 'Membrane is depicted with gray spheres, the G700G704G708 motif\\n with teal spheres and the G709A713 motif with gold spheres.', '(b) The black line\\n depicts the probability density distribution of the trajectory along the first principal\\n component, which covers 77% of variability.', 'Obtained clusters are shown in colors\\n underneath, with their centers as black stars.', 'Below the clusters is the distribution of\\n core cardinalities, with the corresponding color bar below it.', '(c) The cluster of\\n bound dimers of (b) was extracted and the pair-wise distances between the backbone atoms of each motifs in both helices was computed for every frame.', 'The plot\\n shows the first two principal components of the resulting dataset (with eigenvalues\\n of 0.66 and 0.28, respectively), where each point is color-coded according to the\\n cardinality of its core.', 'Stars represent cluster centers.', '(d) The clusters obtained from\\n the aforementioned dataset of bound conformations.', '(e) Renders of the unbound\\n and dimerized APP cluster centers and their respective frequency after outlier removal.', 'Dimerized APP centers shown correspond to the dark blue, dark brown and\\n dark green clusters.', 'Sidechains have been hidden for better visualization\\n CLoNe: automated clustering of biomolecular structural ensembles 7\\n Downloaded from https://academic.oup.com/bioinformatics/advance-article/doi/10.1093/bioinformatics/btaa742/5895303 by guest on 19 March 2021\\n Fu,L.', 'and Medico,E.', '(2007) FLAME, a novel fuzzy clustering method for the\\n analysis of DNA microarray data.', 'BMC Bioinformatics, 8, 3.', 'Gionis,A.', 'et al.', '(2007) Clustering aggregation.', 'ACM Trans.', 'Knowl.', 'Discov.', 'Data, 1, 4.', 'Hamelberg,D.', 'et al.', '(2004) Accelerated molecular dynamics: a promising and\\n efficient simulation method for biomolecules.', 'J. Chem.', 'Phys., 120,\\n 11919–11929.', 'Horn,J.R.', 'and Shoichet,B.K.', '(2004) Allosteric inhibition through core disruption.', 'J. Mol.', 'Biol, 336, 1283–1291.', 'Humphrey,W.', 'et al.', '(1996) VMD: visual molecular dynamics.', 'J. Mol.', 'Graph,\\n 14, 33–38.', 'Husic,B.E.', 'and Pande,V.S.', '(2018) Markov state models: from an art to a science.', 'J.', 'Am.', 'Chem.', 'Soc., 140, 2386–2396.', 'Husic,B.E.', 'and Pande,V.S.', '(2017) Ward clustering improves cross-validated Markov\\n state models of protein folding.J.', 'Chem.', 'Theory Comput., 13, 963–967.', 'Jain,A.K.', '(2010) Data clustering: 50 years beyond K-means.', 'Pattern Recognit.', 'Lett., 31, 651–666.', 'Jones,E.', 'et al.', '(2001) SciPy: open source scientific tools for Python.', '10.1038/s41592-019-0686-2.', 'Kokh,D.B.', 'et al.', '(2011) Receptor flexibility in small-molecule docking calculations.', 'Wiley Interdiscip.', 'Rev.', 'Comput.', 'Mol.', 'Sci., 1, 298–314.', 'Le Guilloux,V.', 'et al.', '(2009) Fpocket: an open source platform for ligand\\n pocket detection.', 'BMC Bioinformatics, 10, 168.', 'Liang,Z.', 'and Chen,P.', '(2016) Delta-density based clustering with a\\n divide-and-conquer strategy: 3DC clustering.', 'Pattern Recognit.', 'Lett., 73, 52–59.', 'Lohman,D.C.', 'et al.', '(2019) An isoprene lipid-binding protein promotes eukaryotic coenzyme Q biosynthesis.', 'Mol.', 'Cell, 73, 763–774.e10.', 'Lohman,D.C.', 'et al.', '(2014) Mitochondrial COQ9 is a lipid-binding protein\\n that associates with COQ7 to enable coenzyme Q biosynthesis.', 'Proc.', 'Natl.', 'Acad.', 'Sci.', 'USA, 111, E4697–E4705.', 'Malhotra,S.', 'et al.', '(2019) Modelling structures in cryo-EM maps.', 'Curr.', 'Opin.', 'Struct.', 'Biol., 58, 105–114.', 'McGibbon,R.T.', 'et al.', '(2015) MDTraj: a modern open library for the analysis\\n of molecular dynamics trajectories.', 'Biophys.', 'J., 109, 1528–1532.', 'McKiernan,K.', 'A. et al.. (2017) Modeling the mechanism of CLN025 beta--\\n hairpin formation.', 'The Journal of Chemical Physics, 147, 104107.', 'Mehmood,R.', 'et al.', '(2016) Clustering by fast search and find of density peaks\\n via heat diffusion.', 'Neurocomputing, 208, 210–217.', 'Mu,Y.', 'et al.', '(2004) Energy landscape of a small peptide revealed by dihedral\\n angle principal component analysis.', 'Proteins Struct.', 'Funct.', 'Bioinform., 58,\\n 45–52.', 'Naritomi,Y.', 'and Fuchigami,S.', '(2011) Slow dynamics in protein fluctuations\\n revealed by time-structure based independent component analysis: the case\\n of domain motions.', 'J. Chem.', 'Phys., 134, 065101.', 'Noe´,F.', 'et al.', '(2019) Boltzmann generators: sampling equilibrium states of\\n many-body systems with deep learning.', 'Science, 365, eaaw1147.', 'Oleinikovas,V.', 'et al.', '(2016) Understanding cryptic pocket formation in protein targets by enhanced sampling simulations.', 'J.', 'Am.', 'Chem.', 'Soc., 138,\\n 14257–14263.', 'Paris,R.D.', 'et al.', '(2015) An effective approach for clustering InhA molecular\\n dynamics trajectory using substrate-binding cavity features.', 'PLoS One, 10,\\n e0133172.', 'Pedregosa,F.', 'et al.', '(2011) Scikit-learn: machine learning in Python.', 'J. Mach.', 'Learn.', 'Res., 12, 2825–2830.', 'Peng,J.', 'et al.', '(2018) Clustering algorithms to analyze molecular dynamics\\n simulation trajectories for complex chemical and biological systems.', 'Chin.', 'J. Chem.', 'Phys., 31, 404–420.', 'Pe´rez-Herna´ndez,G.', 'et al.', '(2013) Identification of slow molecular order\\n parameters for Markov model construction.', 'J. Chem.', 'Phys., 139, 015102.', 'Rodriguez,A.', 'et al.', '(2018) Computing the free energy without collective variables.', 'J. Chem.', 'Theory Comput., 14, 1206–1215.', 'Rodriguez,A.', 'and Laio,A.', '(2014) Clustering by fast search and find of density\\n peaks.', 'Science, 344, 1492–1496.', 'Salmaso,V., and Moro,S.', '(2018) Bridging molecular docking to molecular dynamics in exploring ligand-protein recognition process: an overview.', 'Front.', 'Pharmacol, 9, 923.', 'Seabold,S.', 'and Perktold,J.', '(2010) Statsmodels: econometric and statistical\\n modeling with python.', 'In: 9th Python in Science Conference.', 'https://www.', 'statsmodels.org/devel/#citation.', 'Shao,J.', 'et al.', '(2007) Clustering molecular dynamics trajectories: 1.', 'Characterizing the performance of different clustering algorithms.', 'J. Chem.', 'Theory Comput., 3, 2312–2334.', 'Shirts,M.', 'and Pande,V.S.', '(2000) Screen savers of the World Unite!', 'Science,\\n 290, 1903–1904.', 'Sultan,M.M.', 'et al.', '(2018) Transferable neural networks for enhanced sampling of protein dynamics.', 'J. Chem.', 'Theory Comput., 14, 1887–1894.', 'Tamo`,G.E.', 'et al.', '(2015) The importance of dynamics in integrative modeling\\n of supramolecular assemblies.', 'Curr.', 'Opin.', 'Struct.', 'Biol., 31, 28–34.', 'Vahl Quevedo,C.', 'et al.', '(2014) A strategic solution to optimize molecular\\n docking simulations using Fully-Flexible Receptor models.', 'Expert Syst.', 'Appl., 41, 7608–7620.', 'Wang,W.', 'et al.', '(2018) Constructing Markov state models to elucidate the\\n functional conformational changes of complex biomolecules.', 'Wiley\\n Interdiscip.', 'Rev.', 'Comput.', 'Mol.', 'Sci., 8, e1343.', 'Wang,X.-F. and Xu,Y.', '(2017) Fast clustering using adaptive density peak detection.', 'Stat.', 'Methods Med.', 'Res., 26, 2800–2811.', 'Ward,J.H.', '(1963) Hierarchical grouping to optimize an objective function.', 'J.', 'Am.', 'Stat.', 'Assoc., 58, 236–244.', 'Wassenaar,T.A.', 'et al.', '(2015) High-throughput simulations of dimer and trimer assembly of membrane proteins.', 'the DAFT Approach.', 'J. Chem.', 'Theory\\n Comput., 11, 2278–2291.', 'Wolf,A.', 'and Kirschner,K.N.', '(2013) Principal component and clustering analysis on molecular dynamics data of the ribosomal L11\\x0523S subdomain.', 'J.\\n Mol.', 'Model., 19, 539–549.', 'Xie,J.', 'et al.', '(2016) Robust clustering by detecting density peaks and assigning\\n points based on fuzzy weighted K-nearest neighbors.', 'Inf.', 'Sci., 354, 19–40.', 'Zhang,W.', 'and Li,J.', '(2015) Extended fast search clustering algorithm: widely\\n density clusters, no density peaks.', 'arXiv:1505.05610 [cs.DS].', '8 S.Tra¨ ger et al.', 'Downloaded from https://academic.oup.com/bioinformatics/advance-article/doi/10.1093/bioinformatics/btaa742/5895303 by guest on 19 March 2021'][' Structural bioinformatics\\n CLoNe: automated clustering based on local density\\n neighborhoods for application to biomolecular structural\\n ensembles\\n Sylvain Tra¨ ger1,2, Giorgio Tamo` 1,2, Deniz Aydin1,2, Giulia Fonti1,2,\\n Martina Audagnotto1,2 and Matteo Dal Peraro1,2,*\\n 1\\n Institute of Bioengineering, School of Life Sciences, Ecole Polytechnique Fe´ de´ rale de Lausanne, Lausanne 1025, Switzerland and 2\\n Swiss Institute of Bioinformatics, Lausanne 1015, Switzerland\\n *To whom correspondence should be addressed.', 'Associate Editor: Lenore Cowen\\n Received on January 8, 2020; revised on July 14, 2020; editorial decision on August 12, 2020; accepted on August 18, 2020\\n Abstract\\n Motivation: Proteins are intrinsically dynamic entities.', 'Flexibility sampling methods, such as molecular dynamics or\\n those arising from integrative modeling strategies, are now commonplace and enable the study of molecular conformational landscapes in many contexts.', 'Resulting structural ensembles increase in size as technological and algorithmic advancements take place, making their analysis increasingly demanding.', 'In this regard, cluster analysis\\n remains a go-to approach for their classification.', 'However, many state-of-the-art algorithms are restricted to specific\\n cluster properties.', 'Combined with tedious parameter fine-tuning, cluster analysis of protein structural ensembles\\n suffers from the lack of a generally applicable and easy to use clustering scheme.', 'Results: We present CLoNe, an original Python-based clustering scheme that builds on the Density Peaks algorithm\\n of Rodriguez and Laio.', 'CLoNe relies on a probabilistic analysis of local density distributions derived from nearest\\n neighbors to find relevant clusters regardless of cluster shape, size, distribution and amount.', 'We show its capabilities on many toy datasets with properties otherwise dividing state-of-the-art approaches and improves on the original algorithm in key aspects.', 'Applied to structural ensembles, CLoNe was able to extract meaningful conformations from membrane binding events and ligand-binding pocket opening as well as identify dominant dimerization\\n motifs or inter-domain organization.', 'CLoNe additionally saves clusters as individual trajectories for further analysis\\n and provides scripts for automated use with molecular visualization software.', 'Availability and implementation: www.epfl.ch/labs/lbm/resources, github.com/LBM-EPFL/CLoNe.', 'Contact: matteo.dalperaro@epfl.ch\\n Supplementary information: Supplementary data are available at Bioinformatics online.', '1 Introduction\\n The perception of molecular structures, especially proteins, is gradually shifting from the concept of one single and rigid structure to\\n the idea that biomolecules natively exhibit a continuum of states\\n (Frank, 2018).', 'Protein folding, post-translational modifications\\n (Audagnotto and Dal Peraro, 2017), binding to other molecules or\\n their involvement in catalytic events result in vast and complex conformational landscapes.', 'Molecular dynamics (MD), thanks to progress in both its technological and algorithmic aspects, allows for\\n the simulation of key biomolecular events.', 'Their observability, however, tends to be limited by currently accessible timescales.', 'Researchers consistently come up with innovative protocols to push\\n this limit further (Barducci et al., 2011; Bussi, 2014; Chavent et al.,\\n 2016; Doerr et al., 2016; Hamelberg et al., 2004; Noe´ et al., 2019;\\n Shirts and Pande, 2000; Sultan et al., 2018; Wassenaar et al., 2015)\\n granting us with the ability to capture protein folding as well as protein–protein, protein–membrane and protein–ligand interactions\\n (Audagnotto et al., 2016; De Vivo et al., 2016; McKiernan et al.,\\n 2017; Oleinikovas et al., 2016).', 'State-of-the-art protocols for smallmolecule docking (Amaro et al., 2018; Kokh et al., 2011; Vahl\\n Quevedo et al., 2014), protein–protein docking and integrative\\n modeling strategies, in general, have shifted toward the integration\\n of dynamics in some form as well (Abriata and Dal Peraro, 2020;\\n Malhotra et al., 2019; Tamo` et al., 2015).', 'All of the aforementioned\\n aspects advocate dynamics as a cornerstone of modern structural\\n biology and push the need for efficient tools to extract functional insight from structural ensembles in general.', 'VC The Author(s) 2020.', 'Published by Oxford University Press.', '1\\n This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (http://creativecommons.org/licenses/by-nc/4.0/),\\n which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited.', 'For commercial re-use, please contact\\n journals.permissions@oup.com\\n Bioinformatics, 2020, 1–8\\n doi: 10.1093/bioinformatics/btaa742\\n Advance Access Publication Date: 21 August 2020\\n Original Paper\\n Downloaded from https://academic.oup.com/bioinformatics/advance-article/doi/10.1093/bioinformatics/btaa742/5895303 by guest on 19 March 2021\\n However, these advances come at a price.', 'The sheer size, the intrinsic complexity and redundancy of structural ensembles makes\\n their successful analysis and computational integration non-trivial.', 'Coarse-graining tools such as cluster analysis effectively reduce simulations of thousands of conformations to few key biological states\\n and hence constitute a go-to approach with countless applications to\\n date [(Cheng et al., 2008; De Paris et al., 2015; de Souza et al.,\\n 2017), reviewed in (Peng et al., 2018; Shao et al., 2007)].', 'Such states\\n may serve as basis of Markov state models (Husic and Pande, 2018;\\n Wang et al., 2018).', 'To our knowledge, however, an algorithm able\\n to cluster data efficiently irrespective of their properties is still missing.', 'Indeed, different cluster shapes, sizes and densities usually dictate which clustering approach is best suited for a given task.', 'The\\n most known and widely used scheme is probably that of k-means\\n and its many variations (Jain, 2010).', 'This center-based clustering\\n scheme, however, suffers from unequal results due to random initializations, the a priori setting of the number of clusters and its limitation to spherical clusters.', 'Alternatively, hierarchical schemes such as\\n the Ward-linkage agglomerative algorithm (Ward, 1963) do not require pre-setting the number of clusters and are popular for building\\n Markov state models (Beauchamp et al., 2012; Husic and Pande,\\n 2017; Paris et al., 2015).', 'They are however sensitive to noise and\\n outliers and may suffer from non-spherical clusters (Peng et al.,\\n 2018).', 'Conversely, DBSCAN (Ester et al., 1996) is able to manage\\n clusters regardless of shape by utilizing density differences between\\n clusters and noise.', 'However, setting its parameter is not trivial and\\n its optimal value may not be unique throughout the dataset when\\n clusters of largely different densities are present.', 'This limitation is at\\n the core of OPTICS, which can be seen as an extension of DBSCAN\\n (Ankerst et al., 1999), although not strictly advertised as a clustering\\n algorithm.', 'Defining metastable states of proteins is non-trivial due to the\\n large and often redundant number of internal degrees of freedom,\\n yielding sampled conformational spaces with local minima often devoid of biological significance.', 'We can make the assumption that,\\n given enough sampling and a choice of relevant features, metastable\\n states would lie in regions or clusters of high density, which would\\n be separated by valleys of different density levels that would correspond to transitional states.', 'Furthermore, no assumption can be\\n made on the shape or relative densities of clusters, which would depend on both conformational sampling and target system.', 'Rodriguez and Laio (2014) designed the Density Peaks (DP) algorithm aimed at clustering regardless of shape and dimensionality.', 'Their algorithm generated significant interest thanks to their clever\\n definition of cluster centers, which states that a cluster center should\\n display a higher density (q) than its neighbors and a high distance to\\n another point of higher density (d).', 'DP takes a single input parameter, which relates to a cutoff distance for the computation of q.', 'However, it requires the user to specify thresholds for both q and d\\n mid-computation in order to select the cluster centers, which prevents a fully automated clustering process.', 'DP has since been\\n improved by the inclusion of k nearest neighbors (kNN) (Du et al.,\\n 2016; Xie et al., 2016; Zhang and Li, 2015) or heat diffusion\\n (Mehmood et al., 2016) for a more robust estimation of q, which\\n allows for a better handling of cases where clusters have significantly different densities.', 'These improvements still require user intervention for selecting cluster centers.', 'Conversely, Wang and Xu (2017)\\n built on DP to automatically select cluster centers based on maximizing an average silhouette index, although other input parameters\\n are required instead.', 'Liang and Cheng coupled principles from\\n DBSCAN with a divide-and-conquer approach to recursively and\\n automatically select cluster centers (Liang and Chen, 2016).', 'Recently, d’Errico et al.', 'coupled DP with a non-parametric density\\n estimator (Rodriguez et al., 2018), yielding Density Peaks Advanced\\n (DPA; d’Errico et al., 2018).', 'While exhibiting impressive robustness\\n to a variety of cluster shapes, densities and to outliers, DPA still suffers from a few issues.', 'We found that it performed worse than the\\n original on some typical benchmark datasets, and requires a sensitive albeit unique input parameter.', 'Moreover, both DP and DPA exhibit an inconsistent outlier removal procedure.', 'These drawbacks\\n may prove crucial when targeting structural biological data, where\\n regions at lower effective density may have equal or even increased\\n significance than others at higher densities.', 'The complexity of biological structures leads to numerous unique yet equally relevant\\n choices of features, each with their own topology.', 'The analysis of\\n such datasets is greatly hindered by sensitivity to input parameters,\\n which implies that tedious fine-tuning steps have to be undertaken.', 'Here, we introduce an approach to remedy these drawbacks,\\n enabling a facilitated analysis of complex real-world datasets from\\n structural biology.', 'Our approach builds on the original DP algorithm by introducing a fragmenting of the data into specific density\\n distributions.', 'In essence, the local densities of each point are computed using nearest neighbors and a Gaussian kernel and points\\n associated with local density maxima are identified as putative cluster centers.', 'To increase robustness to non-spherical cluster shapes,\\n clusters are merged using the Bhattacaryaa coefficient\\n (Bhattacharyya, 1943) by comparing density distributions derived\\n from putative cluster cores and boundaries.', 'Finally, outliers from\\n impromptu noise fluctuations are removed by means of a Bayes classifier.', 'This, to the best of our knowledge, constitute an original contribution to the density peaks algorithm.', 'Termed Clustering based\\n on Local density Neighborhoods (CLoNe), our approach relies on a\\n single input parameter that is both robust and intuitive to set.', 'We\\n test it on many typical benchmark datasets and against state-of-theart clustering schemes.', 'The local focus of CLoNe allows for the detection of biological states of smaller frequency while its ease of use\\n allows the researcher to focus on choosing relevant biological features for pre-processing or analyzing their structural ensemble without being hindered by algorithmic limitations.', 'Furthermore, CLoNe\\n outputs useful molecular visualization scripts for the validation of\\n cluster relevance in the target biological context (Supplementary Fig.', 'S1).', 'We apply CLoNe on a range of structural datasets from MD\\n simulations or integrative modeling studies, each time detailing the\\n feature selection process and which information can be extracted\\n from the results.', 'Our examples cover previously published studies\\n on protein–membrane interactions, internal structural rearrangements of disordered proteins, cryptic allosteric pocket formation and\\n transmembrane dimerization motifs, and highlight the broad advantages of CLoNe for the analysis of molecular structural ensembles.', '2 Materials and methods\\n An overview and basic usage of CLoNe is available in\\n Supplementary Figure S1, on GitHub and the webpage of our laboratory (see Abstract section).', 'We created a synthetic dataset containing clusters of significantly different densities and various shapes\\n in order to showcase the procedure behind our approach.', 'CLoNe\\n starts by finding the k nearest neighbors of each point in a dataset X\\n of N points using k-nearest neighbors (kNN) (Pedregosa et al.,\\n 2011), yielding a neighbor matrix M where each row i contains all\\n the neighbors j of point i in increasing order of Euclidean distance.', 'To account for significant density differences between clusters, we\\n initially assume that all points are cluster centers.', 'In a first step, we\\n estimate the local density q of each point i using a Gaussian kernel:\\n qi ¼ X\\n jkNNi\\n e\\n  Mi;j\\n dc\\n  2\\n ¼ X\\n jkNNi\\n qij (1)\\n where kNNi is the set of nearest neighbors of i in increasing order of\\n distance and dc is a cutoff distance defined as to be superior to a\\n user-defined percentage pdc (the single input parameter of CLoNe)\\n of all distances within M, similar to the original DP algorithm\\n (Rodriguez and Laio, 2014).', 'We define the core of putative cluster i\\n as the set of neighbors that contribute to qi at least as much of the\\n j1 previous neighbors on average:\\n corei ¼ j  kNNijqij\\n 1\\n pdcN\\n Xj1\\n k¼0 qik \\x04 \\x05 (2)\\n We show in Figure 1a the cardinality (number of elements) of\\n the core of each point in our synthetic dataset.', 'As expected, this\\n 2 S.Tra¨ ger et al.', 'Downloaded from https://academic.oup.com/bioinformatics/advance-article/doi/10.1093/bioinformatics/btaa742/5895303 by guest on 19 March 2021\\n number is higher for points closer to real cluster centers and lower\\n for points laying on the outskirt of clusters.', 'The visualization of core\\n cardinalities is an efficient way to observe the underlying topology\\n of the dataset.', 'In order to identify if i is a genuine candidate for cluster center, we identify its first neighbor j of higher density.', 'If neighbor j belongs to corei, then neighbor j is a better candidate for\\n cluster center in this region than i. Conversely, i is a genuine candidate for cluster center if j is not in the core of i.', 'Cluster assignation\\n is done in a single step by assigning a point to the same cluster as its\\n nearest point of higher density, in order of decreasing local density,\\n similar to the original DP approach.', 'The results at this stage of\\n CLoNe are shown in Figure 1a.', 'One of the drawbacks of the DP algorithm is its limited ability to\\n deal with clusters with more than one peak or those with an elongated region of similar density, such as the noisy circles benchmark\\n dataset (Supplementary Fig.', 'S2).', 'This is true at this stage of CLoNe\\n as well, as the Gaussian kernel in (1) is biased toward determining\\n cores with spherical shapes (Fig.', '1b).', 'We can make the assumptions\\n that if two existing clusters A and B should be merged, then the\\n density from one core to the other should be relatively constant.', 'This can be estimated by looking at the core cardinality distribution\\n of the points belonging to the core of both clusters as well as that of\\n the points from the boundary between them (Fig.', '1b, left), which\\n can be defined as:\\n boundaryAB ¼ i 2 A; j 2 Bjd ið Þ ; j < dcg \\x06 (3)\\n Then, we define the following probability density function for\\n the ensemble of points belonging to either cluster cores or the\\n boundary from (3):\\n Ps ¼ KDE corei ð Þ f g ; i 2 S (4)\\n where S denotes one of the aforementioned ensembles and #corei the\\n core cardinality of point i and KDE refers to the probability density\\n function estimated by unimodal Gaussian kernel density estimation.', 'Similarity between probability distributions can be measured using\\n the Bhattacharyya coefficient (BC) (Bhattacharyya, 1943), which is\\n bound between 0 and 1.', 'Thus, the formula to compute the BC between the core of cluster A with the boundary from (3) becomes:\\n BCA ¼ ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\\n PboundPcoreA\\n p (5)\\n We take the decision of merging Clusters A and B if the mean of\\n their respective BC with their boundary is above a threshold sBC:\\n B Að Þ ; B ¼ 1\\n 2 ð Þ BCA þ BCB > sBC (6)\\n where PcoreB is obtained as for cluster A in (5) and sBC was chosen to\\n be the 65th percentile to limit uncertainty and based on benchmarks\\n (Fig.', '1 and Supplementary Fig.', 'S2).', 'Taking the mean of both coefficients prevents the merging of a cluster whose probability density is\\n similar to that of its boundary with a cluster of significantly higher\\n density.', 'This enabled us to identify clusters that can hardly be\\n defined with a single density peak, such as uniform density over\\n non-spherical shapes (Figs 1b and 2a).', 'The point with highest q is\\n chosen as the new cluster center.', 'If pdc is chosen too small, clusters\\n may be split into sub-clusters.', 'Within our approach, these subclusters are likely to be merged into clusters matching the original\\n topology, expanding the range of acceptable values for pdc and making it an input parameter less sensitive than the one of DPA\\n (Supplementary Fig.', 'S3).', 'The second drawback of using the Gaussian kernel in (1) is that\\n it may falsely identify impromptu local noise fluctuations as cluster\\n centers (Fig.', '1b).', 'To remedy this, we define two probability density\\n functions.', 'Mcores is the probability density of the local density of all\\n points belonging to any cluster core as per (2):\\n Mcores ¼ KDEð qx f g ; x 2 corei 8i 2 C Þ (7)\\n where C is the set of cluster centers remaining after the previous\\n merging step.', 'Moutliers is the equivalent function for all points identified as outliers:\\n Moutliers ¼ KDEð qx; x 2 X if qx < f \\x04 qcenterx\\n \\x06 \\x08Þ (8)\\n where qcenterx is the local density of the center of the cluster x\\n belongs to and f an arbitrary fraction chosen to be 0.1 by default\\n and used throughout this article.', 'To determine if an identified cluster is more probable to be derived from noise than to be a genuine\\n cluster, we use a Bayesian classifier.', 'For each cluster core ci, we derive the following posterior probabilities using Bayes’ theorem:\\n p Yð Þ¼ jci\\n p Yð Þ pðcijYÞ\\n pðciÞ ; Y 2 f g outliers; cores (9)\\n where the prior probabilities are defined as follows:\\n Fig.', '1.', 'Clustering based on local density neighborhoods.', 'We created a synthetic\\n dataset that contains four croissant-shaped clusters of 500 elements each with different scaling as well as a cluster in the shape of a cross with 4000 elements and added\\n Gaussian noise.', '(a) On the left, the cardinality of the core of each point in the dataset.', 'On the right, the clusters obtained after the first stage of clustering.', '(b) The average Bhattacaryya coefficient B(A,B) between two Clusters A and B is shown.', 'The\\n upper left plots show an example of two clusters being merged corresponding to the\\n upper square in panel (a).', 'The lower left plots show an example of two clusters that\\n will not be merged corresponding to the lower square in panel (a).', 'Points belonging\\n to the core of each cluster are shown in black, regular points in shades of gray and\\n points belonging to the boundary in red.', 'The plot on the right shows the clustering\\n after merging clusters.', '(c) CLoNe uses a Bayesian classifier to decide if a cluster is\\n genuine or arises from noise fluctuations.', 'On the left, the corresponding probability\\n density functions of points belonging to any cluster cores (black), noise (blue), or to\\n individual cluster cores (light blue).', 'The range of local density of clusters classified\\n as noise fluctuations are shown on the secondary y-axis (dark blue).', 'The final clustering result is shown on the right, with identified outliers shown as black crosses\\n CLoNe: automated clustering of biomolecular structural ensembles 3\\n Downloaded from https://academic.oup.com/bioinformatics/advance-article/doi/10.1093/bioinformatics/btaa742/5895303 by guest on 19 March 2021\\n p Yð Þ ¼ jYj\\n N ; Y 2 f g outliers; cores (10)\\n where jYj denotes the cardinality of the corresponding class.', 'The\\n likelihoods pðcijYÞ can be computed by evaluating the previously\\n defined probability distributions (7) and (8) at ci.', 'Disregarding the\\n evidence pðciÞ common for both outliers and cores classes, we thus\\n obtain the following Bayesian classifier:\\n y^i ¼ argmax Y2f g outliers; cores\\n p Yð ÞY\\n x2ci\\n MYðqxÞ (11)\\n This classifier enabled us to remove all cluster centers arising\\n from noise fluctuations.', 'Combined with the previous merging step,\\n the clustering is now complete (Fig.', '1c).', 'The software has been written using Python3.7.', 'When used on\\n structural biological data, CLoNe outputs cluster centers as separate\\n PDB files, individual clusters as XTC trajectories and Tcl scripts for\\n automated loading within the visualization software VMD (Visual\\n Molecular Dynamics, (Humphrey et al., 1996)).', 'The loading of MD\\n trajectories as well as the saving of cluster centers and cluster subtrajectories is done through the MDTraj package (McGibbon et al.,\\n 2015).', 'We use the scipy (Jones et al., 2001), scikit-learn (Pedregosa\\n et al., 2011) and Statsmodels (Seabold and Perktold, 2010) packages\\n for many operations described in the previous subsection and to\\n compare CLoNe to other clustering algorithms.', '3 Results\\n 3.1 Automatic cluster center determination from local\\n density neighborhood analysis\\n We applied CLoNe to a large set of common benchmark datasets\\n from various sources (Chang and Yeung, 2008; d’Errico et al., 2018;\\n Fra¨nti and Sieranoja, 2018; Fu and Medico, 2007; Gionis et al.,\\n 2007; Pedregosa et al., 2011), covering different key properties of\\n clusters, such as non-spherical shapes, anisotropy, as well as significant size and density differences, all of which can be expected from\\n real-world datasets from structural biology.', 'In the previous section,\\n we detailed how CLoNe automatically detects cluster centers, accurately merges clusters and removes outliers, succeeding in cases where\\n previous iterations of DP did not (Fig.', '2a and Supplementary Fig.', 'S2).', 'Similarly to the original DP algorithm (Rodriguez and Laio,\\n 2014), CLoNe requires a single input parameter pdc, which relates\\n to a cutoff distance used in the estimation of local densities (see\\n Section 2).', 'In general, pdc takes a value in a small range and is\\n intuitive to set.', 'For instance, with pdc values of 1 or 2 local densities\\n will be estimated considering neighborhoods small enough to identify individual spiral branches as clusters (Fig.', '2b).', 'For higher values\\n of pdc, the scale of the Gaussian kernel in Equation (1) will increase\\n and merge individual branches into whole spirals, allowing the study\\n of multiple hierarchies intuitively (Fig.', '2c).', 'Other than clusters with\\n non-spherical shapes, CLoNe identifies successfully the numerous\\n Gaussian clusters of the A3 dataset (Fig.', '2d).', 'Some degree of overlapping in real-world datasets is to be expected.', 'The S4 dataset contains 15 highly overlapping Gaussian clusters of varying densities\\n and shapes but equal size.', 'As with the A3 dataset, CLoNe does not\\n perform unnecessary merging with nearby clusters (Fig.', '2e) and is\\n robust to large amounts of outliers on top of clusters with significantly different densities (Fig.', '2f).', 'This general applicability of\\n CLoNe coupled with a single, robust and easy to set input parameter\\n (Supplementary Fig.', 'S3) is unique among the commonly used clustering algorithms found in the Scikit-learn package (Pedregosa et al.,\\n 2011).', 'In fact, CLoNe is among the fastest algorithms from that\\n package in addition to both DP and DPA and the most accurate on\\n the available benchmark cases (Supplementary Fig.', 'S2).', 'The only\\n other algorithm succeeding on all benchmark cases is OPTICS\\n (Ankerst et al., 1999), which runs slightly slower than CLoNe on\\n these datasets and tends to classify too many points as outliers.', 'Similar to the original implementation of DP, CLoNe is applicable\\n to high dimensionality datasets as well (Supplementary Table S1\\n and Supplementary Fig.', 'S4).', 'One of the principal aims of this work is to offer a clustering algorithm able to classify unlabeled biological structural ensembles\\n into relevant states associated with their function and mechanism of\\n action.', 'We have applied CLoNe to real-world structural biology\\n data reporting on the dynamic conformational space of a protein\\n that associates with its specific biological membrane, cryptic allosteric pocket opening and dimerization of transmembrane proteins.', '3.2 Determining relevant states within protein\\n conformational ensembles\\n COQ9 is a lipid-binding protein associated with the biosynthesis of\\n coenzyme Q (CoQ), a redox-active lipid that is essential for cellular\\n respiration (Lohman et al., 2014).', 'Recently, coarse-grained molecular dynamics (CG-MD) simulations and liposome co-flotation assays\\n were used together to reveal that COQ9 accesses membranes in a\\n multi-step fashion through a distinct, C-terminal amphipathic helix\\n (a10) (Lohman et al., 2019).', 'In these simulations, COQ9 first diffused in the aqueous environment, then underwent various\\n Fig.', '2.', 'Local neighborhood density analysis for automated center and cluster determination.', 'For each panel, the cardinality of the core of each point as detailed in the Section 2\\n is shown on the left.', 'The resulting clusters are shown on the right, with clusters in different colors and identified outliers as black crosses.', '(a) Noisy circles dataset.', '(b and c)\\n Four instances of spiral dataset with different values of the input parameter yielding different yet valid clusters.', '(d) The a3 dataset containing 50 Gaussian clusters.', '(e) The s4\\n dataset with highly overlapping Gaussian clusters, some with anisotropic distributions.', '(f) A synthetic dataset with clusters of significantly different sizes and densities taken\\n from Density Peaks Advanced\\n 4 S.Tra¨ ger et al.', 'Downloaded from https://academic.oup.com/bioinformatics/advance-article/doi/10.1093/bioinformatics/btaa742/5895303 by guest on 19 March 2021\\n conformational changes upon membrane binding (Lohman et al.,\\n 2019).', 'We applied CLoNe to the CG-MD trajectory used in the latter study and sought to identify the main binding events pertaining\\n to the protein itself.', 'To this end, we extracted features characterizing both its movements in the aqueous environment through monitoring its distance to the membrane as well as key conformational\\n changes based on the angle between the unique a10 helix of COQ9\\n and its globular domain (Fig.', '3a, left).', 'Using these two features,\\n CLoNe outputs three clusters, each of which seem to follow\\n Gaussian distributions (Fig.', '3b).', 'One cluster regroups all conformations that correspond to diffusion movements in the aqueous environment, while the other two highlight the membrane association of\\n a10 first followed by the globular domain as a converging step\\n (Fig.', '3a), thus its higher density (Fig.', '3b).', 'Similar results can be\\n obtained hypothesis-free by using raw atomic spatial coordinates\\n (Supplementary Fig.', 'S4).', 'The Gaussian distribution of structural\\n clusters has also been observed in a recent study from our group\\n involving the KAP1 protein, where CLoNe was also successfully\\n applied (Supplementary Fig.', 'S5) (Fonti et al., 2019).', '3.2 Isolating sub-ensembles of relevant conformations\\n for ligand–target interactions\\n In recent years, small-molecule docking software is no stranger to\\n dynamics, taking into account ensembles of ligand conformations\\n (Amaro et al., 2018) or receptor flexibility (Kokh et al., 2011;\\n Salmaso and Moro, 2018; Vahl Quevedo et al., 2014).', 'A recent\\n study highlighted a novel replica exchange-based MD protocol combined with benzene probes, where each replica harbors a different\\n scaling of water–protein interactions (Oleinikovas et al., 2016).', 'Using this method, the authors could observe the opening of cryptic\\n allosteric pockets in several systems, including that of the TEM1 blactamase, which plays a critical role in antibiotic resistance (Horn\\n and Shoichet, 2004).', 'The simulations were started from the apo\\n crystal structure with a closed allosteric pocket (Fig.', '4a).', 'Out of the\\n eight replicas of the simulation, we chose three with neutral (first),\\n medium (fourth) and highest (last) scaling factors as a tradeoff between maximizing the sampled conformational space and limiting\\n redundancy of the over-represented closed conformations\\n (Oleinikovas et al., 2016) (Fig.', '4b).', 'Along with key residue R244 on\\n the opposite wall of the pocket, the opening of a-helices H11 and\\n H12 and key residues L220 and N276 dictate pocket opening and\\n allow two inhibitors to be accommodated (Horn and Shoichet,\\n 2004), while the three mentioned residues form a triad when the\\n pocket is closed.', 'In addition to the opening of the two helices, visual\\n inspection of the simulations indicated a deepening of the pocket.', 'As\\n a result, we chose features tracking the distance between the Ca of\\n residues L220 and N276 as well as that of their sidechains to monitor pocket opening as well as the distance between the Ca of I263\\n and I279 as a measure of pocket depth (Fig.', '4a).', 'The original study\\n used fpocket (Le Guilloux et al., 2009) to monitor pocket exposure\\n in each replica (Fig.', '4b, top).', 'The same was done on the clusters\\n obtained by CLoNe (Fig.', '4b, bottom), showing different levels of\\n pocket openness.', 'Corresponding cluster centers highlight key structural differences between each state (Fig.', '4c), which are representative of the feature distribution per cluster (Fig.', '4d, top).', 'Cluster\\n assignation follows the observation of the original publication,\\n where open states were more prevalent in the replica of medium\\n scaling (Fig.', '4d, bottom).', '3.3 Identifying dominant conformational motifs in\\n protein oligomerization\\n Another challenge in structural biology is the understanding of how\\n biomolecules oligomerize to distinctive functional states.', 'One of\\n these cases, the transmembrane a-helix of the Amyloid Precursor\\n Protein (termed APP hereafter), has recently been studied by our lab\\n through the high-throughput MD protocol DAFT (Docking Assay\\n For Transmembrane components, (Wassenaar et al., 2015)) in order\\n to identify which of two dimerization motifs is promoted depending\\n on the lipid composition of the synaptic plasma membrane\\n (Audagnotto et al., 2016).', 'The G700G704G708 motif is thought to\\n direct the binding of APP to regulators promoting cholesterol biosynthesis, while the G709A713 motif would bind to cholesterol molecules (Fig.', '5a).', 'Extracting features from molecular datasets is not\\n always straightforward.', 'Macromolecular movements possess an inherent redundancy due to the sheer number of internal degrees of\\n freedom or prior knowledge may be lacking in order to select meaningful features, such as those highlighted in Figures 3 and 4.', 'The use\\n of dimensionality reduction methods, such as principal component\\n analysis (PCA) has been seen for clustering of MD simulations\\n (Wolf and Kirschner, 2013) and can help identifying coordinates of\\n significance while discarding less useful dimensions.', 'The DAFT simulations of APP from (Audagnotto et al., 2016) are over 2 ms in total\\n and contain countless states, many corresponding to unbound\\n monomers.', 'The first principal component based on the Cartesian\\n coordinates of the coarse grain backbone covers 77% of the variability in the simulation, highlighting two clusters (Fig.', '5b).', 'The\\n blue cluster of lower amplitude corresponds to all states exhibiting\\n unbound monomers (Fig.', '5e, left), while the second cluster regroups\\n all the dimerized states regardless of motif.', 'Focusing on that cluster,\\n we calculated the pair-wise distances between the backbone atoms\\n of each motifs in both helices (Fig.', '5a) and reduced these features to\\n a two-dimensional principal space covering 94% of the variability\\n before clustering (Fig.', '5c).', 'We want to highlight CLoNe’s ability to\\n analyze the neighborhood of low-density clusters without influence\\n from high-density regions (Fig.', '5c and Supplementary Table S2).', 'Clusters in blue in Figure 5d all depict states close to the\\n G700G704G708 motifs and those in green the G709A713 motif.', 'In the\\n middle are two clusters, shown in brown, that we interpret as hybrid.', 'In all cases, the darker-shaded clusters of each group correspond to the closest to the optimal motif arrangement, while the\\n others can be considered as closely related metastable states\\n (Supplementary Fig.', 'S6).', 'Similar to the original study (Audagnotto\\n Fig.', '3.', 'Utilizing Gaussian cluster properties to extract centers as key biological states of the COQ9 membrane protein.', '(a) COQ9 and its associated features, which include an\\n internal angle h and its distance to the membrane d (left).', 'Cluster centers are shown on the right side of the panel.', '(b) Every frame is plotted in the mentioned feature space and\\n color coded according to their core cardinality (left) and cluster assignation (right), which follows the same color code as in (a).', 'Outliers are shown as black crosses and centers\\n as black stars\\n CLoNe: automated clustering of biomolecular structural ensembles 5\\n Downloaded from https://academic.oup.com/bioinformatics/advance-article/doi/10.1093/bioinformatics/btaa742/5895303 by guest on 19 March 2021\\n et al., 2016), CLoNe finds the preferred dimerization motif to be\\n G700G704G708 as evidenced by the corresponding centers’ local densities, cluster population and core cardinality (Fig.', '5c and\\n Supplementary Table S2).', 'A comparison between CLoNe and other\\n state-of-the-art algorithms on all the structural data shown in this\\n section demonstrates the advantages of CLoNe for analysis of molecular structural ensembles (Supplementary Fig.', 'S7).', '4 Discussion\\n Many clustering methods rely on parameters that are often nontrivial to optimize or on random initial conditions that may drastically change the outcome.', 'Commonly used algorithms are generally\\n restricted to specific cluster properties, forcing the researcher\\n through a process of trial and error.', 'Moreover, choosing relevant\\n features from structural datasets is challenging and different features\\n may generate different cluster topologies, sometimes irrelevant.', 'CLoNe was designed with these issues in mind and aims to provide\\n a stream-lined analytic process to yield results rapidly along with\\n helpful visualization scripts to analyze and confirm the relevance of\\n the clusters in the target biological context (Supplementary Fig.', 'S1).', 'CLoNe’s only parameter regulates the size of the local neighborhood\\n considered around each data point, which can be regarded as cluster\\n sizing parameter.', 'Its value need only be decreased if clusters seem\\n too inclusive and vice-versa, making CLoNe an intuitive algorithm\\n to use in addition to its general applicability.', 'For structural datasets,\\n CLoNe is able to extract clusters as separate trajectories and provides scripts for their automatic loading in the visualization software\\n VMD (Humphrey et al., 1996).', 'For larger macromolecules, the concept of a conformational state is blurry, hard to determine and often\\n depends on context.', 'It is not always clear which features to use to\\n obtain an accurate partition of the structural ensemble.', 'The results\\n obtained on COQ9 can be obtained hypothesis-free on raw spatial\\n coordinates or using PCA to extract relevant features\\n (Supplementary Fig.', 'S4).', 'This was done in the case of APP as well as\\n to reduce an otherwise redundant feature space to one of lower\\n dimensionality.', 'If one wishes to disentangle internal from overall\\n motion, dihedral PCA was used with success to study peptide folding (Altis et al., 2007; Mu et al., 2004).', 'However, when other\\n features than the chosen ones can be expected to exhibit motions of\\n larger amplitudes, PCA will favor the latter over the former.', 'This is\\n true for the TEM1 b-lactamase, where internal structural motions\\n will be more prevalent than the fluctuations of the selected key\\n pocket residues.', 'In such cases, a feature-based approach is to be preferred.', 'Alternatively, some will advocate the use of time-lagged independent component analysis (TICA) (Naritomi and Fuchigami,\\n 2011) instead.', 'TICA was found to be the better alternative for building Markov state models (Husic and Pande, 2018; Pe´rez-Herna´ndez\\n et al., 2013).', 'However, in cases where large amplitude fluctuations\\n are the target or when there is redundancy in features, we believe\\n that PCA remains a safe approach.', 'As the conformational ensembles presented in this study tend to\\n exhibit Gaussian distributions, CLoNe may thus be used to extract\\n cluster centers as higher probability states.', 'Such states offer an overview of the ensemble and may serve as starting models for building\\n Markov state models in general.', 'Moreover, the precision of the classification achieved by CLoNe enables the identification of dominant\\n biological states from large datasets.', 'Beyond the case of APP,\\n CLoNe identified different key pocket conformations in the case of\\n TEM1 b-lactamase.', 'Further clustering efforts on this system should\\n target the different positions of R244, which was not tracked in this\\n study but was previously shown to play a dual role between TEM1’s\\n active site and allosteric pocket (Horn and Shoichet, 2004).', 'CLoNe\\n may then be used as a pre-processing tool prior to small-molecule\\n docking studies, where accounting for receptor flexibility is an active\\n development area (Kokh et al., 2011; Vahl Quevedo et al., 2014).', 'Integrative modeling aims at incorporating data from multiple\\n sources to determine the structure of macromolecular complexes.', 'Such hybrid strategies typically combine low resolution data of\\n whole complexes with high resolution structures of their components so as to predict the quaternary structure of the former\\n (Cassidy et al., 2018).', 'This process is however severely hindered by\\n structural dynamics differing between a complex and its isolated\\n components.', 'For this reason, many hybrid modeling strategies now\\n incorporate some form of dynamics to bridge this gap (Malhotra\\n et al., 2019; Tamo` et al., 2015).', 'While we previously utilized classical MD for the prediction of heptameric aerolysin pores (Degiacomi\\n et al., 2013; Degiacomi and Dal Peraro, 2013), such an approach\\n would not be feasible for heteromultimeric assemblies where\\n Fig.', '4.', 'Identification of different opening states of the allosteric cryptic pocket in TEM1 b-lactamase.', '(a) apo and Holo structures (left and right, respectively).', 'Allosteric inhibitors are shown in gray and white.', 'Features following helical opening include the distance between Ca atoms of N276 and L220 (medium blue) and the Cc of their sidechain\\n (light blue).', 'Pocket depth is monitored by the distance between Ca-carbons of I263 and 279 (dark blue).', '(b) The pocket exposure calculated using the fpocket software for the\\n original replicas (top) and for each clusters (bottom).', 'The dotted line in both is the reference value of the holo crystal structure used in the original paper.', '(c) The center of each\\n cluster in cartoon representation on top of a surface representation of the allosteric pocket, highlighting the different states of helical openness and pocket depth.', 'The triad\\n N276-L220-R244 governing pocket opening and closing are shown as gray sticks.', '(c) The distribution of each feature for each cluster (top) and the cluster assignation along\\n the three chosen replicas (bottom)\\n 6 S.Tra¨ ger et al.', 'Downloaded from https://academic.oup.com/bioinformatics/advance-article/doi/10.1093/bioinformatics/btaa742/5895303 by guest on 19 March 2021\\n multiple conformational ensembles are required simultaneously.', 'Reducing them to their crucial components may enable the structural characterization of large macromolecular complexes, which\\n may otherwise be intractable.', 'Applied to the fields of smallmolecule docking, integrative modeling and structural dynamics\\n studies, CLoNe presents itself as a versatile and powerful tool for\\n modern computational structural biology.', 'Acknowledgements\\n We thank Vladimiras Oleinikovas and Francesco L. Gervasio for providing\\n the simulations of the TEM1 b-lactamase as well as offering general advice;\\n Lucien F. Krapp and Romain Groux for helpful discussions.', 'Funding\\n M.D.P.', 'lab was supported by the Swiss National Science Foundation (grants\\n number 200021_157217 and 31003A_170154).', 'Conflict of Interest: none declared.', 'References\\n Abriata,L.A.', 'and Dal Peraro,M.', '(2020) Will cryo-electron microscopy shift\\n the current paradigm in protein structure prediction?', 'J. Chem.', 'Inf.', 'Model.,\\n 60, 2443–2447.', 'Altis,A.', 'et al.', '(2007) Dihedral angle principal component analysis of molecular\\n dynamics simulations.', 'J. Chem.', 'Phys., 126, 244111.', 'Amaro,R.E.', 'et al.', '(2018) Ensemble docking in drug discovery.', 'Biophys.', 'J.,\\n 114, 2271–2278.', 'Ankerst,M.', 'et al.', '(1999) OPTICS: Ordering Points to Identify the Clustering\\n Structure.', 'In: Proceedings of the 1999 ACM SIGMOD International\\n Conference on Management of Data, SIGMOD ’99, pp.', '49–60.', 'ACM, New\\n York, NY, USA.', 'Audagnotto,M.', 'and Dal Peraro,M.', '(2017) Protein post-translational modifications: in silico prediction tools and molecular modeling.', 'Comput.', 'Struct.', 'Biotechnol.', 'J., 15, 307–319.', 'Audagnotto,M.', 'et al.', '(2016) Effect of the synaptic plasma membrane on the\\n stability of the amyloid precursor protein homodimer.', 'J. Phys.', 'Chem.', 'Lett.,\\n 7, 3572–3578.', 'Barducci,A.', 'et al.', '(2011) Metadynamics.', 'Wiley Interdiscip.', 'Rev.', 'Comput.', 'Mol.', 'Sci., 1, 826–843.', 'Beauchamp,K.A.', 'et al.', '(2012) Simple few-state models reveal hidden complexity in protein folding.', 'Proc.', 'Natl.', 'Acad.', 'Sci.', 'USA, 109, 17807–17813.', 'Bhattacharyya,A.', '(1943) On a measure of divergence between two statistical\\n populations defined by their probability distributions.', 'Bull.', 'Calcutta Math.', 'Soc., 35, 99–109.', 'Bussi,G.', '(2014) Hamiltonian replica exchange in GROMACS: a flexible implementation.', 'Mol.', 'Phys., 112, 379–384.', 'Cassidy,C.K.', 'et al.', '(2018) CryoEM-based hybrid modeling approaches for\\n structure determination.', 'Curr.', 'Opin.', 'Microbiol., 43, 14–23.', 'Chang,H.', 'and Yeung,D.-Y.', '(2008) Robust path-based spectral clustering.', 'Pattern Recogn., 41, 191–203.', 'Chavent,M.', 'et al.', '(2016) Molecular dynamics simulations of membrane proteins and their interactions: from nanoscale to mesoscale.', 'Curr.', 'Opin.', 'Struct.', 'Biol., 40, 8–16.', 'Cheng,L.S.', 'et al.', '(2008) Ensemble-based virtual screening reveals potential\\n novel antiviral compounds for avian influenza neuraminidase.', 'J. Med.', 'Chem., 51, 3878–3894.', 'd’Errico,M.', 'et al.', '(2018) Automatic topography of high-dimensional data sets\\n by non-parametric density peak clustering.', 'arXiv:1802.10549v1 [stat.ML]\\n De Paris,R.', 'et al.', '(2015) Clustering molecular dynamics trajectories for optimizing docking experiments.', 'Comput.', 'Intell.', 'Neurosci., 2015, 1–9.', 'de Souza,V.C.', 'et al.', '(2017) Clustering algorithms applied on analysis of protein molecular dynamics.', 'In: 2017 IEEE Latin American Conference on\\n Computational Intelligence (LA-CCI).', 'Arequipa, 2017, pp.', '1–6.', 'https://doi.', 'org/10.1109/LA-CCI.2017.8285695\\n De Vivo,M.', 'et al.', '(2016) Role of molecular dynamics and related methods in\\n drug discovery.', 'J. Med.', 'Chem., 59, 4035–4061.', 'Degiacomi,M.T.', 'and Dal Peraro,M.', '(2013) Macromolecular symmetric assembly prediction using swarm intelligence dynamic modeling.', 'Structure,\\n 21, 1097–1106.', 'Degiacomi,M.T.', 'et al.', '(2013) Molecular assembly of the aerolysin pore reveals\\n a swirling membrane-insertion mechanism.', 'Nat.', 'Chem.', 'Biol., 9, 623–629.', 'Doerr,S.', 'et al.', '(2016) HTMD: high-throughput molecular dynamics for molecular discovery.', 'J. Chem.', 'Theory Comput., 12, 1845–1852.', 'Du,M.', 'et al.', '(2016) Study on density peaks clustering based on k-nearest neighbors and principal component analysis.', 'Knowl.', 'Based Syst., 99, 135–145.', 'Ester,M.', 'et al.', '(1996) A density-based algorithm for discovering clusters a\\n density-based algorithm for discovering clusters in large spatial databases\\n with noise.', 'In: Proceedings of the Second International Conference on\\n Knowledge Discovery and Data Mining, KDD’96, pp.', '226–231.', 'AAAI\\n Press, Portland, OR, USA.', 'Fonti,G.', 'et al.', '(2019) KAP1 is an antiparallel dimer with a natively functional\\n asymmetry.', 'Life Science Alliance, 2(4), e201900349.', 'Frank,J.', '(2018) New opportunities created by single-particle cryo-EM: the\\n mapping of conformational space.', 'Biochemistry, 57, 888–888.', 'Fra¨nti,P., and Sieranoja,S.', '(2018) K-means properties on six clustering benchmark datasets.', 'Applied Intelligence, 48, 4743–4759.', '10.1007/s10489-\\n 018-1238-7\\n Fig.', '5.', 'Classification and frequency estimation of APP dimerization motifs in the\\n plasma membrane.', '(a) The two known dimerization motifs of the transmembrane\\n helix of APP.', 'Membrane is depicted with gray spheres, the G700G704G708 motif\\n with teal spheres and the G709A713 motif with gold spheres.', '(b) The black line\\n depicts the probability density distribution of the trajectory along the first principal\\n component, which covers 77% of variability.', 'Obtained clusters are shown in colors\\n underneath, with their centers as black stars.', 'Below the clusters is the distribution of\\n core cardinalities, with the corresponding color bar below it.', '(c) The cluster of\\n bound dimers of (b) was extracted and the pair-wise distances between the backbone atoms of each motifs in both helices was computed for every frame.', 'The plot\\n shows the first two principal components of the resulting dataset (with eigenvalues\\n of 0.66 and 0.28, respectively), where each point is color-coded according to the\\n cardinality of its core.', 'Stars represent cluster centers.', '(d) The clusters obtained from\\n the aforementioned dataset of bound conformations.', '(e) Renders of the unbound\\n and dimerized APP cluster centers and their respective frequency after outlier removal.', 'Dimerized APP centers shown correspond to the dark blue, dark brown and\\n dark green clusters.', 'Sidechains have been hidden for better visualization\\n CLoNe: automated clustering of biomolecular structural ensembles 7\\n Downloaded from https://academic.oup.com/bioinformatics/advance-article/doi/10.1093/bioinformatics/btaa742/5895303 by guest on 19 March 2021\\n Fu,L.', 'and Medico,E.', '(2007) FLAME, a novel fuzzy clustering method for the\\n analysis of DNA microarray data.', 'BMC Bioinformatics, 8, 3.', 'Gionis,A.', 'et al.', '(2007) Clustering aggregation.', 'ACM Trans.', 'Knowl.', 'Discov.', 'Data, 1, 4.', 'Hamelberg,D.', 'et al.', '(2004) Accelerated molecular dynamics: a promising and\\n efficient simulation method for biomolecules.', 'J. Chem.', 'Phys., 120,\\n 11919–11929.', 'Horn,J.R.', 'and Shoichet,B.K.', '(2004) Allosteric inhibition through core disruption.', 'J. Mol.', 'Biol, 336, 1283–1291.', 'Humphrey,W.', 'et al.', '(1996) VMD: visual molecular dynamics.', 'J. Mol.', 'Graph,\\n 14, 33–38.', 'Husic,B.E.', 'and Pande,V.S.', '(2018) Markov state models: from an art to a science.', 'J.', 'Am.', 'Chem.', 'Soc., 140, 2386–2396.', 'Husic,B.E.', 'and Pande,V.S.', '(2017) Ward clustering improves cross-validated Markov\\n state models of protein folding.J.', 'Chem.', 'Theory Comput., 13, 963–967.', 'Jain,A.K.', '(2010) Data clustering: 50 years beyond K-means.', 'Pattern Recognit.', 'Lett., 31, 651–666.', 'Jones,E.', 'et al.', '(2001) SciPy: open source scientific tools for Python.', '10.1038/s41592-019-0686-2.', 'Kokh,D.B.', 'et al.', '(2011) Receptor flexibility in small-molecule docking calculations.', 'Wiley Interdiscip.', 'Rev.', 'Comput.', 'Mol.', 'Sci., 1, 298–314.', 'Le Guilloux,V.', 'et al.', '(2009) Fpocket: an open source platform for ligand\\n pocket detection.', 'BMC Bioinformatics, 10, 168.', 'Liang,Z.', 'and Chen,P.', '(2016) Delta-density based clustering with a\\n divide-and-conquer strategy: 3DC clustering.', 'Pattern Recognit.', 'Lett., 73, 52–59.', 'Lohman,D.C.', 'et al.', '(2019) An isoprene lipid-binding protein promotes eukaryotic coenzyme Q biosynthesis.', 'Mol.', 'Cell, 73, 763–774.e10.', 'Lohman,D.C.', 'et al.', '(2014) Mitochondrial COQ9 is a lipid-binding protein\\n that associates with COQ7 to enable coenzyme Q biosynthesis.', 'Proc.', 'Natl.', 'Acad.', 'Sci.', 'USA, 111, E4697–E4705.', 'Malhotra,S.', 'et al.', '(2019) Modelling structures in cryo-EM maps.', 'Curr.', 'Opin.', 'Struct.', 'Biol., 58, 105–114.', 'McGibbon,R.T.', 'et al.', '(2015) MDTraj: a modern open library for the analysis\\n of molecular dynamics trajectories.', 'Biophys.', 'J., 109, 1528–1532.', 'McKiernan,K.', 'A. et al.. (2017) Modeling the mechanism of CLN025 beta--\\n hairpin formation.', 'The Journal of Chemical Physics, 147, 104107.', 'Mehmood,R.', 'et al.', '(2016) Clustering by fast search and find of density peaks\\n via heat diffusion.', 'Neurocomputing, 208, 210–217.', 'Mu,Y.', 'et al.', '(2004) Energy landscape of a small peptide revealed by dihedral\\n angle principal component analysis.', 'Proteins Struct.', 'Funct.', 'Bioinform., 58,\\n 45–52.', 'Naritomi,Y.', 'and Fuchigami,S.', '(2011) Slow dynamics in protein fluctuations\\n revealed by time-structure based independent component analysis: the case\\n of domain motions.', 'J. Chem.', 'Phys., 134, 065101.', 'Noe´,F.', 'et al.', '(2019) Boltzmann generators: sampling equilibrium states of\\n many-body systems with deep learning.', 'Science, 365, eaaw1147.', 'Oleinikovas,V.', 'et al.', '(2016) Understanding cryptic pocket formation in protein targets by enhanced sampling simulations.', 'J.', 'Am.', 'Chem.', 'Soc., 138,\\n 14257–14263.', 'Paris,R.D.', 'et al.', '(2015) An effective approach for clustering InhA molecular\\n dynamics trajectory using substrate-binding cavity features.', 'PLoS One, 10,\\n e0133172.', 'Pedregosa,F.', 'et al.', '(2011) Scikit-learn: machine learning in Python.', 'J. Mach.', 'Learn.', 'Res., 12, 2825–2830.', 'Peng,J.', 'et al.', '(2018) Clustering algorithms to analyze molecular dynamics\\n simulation trajectories for complex chemical and biological systems.', 'Chin.', 'J. Chem.', 'Phys., 31, 404–420.', 'Pe´rez-Herna´ndez,G.', 'et al.', '(2013) Identification of slow molecular order\\n parameters for Markov model construction.', 'J. Chem.', 'Phys., 139, 015102.', 'Rodriguez,A.', 'et al.', '(2018) Computing the free energy without collective variables.', 'J. Chem.', 'Theory Comput., 14, 1206–1215.', 'Rodriguez,A.', 'and Laio,A.', '(2014) Clustering by fast search and find of density\\n peaks.', 'Science, 344, 1492–1496.', 'Salmaso,V., and Moro,S.', '(2018) Bridging molecular docking to molecular dynamics in exploring ligand-protein recognition process: an overview.', 'Front.', 'Pharmacol, 9, 923.', 'Seabold,S.', 'and Perktold,J.', '(2010) Statsmodels: econometric and statistical\\n modeling with python.', 'In: 9th Python in Science Conference.', 'https://www.', 'statsmodels.org/devel/#citation.', 'Shao,J.', 'et al.', '(2007) Clustering molecular dynamics trajectories: 1.', 'Characterizing the performance of different clustering algorithms.', 'J. Chem.', 'Theory Comput., 3, 2312–2334.', 'Shirts,M.', 'and Pande,V.S.', '(2000) Screen savers of the World Unite!', 'Science,\\n 290, 1903–1904.', 'Sultan,M.M.', 'et al.', '(2018) Transferable neural networks for enhanced sampling of protein dynamics.', 'J. Chem.', 'Theory Comput., 14, 1887–1894.', 'Tamo`,G.E.', 'et al.', '(2015) The importance of dynamics in integrative modeling\\n of supramolecular assemblies.', 'Curr.', 'Opin.', 'Struct.', 'Biol., 31, 28–34.', 'Vahl Quevedo,C.', 'et al.', '(2014) A strategic solution to optimize molecular\\n docking simulations using Fully-Flexible Receptor models.', 'Expert Syst.', 'Appl., 41, 7608–7620.', 'Wang,W.', 'et al.', '(2018) Constructing Markov state models to elucidate the\\n functional conformational changes of complex biomolecules.', 'Wiley\\n Interdiscip.', 'Rev.', 'Comput.', 'Mol.', 'Sci., 8, e1343.', 'Wang,X.-F. and Xu,Y.', '(2017) Fast clustering using adaptive density peak detection.', 'Stat.', 'Methods Med.', 'Res., 26, 2800–2811.', 'Ward,J.H.', '(1963) Hierarchical grouping to optimize an objective function.', 'J.', 'Am.', 'Stat.', 'Assoc., 58, 236–244.', 'Wassenaar,T.A.', 'et al.', '(2015) High-throughput simulations of dimer and trimer assembly of membrane proteins.', 'the DAFT Approach.', 'J. Chem.', 'Theory\\n Comput., 11, 2278–2291.', 'Wolf,A.', 'and Kirschner,K.N.', '(2013) Principal component and clustering analysis on molecular dynamics data of the ribosomal L11\\x0523S subdomain.', 'J.\\n Mol.', 'Model., 19, 539–549.', 'Xie,J.', 'et al.', '(2016) Robust clustering by detecting density peaks and assigning\\n points based on fuzzy weighted K-nearest neighbors.', 'Inf.', 'Sci., 354, 19–40.', 'Zhang,W.', 'and Li,J.', '(2015) Extended fast search clustering algorithm: widely\\n density clusters, no density peaks.', 'arXiv:1505.05610 [cs.DS].', '8 S.Tra¨ ger et al.', 'Downloaded from https://academic.oup.com/bioinformatics/advance-article/doi/10.1093/bioinformatics/btaa742/5895303 by guest on 19 March 2021']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BzSxRz_YDJ_B",
        "outputId": "4236b963-dcd8-42ad-ed81-e43dd4c88089"
      },
      "source": [
        "lsa_summary[0]"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'['"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nySyffmVAISY",
        "outputId": "39f19e70-0bcc-4adb-b252-075d29ded1f0"
      },
      "source": [
        "myquery= input(\"Please enter the information to be searched \")\n",
        "data =google_search(API_KEY,SEARCH_ENGINE_ID,myquery)\n",
        "results(data)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please enter the information to be searched Structural bioinformatics\\\\n CLoNe: automated clustering based on local density\\\\n neighborhoods for application to biomolecular structural\\\\n ensembles\\\\n Sylvain Tra¨ ger1,2, Giorgio Tamo` 1,2, Deniz Aydin1,2, Giulia Fonti1,2,\\\\n Martina Audagnotto1,2 and Matteo Dal Peraro1,2,*\\\\n 1\\\\n Institute of Bioengineering, School of Life Sciences, Ecole Polytechnique Fe´ de´ rale de Lausanne, Lausanne 1025, Switzerland and 2\\\\n Swiss Institute of Bioinformatics, Lausanne 1015, Switzerland\\\\n *To whom correspondence should be addressed.', 'Associate Editor: Lenore Cowen\\\\n Received on January 8, 2020; revised on July 14, 2020; editorial decision on August 12, 2020; accepted on August 18, 2020\\\\n Abstract\\\\n Motivation: Proteins are intrinsically dynamic entities.', 'Flexibility sampling methods, such as molecular dynamics or\\\\n those arising from integrative modeling strategies, are now commonplace and enable the study of molecular conformational landscapes in many contexts\n",
            "Title: CLoNe: automated clustering based on local density neighborhoods ...\n",
            "Description: Aug 21, 2020 ... neighborhoods for application to biomolecular structural ensembles. Sylvain Tra¨ \n",
            "ger1,2, Giorgio Tamo`1,2, Deniz Aydin1,2, Giulia Fonti1,2,.\n",
            "URL: https://academic.oup.com/bioinformatics/advance-article-pdf/doi/10.1093/bioinformatics/btaa742/36453399/btaa742.pdf \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfA1A9jNEqk0",
        "outputId": "1fbbc5c8-8ee4-4437-d1a6-6ba69726512b"
      },
      "source": [
        "url = \"https://academic.oup.com/bioinformatics/advance-article-pdf/doi/10.1093/bioinformatics/btaa742/36453399/btaa742.pdf  \"\n",
        "\n",
        "# Requests URL and get response object \n",
        "response = requests.get(url) \n",
        "i=1\n",
        "pdf = open(\"pdf\"+str(i)+\".pdf\", 'wb') \n",
        "pdf.write(response.content) \n",
        "pdf.close() \n",
        "print(\"File \", i, \" downloaded\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File  1  downloaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "EuPPfLYDFHqY",
        "outputId": "247beca3-4927-4bf1-9184-3e16a8591d76"
      },
      "source": [
        "import PyPDF2\n",
        "from PyPDF2 import PdfFileReader\n",
        "  \n",
        "# creating a pdf file object\n",
        "pdfFileObj = open('pdf1.pdf', 'rb')\n",
        "  \n",
        "# creating a pdf reader object\n",
        "pdfReader = PyPDF2.PdfFileReader(pdfFileObj)\n",
        "with open(\"pdf1.pdf\", 'rb') as f:\n",
        "  pdf = PdfFileReader(f)\n",
        "  information = pdf.getDocumentInfo()\n",
        "  number_of_pages = pdf.getNumPages()\n",
        "\n",
        "txt = f\"\"\"\n",
        "Information about {\"pdf1.pdf\"}: \n",
        "Author: {information.author}\n",
        "Creator: {information.creator}\n",
        "Producer: {information.producer}\n",
        "Subject: {information.subject}\n",
        "Title: {information.title}\n",
        "Number of pages: {number_of_pages}\n",
        "    \"\"\"\n",
        "\n",
        "print(txt)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "error",
          "ename": "PdfReadError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPdfReadError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-27542030cf8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# creating a pdf reader object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mpdfReader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPyPDF2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPdfFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdfFileObj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pdf1.pdf\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mpdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPdfFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PyPDF2/pdf.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, stream, strict, warndest, overwriteWarnings)\u001b[0m\n\u001b[1;32m   1082\u001b[0m             \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m             \u001b[0mfileobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1085\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PyPDF2/pdf.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, stream)\u001b[0m\n\u001b[1;32m   1695\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlast1K\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1696\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPdfReadError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"EOF marker not found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1697\u001b[0;31m             \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadNextEndLine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1698\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"  line:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PyPDF2/pdf.py\u001b[0m in \u001b[0;36mreadNextEndLine\u001b[0;34m(self, stream)\u001b[0m\n\u001b[1;32m   1935\u001b[0m             \u001b[0;31m# Prevent infinite loops in malformed PDFs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1936\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1937\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPdfReadError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Could not read malformed PDF file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1938\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1939\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"  x:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"%x\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mPdfReadError\u001b[0m: Could not read malformed PDF file"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "id": "6dDQhvKTAey_",
        "outputId": "31a6809d-3123-4b81-befb-e73504336b58"
      },
      "source": [
        "import newspaper \n",
        "URL_link =only_link(data)\n",
        "all_scraped_documents =[]  \n",
        "i= 0\n",
        "# Parse through each url and display its content \n",
        "for url in URL_link: \n",
        "    print(\"First Run\")\n",
        "    url_i = newspaper.Article(url=\"%s\" % (url), language='en') \n",
        "    url_i.download() \n",
        "    url_i.parse() \n",
        "    all_scraped_documents.append(url_i.text)\n",
        "    i = i+1\n",
        "    print(url_i.text)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First Run\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ArticleException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mArticleException\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-536ddf7c9619>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0murl_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnewspaper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArticle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0murl_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0murl_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mall_scraped_documents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/newspaper/article.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow_if_not_downloaded_verbose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/newspaper/article.py\u001b[0m in \u001b[0;36mthrow_if_not_downloaded_verbose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mArticleDownloadState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFAILED_RESPONSE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             raise ArticleException('Article `download()` failed with %s on URL %s' %\n\u001b[0;32m--> 532\u001b[0;31m                   (self.download_exception_msg, self.url))\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mthrow_if_not_parsed_verbose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mArticleException\u001b[0m: Article `download()` failed with 403 Client Error: Forbidden for url: https://academic.oup.com/bioinformatics/advance-article-pdf/doi/10.1093/bioinformatics/btaa742/36453399/btaa742.pdf on URL https://academic.oup.com/bioinformatics/advance-article-pdf/doi/10.1093/bioinformatics/btaa742/36453399/btaa742.pdf"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YaOe4MTBuHZ"
      },
      "source": [
        "sentencesweb=sent_tokenize(textextract2)\n",
        "text_embeddings = model.encode(sentencesweb, batch_size = 8, show_progress_bar = True)\n",
        "text_embeddings2 = model.encode(sentencesAtten, batch_size = 8, show_progress_bar = True)\n",
        "np.shape(text_embeddings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrHuQ__fB4VJ"
      },
      "source": [
        "similarities = cosine_similarity(text_embeddings,text_embeddings2)\n",
        "similarities_sorted = similarities.argsort()\n",
        "# Get list of similarity indices i.e. doc at index 0 simialr with doc at index 1169 below.\n",
        "id_1 = []\n",
        "id_2 = []\n",
        "score = []\n",
        "for index,array in enumerate(similarities_sorted):\n",
        "    id_1.append(index)\n",
        "    id_2.append(array[-2])\n",
        "    score.append(similarities[index][array[-2]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQgy4rwBB-vz"
      },
      "source": [
        "sum_of_sims =(np.sum(index_df[\"score\"]))\n",
        "print(sum_of_sims)\n",
        "percentage_of_similarity = round(float((sum_of_sims / len(sentencesweb)) * 100))\n",
        "print(f'Average similarity float: {float(sum_of_sims / len(sentencesweb))}')\n",
        "print(f'Average similarity percentage: {float(sum_of_sims / len(sentencesweb)) * 100}')\n",
        "print(f'Average similarity rounded percentage: {percentage_of_similarity}')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}